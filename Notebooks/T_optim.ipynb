{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the right T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal : find T such as [A1,...,A1,A2,...,A2] is the optimal split.\n",
    "                                T\n",
    "                                \n",
    "Definition: risque: $R(A)=\\frac{1}{n}\\sum_{i}^{n}\\sum_{t}^{T} || Y_{i,t}-A_{t}X_{i,t}||²$\n",
    "\n",
    "Trois modèles:\n",
    "- Général : A = (A,A,...,A)\n",
    "- Spécifique : A = (A1,A1,...,A5,A5)\n",
    "- Selectif: A = (A1,...,A1,A2,...,A2) avec split en T^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\" \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt        \n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "sys.path.append('../scripts/')\n",
    "from models import BaseModels, DataCleaner, ModelPlots, DataModel\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeResults=pd.read_pickle(\"../data/mergeResults.pckl\")\n",
    "segmentsMeta=pd.read_pickle(\"../data/segmentsMeta.pckl\")\n",
    "speeds = pd.read_pickle(\"../data/monthsSpeed__0.pckl\")\n",
    "counts = pd.read_pickle('../data/monthsCount__0.pckl')\n",
    "data_cleaner = DataCleaner(speeds, segmentsMeta, mergeResults, counts)\n",
    "speedDF = data_cleaner.data\n",
    "\n",
    "nSegments = len(speedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedDF = pd.read_pickle('../data/full_day_speed_df.pckl')\n",
    "nSegments = len(speedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de rique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risque(A, X, Y):\n",
    "    n = 45\n",
    "    T = 19\n",
    "    r = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for t in range(T):\n",
    "            r += np.mean((Y[i*t] - np.dot(A[t], X[i*t]))**2)\n",
    "    r = r/(n*T)\n",
    "    \n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des risques en fonction de T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Général"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Created!\n",
      "n = 61\n",
      "Z Centré !\n",
      "(2475, 556) (2475, 556)\n",
      "(880, 556) (880, 556)\n"
     ]
    }
   ],
   "source": [
    "Z = []\n",
    "\n",
    "times_per_day = 56\n",
    "\n",
    "for i in range(int((speedDF.shape[1])/times_per_day)):\n",
    "    Z.append(speedDF.iloc[:,i*times_per_day:(i+1)*times_per_day].values)\n",
    "\n",
    "print(\"Z Created!\")\n",
    "n = len(Z)\n",
    "print(\"n =\", n)\n",
    "\n",
    "Z = np.array(Z)\n",
    "\n",
    "Z_train = Z[:45]\n",
    "Z_test = Z[45:]\n",
    "\n",
    "M = (1/45)*Z_train.sum(axis=0)\n",
    "\n",
    "for i in range(45):\n",
    "    Z_train[i] = Z_train[i] - M\n",
    "for i in range(61-45):\n",
    "    Z_test[i] = Z_test[i] - M\n",
    "    \n",
    "print(\"Z Centré !\")\n",
    "\n",
    "\n",
    "def X_Y(Z):\n",
    "    new_X = Z[:,:,:-1]\n",
    "    new_Y = Z[:,:,1:]\n",
    "    new_X = np.concatenate(new_X, axis=1)\n",
    "    new_Y = np.concatenate(new_Y, axis=1)\n",
    "    return new_X.T, new_Y.T\n",
    "\n",
    "new_X_train, new_Y_train  = X_Y(Z_train)\n",
    "print(new_X_train.shape, new_Y_train.shape)\n",
    "new_X_test, new_Y_test = X_Y(Z_test)\n",
    "print(new_X_test.shape, new_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lasso_parra = [linear_model.LassoCV(n_jobs=4, cv=5, max_iter=10000, tol=0.0001, n_alphas=100, fit_intercept=False, eps=0.0001) for i in range(nSegments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lasso(i):\n",
    "    A_lasso_parra[i].fit(new_X_train, new_Y_train[:, i])\n",
    "    print(i,\"alpha:\",A_lasso_parra[i].alpha_,\"\\nalphas\", len(A_lasso_parra[i].alphas_), \"\\nnb iter:\", A_lasso_parra[i].n_iter_)\n",
    "    return A_lasso_parra[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 alpha: 3.937372268742703 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "120 alpha: 3.7003479321245556 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "48 alpha: 3.783406929925741 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "24 alpha: 3.1754900060253983 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "36 alpha: 6.345250665664159 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "108 alpha: 4.099319692662646 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "132 alpha: 7.529903470758456 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "96 alpha: 2.347885296194432 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "12 alpha: 4.977210792290045 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "84 alpha: 5.935072267512031 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "61 alpha: 2.8030974486357496 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "0 alpha: 5.084526337056244 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "72 alpha: 2.996388045019106 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "49 alpha: 3.6761143958645897 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "121 alpha: 7.156685115516659 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "25 alpha: 6.539713105100005 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "62 alpha: 4.4427667961511 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "13 alpha: 4.592918647445272 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "50 alpha: 9.430561328538177 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "133 alpha: 6.522438074537581 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "109 alpha: 5.470236358764467 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "73 alpha: 2.718346177643803 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "1 alpha: 3.639771571180838 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "37 alpha: 1.660749087190992 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "97 alpha: 5.827881386533594 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "85 alpha: 6.717351212141642 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "14 alpha: 3.468569204320932 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "26 alpha: 2.4227918828281223 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "51 alpha: 5.5553279003960725 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "63 alpha: 5.040516350728668 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "86 alpha: 6.111250312717636 \n",
      "alphas 100 \n",
      "nb iter: 77\n",
      "122 alpha: 11.330198891980888 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "15 alpha: 6.8197897634499105 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "2 alpha: 4.212774794975777 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "38 alpha: 5.215507806463355 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "98 alpha: 6.898127249202415 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "134 alpha: 9.89886565574828 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "110 alpha: 3.898319456889811 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "74 alpha: 1.9322769398537794 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "52 alpha: 3.9526605681980347 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "16 alpha: 2.709776357766053 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "123 alpha: 4.202235669541728 \n",
      "alphas 100 \n",
      "nb iter: 67\n",
      "87 alpha: 7.476076339168174 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "64 alpha: 4.264850707104959 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "27 alpha: 1.9549463194042063 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "3 alpha: 7.105546840004369 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "135 alpha: 2.6291164877678708 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "99 alpha: 5.349339707754108 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "53 alpha: 5.9157136169058715 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "17 alpha: 4.946713685861367 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "39 alpha: 4.272303268592268 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "4 alpha: 1.7137781032757775 \n",
      "alphas 100 \n",
      "nb iter: 79\n",
      "124 alpha: 5.042527225689603 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "28 alpha: 6.277555491728509 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "18 alpha: 3.4890256259165366 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "75 alpha: 6.551184420718445 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "111 alpha: 3.365216332295814 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "54 alpha: 2.213750189622374 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "88 alpha: 4.277226160607005 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "65 alpha: 5.828663251882224 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "136 alpha: 3.4965712820843042 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "40 alpha: 4.278929205720682 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "19 alpha: 3.741689720637754 \n",
      "alphas 100 \n",
      "nb iter: 67\n",
      "29 alpha: 5.208615809209246 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "100 alpha: 3.1727977116999604 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "137 alpha: 6.08497423965662 \n",
      "alphas 100 \n",
      "nb iter: 78\n",
      "66 alpha: 3.133876965406974 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "76 alpha: 7.9017345259282585 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "55 alpha: 2.843750679298778 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "5 alpha: 2.4929855134615146 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "89 alpha: 5.183765457583293 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "125 alpha: 3.3497093649210696 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "30 alpha: 4.949979951515281 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "67 alpha: 4.345247305737133 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "101 alpha: 4.217193645947244 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "112 alpha: 2.5161575216345957 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "20 alpha: 3.454374177048441 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "56 alpha: 3.6563730530083274 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "77 alpha: 7.8982907064015615 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "41 alpha: 3.794146552975768 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "90 alpha: 4.012857560983659 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "6 alpha: 5.95599079234283 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "68 alpha: 1.6928363864938134 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "138 alpha: 10.16605500492602 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "126 alpha: 4.096782021696342 \n",
      "alphas 100 \n",
      "nb iter: 55\n",
      "57 alpha: 3.1095630008972557 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "31 alpha: 13.747151597997036 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "102 alpha: 3.879742179056338 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "7 alpha: 5.289910055555876 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "21 alpha: 8.46920616744094 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "69 alpha: 2.576865710223909 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "127 alpha: 5.2745428786491075 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "113 alpha: 7.073496982108314 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "78 alpha: 3.046665767179689 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "58 alpha: 3.060617385197003 \n",
      "alphas 100 \n",
      "nb iter: 52\n",
      "42 alpha: 4.134406806495898 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "70 alpha: 2.8431025452171004 \n",
      "alphas 100 \n",
      "nb iter: 93\n",
      "91 alpha: 9.603854513139577 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "8 alpha: 2.846152334371196 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "32 alpha: 9.452542957192504 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "79 alpha: 4.625736327639632 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "103 alpha: 5.571113783062043 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "139 alpha: 3.0527627474885537 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "114 alpha: 2.4808322199937787 \n",
      "alphas 100 \n",
      "nb iter: 93\n",
      "22 alpha: 4.444658364141705 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "128 alpha: 5.8975085835710415 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "59 alpha: 5.739039297412058 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "9 alpha: 4.703959941492476 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "71 alpha: 3.2750089755909797 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "104 alpha: 4.341576665623308 \n",
      "alphas 100 \n",
      "nb iter: 87\n",
      "23 alpha: 2.927301523752698 \n",
      "alphas 100 \n",
      "nb iter: 60\n",
      "43 alpha: 3.0782221386233872 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "80 alpha: 4.106854757315888 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "129 alpha: 3.783075649791988 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "144 alpha: 4.572889189207551 \n",
      "alphas 100 \n",
      "nb iter: 78\n",
      "92 alpha: 5.034054686266126 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "33 alpha: 10.16963532616385 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "105 alpha: 2.1767936750231485 \n",
      "alphas 100 \n",
      "nb iter: 105\n",
      "115 alpha: 10.853795747018287 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "44 alpha: 3.592573274798499 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "10 alpha: 4.0372728234516115 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "156 alpha: 3.4293762484901094 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "140 alpha: 4.272845421664079 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "81 alpha: 1.8408943241565536 \n",
      "alphas 100 \n",
      "nb iter: 55\n",
      "130 alpha: 3.017194538412133 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "168 alpha: 4.942968805675946 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "145 alpha: 5.234562361600242 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "45 alpha: 3.6098264693189233 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "157 alpha: 3.4125137484932715 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "93 alpha: 4.169328978164335 \n",
      "alphas 100 \n",
      "nb iter: 73\n",
      "34 alpha: 4.116136087228222 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "169 alpha: 2.4862696545552345 \n",
      "alphas 100 \n",
      "nb iter: 73\n",
      "11 alpha: 2.574786719796833 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "116 alpha: 10.626774786474796 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "82 alpha: 6.043305782312076 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "106 alpha: 6.278606655526046 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "158 alpha: 11.128704177390917 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "35 alpha: 5.152953817628634 \n",
      "alphas 100 \n",
      "nb iter: 75\n",
      "131 alpha: 4.326486887420964 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "46 alpha: 6.854734802732029 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "94 alpha: 3.2972535062291572 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "146 alpha: 2.167229054703404 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "180 alpha: 3.993142109129538 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "170 alpha: 7.120807447230932 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "83 alpha: 5.832657612266224 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "141 alpha: 10.159480567539173 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "159 alpha: 3.7651599839096512 \n",
      "alphas 100 \n",
      "nb iter: 83\n",
      "204 alpha: 5.475736266392899 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "181 alpha: 4.697286781670672 \n",
      "alphas 100 \n",
      "nb iter: 64\n",
      "216 alpha: 4.038752211502998 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "192 alpha: 3.874249583393574 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "142 alpha: 4.7489260738557215 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "117 alpha: 5.783481167732383 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "205 alpha: 6.085894109927445 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "47 alpha: 2.375670382365183 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "147 alpha: 3.986839165151797 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "171 alpha: 3.6403838495648615 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "160 alpha: 3.8287395333162273 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "107 alpha: 5.8438247921935735 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "95 alpha: 2.72570729014929 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "217 alpha: 4.03140156862183 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "193 alpha: 5.688027500042366 \n",
      "alphas 100 \n",
      "nb iter: 71\n",
      "182 alpha: 3.3417923590278207 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "206 alpha: 6.5695880434662755 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "118 alpha: 4.250465102251499 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "148 alpha: 4.055910250705207 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "161 alpha: 2.8372275617854052 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "228 alpha: 1.690848709958574 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "143 alpha: 21.788317366799056 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "218 alpha: 8.538660250221545 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "252 alpha: 5.73900881286724 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "149 alpha: 3.3865448398311364 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "172 alpha: 4.660573281267612 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "119 alpha: 4.646133859658709 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "240 alpha: 2.469202673678943 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "194 alpha: 5.053172303234735 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "264 alpha: 5.4869292503588545 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "207 alpha: 4.902005134339792 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "162 alpha: 2.7050711612498834 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "183 alpha: 5.371076315920631 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "229 alpha: 6.13796532720254 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "276 alpha: 4.1894250221130935 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "253 alpha: 3.8480554385322643 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "150 alpha: 8.591054682890308 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "208 alpha: 2.6744497604712687 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "219 alpha: 4.548508758241692 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "173 alpha: 6.135812953561645 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "184 alpha: 6.082130181484012 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "241 alpha: 5.244994351830859 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "277 alpha: 2.4201699550977205 \n",
      "alphas 100 \n",
      "nb iter: 83\n",
      "163 alpha: 5.312021611640585 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "195 alpha: 3.03406072635829 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "265 alpha: 1.6841607027104288 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "209 alpha: 1.9682823992271667 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "242 alpha: 3.5614742803905584 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "220 alpha: 5.444500046202605 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "230 alpha: 3.927488282749939 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "185 alpha: 3.6673480999663135 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "151 alpha: 7.62628330875789 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "266 alpha: 5.142584398238851 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "164 alpha: 4.039776755925004 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "278 alpha: 4.578106190182422 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "254 alpha: 1.378272725651118 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "174 alpha: 6.208658111982708 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "196 alpha: 4.613844915269218 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "231 alpha: 3.751942974596258 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "221 alpha: 6.253977303705593 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "243 alpha: 5.53830209414693 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "210 alpha: 8.0654871526619 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "279 alpha: 5.421785125011453 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "186 alpha: 5.865261685167318 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "267 alpha: 6.983102942435173 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "165 alpha: 5.408838707508737 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "152 alpha: 4.028177598889079 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "175 alpha: 10.511139821416169 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "244 alpha: 4.170176854298034 \n",
      "alphas 100 \n",
      "nb iter: 110\n",
      "232 alpha: 3.02462026007141 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "255 alpha: 14.90411487227676 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "222 alpha: 7.719643064933481 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "280 alpha: 5.162192184999501 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "211 alpha: 6.49155504170596 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "268 alpha: 2.2846037587285997 \n",
      "alphas 100 \n",
      "nb iter: 52\n",
      "245 alpha: 3.110447144026681 \n",
      "alphas 100 \n",
      "nb iter: 89\n",
      "153 alpha: 6.054094397765696 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "197 alpha: 4.577833043385963 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "233 alpha: 2.6287716762987823 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "176 alpha: 3.464633095928741 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "187 alpha: 8.863979530994774 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "166 alpha: 7.076174775153485 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "269 alpha: 3.8074513319790833 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "212 alpha: 3.549905971547373 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "223 alpha: 8.852956661290081 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "281 alpha: 13.25537099474255 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "154 alpha: 4.633527927322399 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "234 alpha: 5.531754475885237 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "246 alpha: 6.802538087927697 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "198 alpha: 6.805578973854829 \n",
      "alphas 100 \n",
      "nb iter: 3\n",
      "155 alpha: 2.3754273912647825 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "167 alpha: 2.3821353978172706 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "224 alpha: 4.980854700152958 \n",
      "alphas 100 \n",
      "nb iter: 79\n",
      "213 alpha: 4.407091571665398 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "177 alpha: 8.201805370591668 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "188 alpha: 10.063021486261093 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "256 alpha: 8.595714753683563 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "270 alpha: 3.7004115138807645 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "235 alpha: 4.281439189258011 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "282 alpha: 6.051597559449507 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "247 alpha: 4.111136230260232 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "199 alpha: 3.930582946757588 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "300 alpha: 7.438087613262321 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "288 alpha: 3.8041976216229214 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "271 alpha: 2.7230109802038522 \n",
      "alphas189 alpha: 10.908089964494481 \n",
      "alphas 100 \n",
      "nb iter: 100 \n",
      "nb iter: 2\n",
      " 53\n",
      "257 alpha: 2.3679020070359904 \n",
      "alphas 100 \n",
      "nb iter: 61\n",
      "178 alpha: 6.351120420331865 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "248 alpha: 4.470645431918283 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "225 alpha: 6.701561938253686 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "214 alpha: 2.3664847962183146 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "283 alpha: 8.222191873019524 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "200 alpha: 5.294054289503969 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "236 alpha: 8.640780594777233 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "249 alpha: 3.051967639218137 \n",
      "alphas 100 \n",
      "nb iter: 82\n",
      "301 alpha: 3.8710433254739725 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "258 alpha: 7.27872924719185 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "190 alpha: 3.987786927930862 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "289 alpha: 4.890128174620428 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "215 alpha: 4.40180789127767 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "250 alpha: 9.345369504426047 \n",
      "alphas 100 \n",
      "nb iter: 61\n",
      "226 alpha: 10.573384897190891 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "272 alpha: 9.689522528017466 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "237 alpha: 10.611115638140111 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "284 alpha: 4.146412650720396 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "201 alpha: 4.60125847444045 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "179 alpha: 12.285075698228264 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "191 alpha: 7.756159533468288 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "302 alpha: 2.027318841605087 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "259 alpha: 4.593889968486697 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "251 alpha: 4.725910627432828 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "312 alpha: 5.6231651157447615 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "285 alpha: 6.204402517802199 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "238 alpha: 7.877595791225181 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "273 alpha: 6.327287056046059 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "227 alpha: 2.4484466847111785 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "202 alpha: 4.93966091662001 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "324 alpha: 5.054253948367216 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "336 alpha: 2.339797563899256 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "290 alpha: 7.848237856471864 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "303 alpha: 4.730104395142373 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "313 alpha: 5.699475325773688 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "286 alpha: 4.30351874615854 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "325 alpha: 7.803100338864873 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "337 alpha: 2.5360931139857863 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "348 alpha: 8.232840589180752 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "239 alpha: 4.286838103123944 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "260 alpha: 3.2999091553190336 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "203 alpha: 5.081463636508983 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "360 alpha: 1.5480705035370426 \n",
      "alphas 100 \n",
      "nb iter: 67\n",
      "274 alpha: 2.3359927269838483 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "291 alpha: 5.828905965190854 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "314 alpha: 2.199816411247627 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "304 alpha: 7.811984371465538 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "287 alpha: 3.687455837297524 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "338 alpha: 2.403752965728757 \n",
      "alphas 100 \n",
      "nb iter: 52\n",
      "349 alpha: 3.469621990529956 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "372 alpha: 5.369322327407256 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "261 alpha: 3.5012753941523393 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "275 alpha: 2.12010795623452 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "315 alpha: 3.0090710177784534 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "292 alpha: 3.9850493011657595 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "384 alpha: 10.660797069346819 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "361 alpha: 4.631063837528422 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "373 alpha: 3.8201986467318143 \n",
      "alphas 100 \n",
      "nb iter: 62\n",
      "396 alpha: 7.969549590261432 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "305 alpha: 9.631988812414173 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "326 alpha: 8.813075062207012 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "339 alpha: 1.8420783711009618 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "350 alpha: 4.260797329670135 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "293 alpha: 5.489797702314994 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "374 alpha: 5.676703714180269 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "316 alpha: 6.8301909230632845 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "408 alpha: 5.912023796932332 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "385 alpha: 3.0602491294421137 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "262 alpha: 9.954076540946117 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "327 alpha: 4.3221871542031485 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "375 alpha: 5.351561056338005 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "317 alpha: 3.307332302618524 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "351 alpha: 6.187114963532596 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "397 alpha: 6.757827518154442 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "294 alpha: 6.292493066911329 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "306 alpha: 6.910412730511078 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "340 alpha: 6.336174729392217 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "409 alpha: 4.988517073110868 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "362 alpha: 9.6368576024458 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "328 alpha: 3.652166132151042 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "263 alpha: 3.7831805388470974 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "376 alpha: 4.047428641085294 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "318 alpha: 3.683485486205844 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "352 alpha: 4.062281341169332 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "386 alpha: 9.460195322243955 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "398 alpha: 1.7333838715272953 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "307 alpha: 2.9808157314173833 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "341 alpha: 3.7144227542517574 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "295 alpha: 3.3871138155465284 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "420 alpha: 6.384362346338808 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "329 alpha: 3.158378220869625 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "308 alpha: 4.593039716863549 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "377 alpha: 14.453726558661035 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "342 alpha: 3.2985821025587874 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "319 alpha: 5.487646059807105 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "410 alpha: 6.109570690025846 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "399 alpha: 3.015267628663085 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "353 alpha: 4.544381688955281 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "387 alpha: 7.422411803827621 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "363 alpha: 5.047378303838997 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "330 alpha: 4.038850181396192 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "400 alpha: 3.3987985532599976 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "411 alpha: 1.7234007294092364 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "309 alpha: 5.094370183266972 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "354 alpha: 6.6952511174568095 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "296 alpha: 7.407470718715833 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "388 alpha: 1.1045487972554546 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "421 alpha: 5.102959160076301 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "378 alpha: 3.141500592259702 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "320 alpha: 3.826477383302549 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "343 alpha: 7.354680297092469 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "412 alpha: 3.1712460470256834 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "331 alpha: 5.616915828715893 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "364 alpha: 5.790183928741222 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "297 alpha: 1.8817576961559646 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "389 alpha: 1.70332148586931 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "379 alpha: 2.6840611654832656 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "422 alpha: 1.6892673342768403 \n",
      "alphas 100 \n",
      "nb iter: 93\n",
      "401 alpha: 3.483548620310897 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "355 alpha: 3.744813117837485 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "413 alpha: 3.9095185155830836 \n",
      "alphas 100 \n",
      "nb iter: 55\n",
      "344 alpha: 4.532854830746282 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "310 alpha: 7.119420720848666 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "321 alpha: 10.659029455890138 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "298 alpha: 4.265593725398208 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "380 alpha: 4.980428169145738 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "365 alpha: 6.109653720405668 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "345 alpha: 7.88094201505959 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "332 alpha: 1.9856026923264651 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "356 alpha: 6.05250637019221 \n",
      "alphas 100 \n",
      "nb iter:390 alpha: 4.387638230042088 \n",
      "alphas 26\n",
      " 100 \n",
      "nb iter: 23\n",
      "402 alpha: 3.2861283785462962 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "299 alpha: 4.357716995915474 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "311 alpha: 4.797907259411372 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "423 alpha: 6.106920522851244 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "322 alpha: 8.296901195092643 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "357 alpha: 4.674679610043919 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "414 alpha: 5.6828069428901244 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "391 alpha: 2.269944234366406 \n",
      "alphas 100 \n",
      "nb iter: 96\n",
      "333 alpha: 4.848265828483809 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "381 alpha: 3.5306965703094457 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "444 alpha: 4.4804213832449 \n",
      "alphas 100 \n",
      "nb iter: 84\n",
      "366 alpha: 6.932948795254534 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "432 alpha: 6.562604697147073 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "346 alpha: 3.0205530822474707 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "403 alpha: 7.506069674996083 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "358 alpha: 6.047535378017743 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "382 alpha: 3.9322968715390667 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "392 alpha: 3.6533936891825824 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "424 alpha: 6.046926843970527 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "415 alpha: 6.377982213596346 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "323 alpha: 16.476230804134087 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "334 alpha: 5.303901799609673 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "445 alpha: 1.908800494550659 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "359 alpha: 4.064945145198388 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "433 alpha: 4.924002180275306 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "393 alpha: 3.26287344589978 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "383 alpha: 2.588068482142439 \n",
      "alphas 100 \n",
      "nb iter: 77\n",
      "404 alpha: 5.080775656608288 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "367 alpha: 10.567278802081432 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "425 alpha: 7.434297075292457 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "347 alpha: 4.834099705563062 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "446 alpha: 3.210951350354177 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "416 alpha: 4.350499965997446 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "468 alpha: 3.4485375787229784 \n",
      "alphas 100 \n",
      "nb iter: 83\n",
      "456 alpha: 3.638435528482547 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "368 alpha: 4.20665110926258 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "434 alpha: 5.095006443853871 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "394 alpha: 3.775078258333504 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "335 alpha: 9.358957794084002 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "480 alpha: 5.835194988764218 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "405 alpha: 5.225398547973494 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "417 alpha: 3.6767152480293452 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "492 alpha: 7.072761178610974 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "447 alpha: 5.886920550303326 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "369 alpha: 4.090202568700669 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "504 alpha: 4.400237070147706 \n",
      "alphas 100 \n",
      "nb iter: 82\n",
      "426 alpha: 4.658925674110557 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "457 alpha: 8.270459352576376 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "435 alpha: 3.0850385797954694 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "448 alpha: 5.642722139691624 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "370 alpha: 7.007020531430776 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "395 alpha: 4.750375263257861 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "469 alpha: 10.902825477723614 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "418 alpha: 4.657360629519422 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "481 alpha: 5.384486227715368 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "406 alpha: 9.650498338282356 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "449 alpha: 4.244465745889287 \n",
      "alphas 100 \n",
      "nb iter:371 alpha: 4.965538800511758 \n",
      "alphas 18\n",
      " 100 \n",
      "nb iter: 41\n",
      "505 alpha: 4.067966931113878 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "427 alpha: 6.775639182540836 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "493 alpha: 5.662610334531417 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "436 alpha: 2.3308333423168666 \n",
      "alphas 100 \n",
      "nb iter: 74\n",
      "458 alpha: 9.142857361819656 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "516 alpha: 4.565766323962961 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "450 alpha: 4.932591531151481 \n",
      "alphas 100 \n",
      "nb iter: 60\n",
      "506 alpha: 6.110610637596458 \n",
      "alphas 100 \n",
      "nb iter: 62\n",
      "419 alpha: 8.347373737153497 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "470 alpha: 5.353020611432681 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "437 alpha: 5.349511501522542 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "528 alpha: 3.248508694387495 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "459 alpha: 6.993381550314448 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "494 alpha: 3.9096104080751335 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "428 alpha: 6.256437802215198 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "451 alpha: 1.7282031216743623 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "407 alpha: 8.28625823413555 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "482 alpha: 3.1873775980633727 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "517 alpha: 5.145922248692863 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "507 alpha: 5.287710153638389 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "471 alpha: 6.237077334054261 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "495 alpha: 9.58873754271767 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "429 alpha: 7.363832760151988 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "438 alpha: 5.44475097095001 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "540 alpha: 5.739245490688588 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "529 alpha: 6.864545393613871 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "483 alpha: 4.800463978725944 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "430 alpha: 5.008358337150818 \n",
      "alphas 100 \n",
      "nb iter: 52\n",
      "452 alpha: 5.382725241244272 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "460 alpha: 6.022698759606797 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "508 alpha: 6.4575427465275 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "518 alpha: 6.389979108561539 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "431 alpha: 2.5409360968662993 \n",
      "alphas 100 \n",
      "nb iter: 83\n",
      "552 alpha: 5.716489498987196 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "541 alpha: 25.398869436140018 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "496 alpha: 9.261520247789962 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "472 alpha: 5.232499626792685 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "439 alpha: 12.141704831375552 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "484 alpha: 3.510367569119646 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "553 alpha: 13.968624813281396 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "453 alpha: 4.401633930476862 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "519 alpha: 3.018722052087478 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "461 alpha: 7.744374138009394 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "440 alpha: 2.86466400891407 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "530 alpha: 10.954651061960442 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "542 alpha: 5.951831193277373 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "509 alpha: 8.599154658002293 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "473 alpha: 2.06893546330846 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "462 alpha: 3.7532219204286994 \n",
      "alphas 100 \n",
      "nb iter: 55\n",
      "454 alpha: 6.581713890268542 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "554 alpha: 7.322095363226082 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "485 alpha: 4.069791300812747 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "497 alpha: 12.461204467560112 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "520 alpha: 2.3859202463223017 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "441 alpha: 3.8149374522257684 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "543 alpha: 4.675057476947927 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "510 alpha: 2.0937722757578747 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "474 alpha: 3.15054987952203 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "463 alpha: 9.592240078360089 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "521 alpha: 7.074591989234816 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "531 alpha: 6.107347540838801 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "455 alpha: 7.5924762654953755 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "498 alpha: 8.406121078928154 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "544 alpha: 3.2319636314437967 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "442 alpha: 1.9805957213093819 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "486 alpha: 4.793456018677663 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "475 alpha: 4.283708380211717 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "555 alpha: 8.9161733665845 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "511 alpha: 4.878881591211651 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "522 alpha: 4.720753236805173 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "532 alpha: 8.771135986330249 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "487 alpha: 5.667515039760757 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "464 alpha: 2.2864184916658075 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "443 alpha: 6.828744253154146 \n",
      "alphas 100 \n",
      "nb iter: 62\n",
      "499 alpha: 2.5928756552113956 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "545 alpha: 12.002261129132178 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "476 alpha: 2.6807916170970687 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "512 alpha: 2.615147071661407 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "488 alpha: 5.136884603536741 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "523 alpha: 5.867933621942418 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "500 alpha: 2.546444364908786 \n",
      "alphas 100 \n",
      "nb iter: 109\n",
      "465 alpha: 4.355637610798248 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "546 alpha: 3.6886620849557294 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "477 alpha: 8.332213569821722 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "524 alpha: 1.6752048673462299 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "533 alpha: 4.67536091406044 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "513 alpha: 3.0357122425159604 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "466 alpha: 7.689302091500309 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "489 alpha: 8.036680458360141 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "547 alpha: 3.47491947457301 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "501 alpha: 6.2473047976039116 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "534 alpha: 4.5792405941990895 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "467 alpha: 4.526964824077265 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "478 alpha: 2.7216227197490706 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "490 alpha: 7.690088930328727 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "548 alpha: 5.148336610786209 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "514 alpha: 2.3609833408422327 \n",
      "alphas 100 \n",
      "nb iter: 74\n",
      "502 alpha: 3.0905881956141097 \n",
      "alphas 100 \n",
      "nb iter: 70\n",
      "525 alpha: 6.219688829839692 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "535 alpha: 4.285308558693663 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "549 alpha: 3.9064967335763745 \n",
      "alphas 100 \n",
      "nb iter: 64\n",
      "503 alpha: 2.6037087763886855 \n",
      "alphas 100 \n",
      "nb iter: 55\n",
      "479 alpha: 1.882844934401368 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "515 alpha: 4.078728724569668 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "536 alpha: 6.936576067909455 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "491 alpha: 5.707393709102804 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "526 alpha: 3.56763026065385 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "550 alpha: 5.855208260151467 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "537 alpha: 2.901578931891677 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "538 alpha: 6.022923601141136 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "551 alpha: 6.539149246891095 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "527 alpha: 6.166369768049406 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "539 alpha: 8.044120178883347 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "CPU times: user 1.3 s, sys: 740 ms, total: 2.04 s\n",
      "Wall time: 6min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pool = mp.Pool(processes=12)\n",
    "\n",
    "results = pool.map(fit_lasso, range(nSegments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 98.4397163818663\n"
     ]
    }
   ],
   "source": [
    "mse=0\n",
    "for i in range(len(results)):\n",
    "    mse += np.mean(results[i].mse_path_[np.where(results[i].alphas_ == results[i].alpha_)[0][0]])\n",
    "mse = mse/len(results)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_para = []\n",
    "\n",
    "for i in range(nSegments):\n",
    "    preds_lasso_para.append(results[i].predict(new_X_test))\n",
    "\n",
    "preds_lasso_para = np.array(preds_lasso_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec CV\n",
      "MSE: 104.00187265016078\n",
      "MAE: 6.914467451217082\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec CV\")\n",
    "print(\"MSE:\", mean_squared_error(preds_lasso_para.T.flatten(), new_Y_test.flatten()))\n",
    "print(\"MAE:\", mean_absolute_error(preds_lasso_para.T.flatten(), new_Y_test.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = []\n",
    "for i in range(nSegments):\n",
    "    alphas.append(results[i].alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.084526337056244,\n",
       " 3.639771571180838,\n",
       " 4.212774794975777,\n",
       " 7.105546840004369,\n",
       " 1.7137781032757775,\n",
       " 2.4929855134615146,\n",
       " 5.95599079234283,\n",
       " 5.289910055555876,\n",
       " 2.846152334371196,\n",
       " 4.703959941492476,\n",
       " 4.0372728234516115,\n",
       " 2.574786719796833,\n",
       " 4.977210792290045,\n",
       " 4.592918647445272,\n",
       " 3.468569204320932,\n",
       " 6.8197897634499105,\n",
       " 2.709776357766053,\n",
       " 4.946713685861367,\n",
       " 3.4890256259165366,\n",
       " 3.741689720637754,\n",
       " 3.454374177048441,\n",
       " 8.46920616744094,\n",
       " 4.444658364141705,\n",
       " 2.927301523752698,\n",
       " 3.1754900060253983,\n",
       " 6.539713105100005,\n",
       " 2.4227918828281223,\n",
       " 1.9549463194042063,\n",
       " 6.277555491728509,\n",
       " 5.208615809209246,\n",
       " 4.949979951515281,\n",
       " 13.747151597997036,\n",
       " 9.452542957192504,\n",
       " 10.16963532616385,\n",
       " 4.116136087228222,\n",
       " 5.152953817628634,\n",
       " 6.345250665664159,\n",
       " 1.660749087190992,\n",
       " 5.215507806463355,\n",
       " 4.272303268592268,\n",
       " 4.278929205720682,\n",
       " 3.794146552975768,\n",
       " 4.134406806495898,\n",
       " 3.0782221386233872,\n",
       " 3.592573274798499,\n",
       " 3.6098264693189233,\n",
       " 6.854734802732029,\n",
       " 2.375670382365183,\n",
       " 3.783406929925741,\n",
       " 3.6761143958645897,\n",
       " 9.430561328538177,\n",
       " 5.5553279003960725,\n",
       " 3.9526605681980347,\n",
       " 5.9157136169058715,\n",
       " 2.213750189622374,\n",
       " 2.843750679298778,\n",
       " 3.6563730530083274,\n",
       " 3.1095630008972557,\n",
       " 3.060617385197003,\n",
       " 5.739039297412058,\n",
       " 3.937372268742703,\n",
       " 2.8030974486357496,\n",
       " 4.4427667961511,\n",
       " 5.040516350728668,\n",
       " 4.264850707104959,\n",
       " 5.828663251882224,\n",
       " 3.133876965406974,\n",
       " 4.345247305737133,\n",
       " 1.6928363864938134,\n",
       " 2.576865710223909,\n",
       " 2.8431025452171004,\n",
       " 3.2750089755909797,\n",
       " 2.996388045019106,\n",
       " 2.718346177643803,\n",
       " 1.9322769398537794,\n",
       " 6.551184420718445,\n",
       " 7.9017345259282585,\n",
       " 7.8982907064015615,\n",
       " 3.046665767179689,\n",
       " 4.625736327639632,\n",
       " 4.106854757315888,\n",
       " 1.8408943241565536,\n",
       " 6.043305782312076,\n",
       " 5.832657612266224,\n",
       " 5.935072267512031,\n",
       " 6.717351212141642,\n",
       " 6.111250312717636,\n",
       " 7.476076339168174,\n",
       " 4.277226160607005,\n",
       " 5.183765457583293,\n",
       " 4.012857560983659,\n",
       " 9.603854513139577,\n",
       " 5.034054686266126,\n",
       " 4.169328978164335,\n",
       " 3.2972535062291572,\n",
       " 2.72570729014929,\n",
       " 2.347885296194432,\n",
       " 5.827881386533594,\n",
       " 6.898127249202415,\n",
       " 5.349339707754108,\n",
       " 3.1727977116999604,\n",
       " 4.217193645947244,\n",
       " 3.879742179056338,\n",
       " 5.571113783062043,\n",
       " 4.341576665623308,\n",
       " 2.1767936750231485,\n",
       " 6.278606655526046,\n",
       " 5.8438247921935735,\n",
       " 4.099319692662646,\n",
       " 5.470236358764467,\n",
       " 3.898319456889811,\n",
       " 3.365216332295814,\n",
       " 2.5161575216345957,\n",
       " 7.073496982108314,\n",
       " 2.4808322199937787,\n",
       " 10.853795747018287,\n",
       " 10.626774786474796,\n",
       " 5.783481167732383,\n",
       " 4.250465102251499,\n",
       " 4.646133859658709,\n",
       " 3.7003479321245556,\n",
       " 7.156685115516659,\n",
       " 11.330198891980888,\n",
       " 4.202235669541728,\n",
       " 5.042527225689603,\n",
       " 3.3497093649210696,\n",
       " 4.096782021696342,\n",
       " 5.2745428786491075,\n",
       " 5.8975085835710415,\n",
       " 3.783075649791988,\n",
       " 3.017194538412133,\n",
       " 4.326486887420964,\n",
       " 7.529903470758456,\n",
       " 6.522438074537581,\n",
       " 9.89886565574828,\n",
       " 2.6291164877678708,\n",
       " 3.4965712820843042,\n",
       " 6.08497423965662,\n",
       " 10.16605500492602,\n",
       " 3.0527627474885537,\n",
       " 4.272845421664079,\n",
       " 10.159480567539173,\n",
       " 4.7489260738557215,\n",
       " 21.788317366799056,\n",
       " 4.572889189207551,\n",
       " 5.234562361600242,\n",
       " 2.167229054703404,\n",
       " 3.986839165151797,\n",
       " 4.055910250705207,\n",
       " 3.3865448398311364,\n",
       " 8.591054682890308,\n",
       " 7.62628330875789,\n",
       " 4.028177598889079,\n",
       " 6.054094397765696,\n",
       " 4.633527927322399,\n",
       " 2.3754273912647825,\n",
       " 3.4293762484901094,\n",
       " 3.4125137484932715,\n",
       " 11.128704177390917,\n",
       " 3.7651599839096512,\n",
       " 3.8287395333162273,\n",
       " 2.8372275617854052,\n",
       " 2.7050711612498834,\n",
       " 5.312021611640585,\n",
       " 4.039776755925004,\n",
       " 5.408838707508737,\n",
       " 7.076174775153485,\n",
       " 2.3821353978172706,\n",
       " 4.942968805675946,\n",
       " 2.4862696545552345,\n",
       " 7.120807447230932,\n",
       " 3.6403838495648615,\n",
       " 4.660573281267612,\n",
       " 6.135812953561645,\n",
       " 6.208658111982708,\n",
       " 10.511139821416169,\n",
       " 3.464633095928741,\n",
       " 8.201805370591668,\n",
       " 6.351120420331865,\n",
       " 12.285075698228264,\n",
       " 3.993142109129538,\n",
       " 4.697286781670672,\n",
       " 3.3417923590278207,\n",
       " 5.371076315920631,\n",
       " 6.082130181484012,\n",
       " 3.6673480999663135,\n",
       " 5.865261685167318,\n",
       " 8.863979530994774,\n",
       " 10.063021486261093,\n",
       " 10.908089964494481,\n",
       " 3.987786927930862,\n",
       " 7.756159533468288,\n",
       " 3.874249583393574,\n",
       " 5.688027500042366,\n",
       " 5.053172303234735,\n",
       " 3.03406072635829,\n",
       " 4.613844915269218,\n",
       " 4.577833043385963,\n",
       " 6.805578973854829,\n",
       " 3.930582946757588,\n",
       " 5.294054289503969,\n",
       " 4.60125847444045,\n",
       " 4.93966091662001,\n",
       " 5.081463636508983,\n",
       " 5.475736266392899,\n",
       " 6.085894109927445,\n",
       " 6.5695880434662755,\n",
       " 4.902005134339792,\n",
       " 2.6744497604712687,\n",
       " 1.9682823992271667,\n",
       " 8.0654871526619,\n",
       " 6.49155504170596,\n",
       " 3.549905971547373,\n",
       " 4.407091571665398,\n",
       " 2.3664847962183146,\n",
       " 4.40180789127767,\n",
       " 4.038752211502998,\n",
       " 4.03140156862183,\n",
       " 8.538660250221545,\n",
       " 4.548508758241692,\n",
       " 5.444500046202605,\n",
       " 6.253977303705593,\n",
       " 7.719643064933481,\n",
       " 8.852956661290081,\n",
       " 4.980854700152958,\n",
       " 6.701561938253686,\n",
       " 10.573384897190891,\n",
       " 2.4484466847111785,\n",
       " 1.690848709958574,\n",
       " 6.13796532720254,\n",
       " 3.927488282749939,\n",
       " 3.751942974596258,\n",
       " 3.02462026007141,\n",
       " 2.6287716762987823,\n",
       " 5.531754475885237,\n",
       " 4.281439189258011,\n",
       " 8.640780594777233,\n",
       " 10.611115638140111,\n",
       " 7.877595791225181,\n",
       " 4.286838103123944,\n",
       " 2.469202673678943,\n",
       " 5.244994351830859,\n",
       " 3.5614742803905584,\n",
       " 5.53830209414693,\n",
       " 4.170176854298034,\n",
       " 3.110447144026681,\n",
       " 6.802538087927697,\n",
       " 4.111136230260232,\n",
       " 4.470645431918283,\n",
       " 3.051967639218137,\n",
       " 9.345369504426047,\n",
       " 4.725910627432828,\n",
       " 5.73900881286724,\n",
       " 3.8480554385322643,\n",
       " 1.378272725651118,\n",
       " 14.90411487227676,\n",
       " 8.595714753683563,\n",
       " 2.3679020070359904,\n",
       " 7.27872924719185,\n",
       " 4.593889968486697,\n",
       " 3.2999091553190336,\n",
       " 3.5012753941523393,\n",
       " 9.954076540946117,\n",
       " 3.7831805388470974,\n",
       " 5.4869292503588545,\n",
       " 1.6841607027104288,\n",
       " 5.142584398238851,\n",
       " 6.983102942435173,\n",
       " 2.2846037587285997,\n",
       " 3.8074513319790833,\n",
       " 3.7004115138807645,\n",
       " 2.7230109802038522,\n",
       " 9.689522528017466,\n",
       " 6.327287056046059,\n",
       " 2.3359927269838483,\n",
       " 2.12010795623452,\n",
       " 4.1894250221130935,\n",
       " 2.4201699550977205,\n",
       " 4.578106190182422,\n",
       " 5.421785125011453,\n",
       " 5.162192184999501,\n",
       " 13.25537099474255,\n",
       " 6.051597559449507,\n",
       " 8.222191873019524,\n",
       " 4.146412650720396,\n",
       " 6.204402517802199,\n",
       " 4.30351874615854,\n",
       " 3.687455837297524,\n",
       " 3.8041976216229214,\n",
       " 4.890128174620428,\n",
       " 7.848237856471864,\n",
       " 5.828905965190854,\n",
       " 3.9850493011657595,\n",
       " 5.489797702314994,\n",
       " 6.292493066911329,\n",
       " 3.3871138155465284,\n",
       " 7.407470718715833,\n",
       " 1.8817576961559646,\n",
       " 4.265593725398208,\n",
       " 4.357716995915474,\n",
       " 7.438087613262321,\n",
       " 3.8710433254739725,\n",
       " 2.027318841605087,\n",
       " 4.730104395142373,\n",
       " 7.811984371465538,\n",
       " 9.631988812414173,\n",
       " 6.910412730511078,\n",
       " 2.9808157314173833,\n",
       " 4.593039716863549,\n",
       " 5.094370183266972,\n",
       " 7.119420720848666,\n",
       " 4.797907259411372,\n",
       " 5.6231651157447615,\n",
       " 5.699475325773688,\n",
       " 2.199816411247627,\n",
       " 3.0090710177784534,\n",
       " 6.8301909230632845,\n",
       " 3.307332302618524,\n",
       " 3.683485486205844,\n",
       " 5.487646059807105,\n",
       " 3.826477383302549,\n",
       " 10.659029455890138,\n",
       " 8.296901195092643,\n",
       " 16.476230804134087,\n",
       " 5.054253948367216,\n",
       " 7.803100338864873,\n",
       " 8.813075062207012,\n",
       " 4.3221871542031485,\n",
       " 3.652166132151042,\n",
       " 3.158378220869625,\n",
       " 4.038850181396192,\n",
       " 5.616915828715893,\n",
       " 1.9856026923264651,\n",
       " 4.848265828483809,\n",
       " 5.303901799609673,\n",
       " 9.358957794084002,\n",
       " 2.339797563899256,\n",
       " 2.5360931139857863,\n",
       " 2.403752965728757,\n",
       " 1.8420783711009618,\n",
       " 6.336174729392217,\n",
       " 3.7144227542517574,\n",
       " 3.2985821025587874,\n",
       " 7.354680297092469,\n",
       " 4.532854830746282,\n",
       " 7.88094201505959,\n",
       " 3.0205530822474707,\n",
       " 4.834099705563062,\n",
       " 8.232840589180752,\n",
       " 3.469621990529956,\n",
       " 4.260797329670135,\n",
       " 6.187114963532596,\n",
       " 4.062281341169332,\n",
       " 4.544381688955281,\n",
       " 6.6952511174568095,\n",
       " 3.744813117837485,\n",
       " 6.05250637019221,\n",
       " 4.674679610043919,\n",
       " 6.047535378017743,\n",
       " 4.064945145198388,\n",
       " 1.5480705035370426,\n",
       " 4.631063837528422,\n",
       " 9.6368576024458,\n",
       " 5.047378303838997,\n",
       " 5.790183928741222,\n",
       " 6.109653720405668,\n",
       " 6.932948795254534,\n",
       " 10.567278802081432,\n",
       " 4.20665110926258,\n",
       " 4.090202568700669,\n",
       " 7.007020531430776,\n",
       " 4.965538800511758,\n",
       " 5.369322327407256,\n",
       " 3.8201986467318143,\n",
       " 5.676703714180269,\n",
       " 5.351561056338005,\n",
       " 4.047428641085294,\n",
       " 14.453726558661035,\n",
       " 3.141500592259702,\n",
       " 2.6840611654832656,\n",
       " 4.980428169145738,\n",
       " 3.5306965703094457,\n",
       " 3.9322968715390667,\n",
       " 2.588068482142439,\n",
       " 10.660797069346819,\n",
       " 3.0602491294421137,\n",
       " 9.460195322243955,\n",
       " 7.422411803827621,\n",
       " 1.1045487972554546,\n",
       " 1.70332148586931,\n",
       " 4.387638230042088,\n",
       " 2.269944234366406,\n",
       " 3.6533936891825824,\n",
       " 3.26287344589978,\n",
       " 3.775078258333504,\n",
       " 4.750375263257861,\n",
       " 7.969549590261432,\n",
       " 6.757827518154442,\n",
       " 1.7333838715272953,\n",
       " 3.015267628663085,\n",
       " 3.3987985532599976,\n",
       " 3.483548620310897,\n",
       " 3.2861283785462962,\n",
       " 7.506069674996083,\n",
       " 5.080775656608288,\n",
       " 5.225398547973494,\n",
       " 9.650498338282356,\n",
       " 8.28625823413555,\n",
       " 5.912023796932332,\n",
       " 4.988517073110868,\n",
       " 6.109570690025846,\n",
       " 1.7234007294092364,\n",
       " 3.1712460470256834,\n",
       " 3.9095185155830836,\n",
       " 5.6828069428901244,\n",
       " 6.377982213596346,\n",
       " 4.350499965997446,\n",
       " 3.6767152480293452,\n",
       " 4.657360629519422,\n",
       " 8.347373737153497,\n",
       " 6.384362346338808,\n",
       " 5.102959160076301,\n",
       " 1.6892673342768403,\n",
       " 6.106920522851244,\n",
       " 6.046926843970527,\n",
       " 7.434297075292457,\n",
       " 4.658925674110557,\n",
       " 6.775639182540836,\n",
       " 6.256437802215198,\n",
       " 7.363832760151988,\n",
       " 5.008358337150818,\n",
       " 2.5409360968662993,\n",
       " 6.562604697147073,\n",
       " 4.924002180275306,\n",
       " 5.095006443853871,\n",
       " 3.0850385797954694,\n",
       " 2.3308333423168666,\n",
       " 5.349511501522542,\n",
       " 5.44475097095001,\n",
       " 12.141704831375552,\n",
       " 2.86466400891407,\n",
       " 3.8149374522257684,\n",
       " 1.9805957213093819,\n",
       " 6.828744253154146,\n",
       " 4.4804213832449,\n",
       " 1.908800494550659,\n",
       " 3.210951350354177,\n",
       " 5.886920550303326,\n",
       " 5.642722139691624,\n",
       " 4.244465745889287,\n",
       " 4.932591531151481,\n",
       " 1.7282031216743623,\n",
       " 5.382725241244272,\n",
       " 4.401633930476862,\n",
       " 6.581713890268542,\n",
       " 7.5924762654953755,\n",
       " 3.638435528482547,\n",
       " 8.270459352576376,\n",
       " 9.142857361819656,\n",
       " 6.993381550314448,\n",
       " 6.022698759606797,\n",
       " 7.744374138009394,\n",
       " 3.7532219204286994,\n",
       " 9.592240078360089,\n",
       " 2.2864184916658075,\n",
       " 4.355637610798248,\n",
       " 7.689302091500309,\n",
       " 4.526964824077265,\n",
       " 3.4485375787229784,\n",
       " 10.902825477723614,\n",
       " 5.353020611432681,\n",
       " 6.237077334054261,\n",
       " 5.232499626792685,\n",
       " 2.06893546330846,\n",
       " 3.15054987952203,\n",
       " 4.283708380211717,\n",
       " 2.6807916170970687,\n",
       " 8.332213569821722,\n",
       " 2.7216227197490706,\n",
       " 1.882844934401368,\n",
       " 5.835194988764218,\n",
       " 5.384486227715368,\n",
       " 3.1873775980633727,\n",
       " 4.800463978725944,\n",
       " 3.510367569119646,\n",
       " 4.069791300812747,\n",
       " 4.793456018677663,\n",
       " 5.667515039760757,\n",
       " 5.136884603536741,\n",
       " 8.036680458360141,\n",
       " 7.690088930328727,\n",
       " 5.707393709102804,\n",
       " 7.072761178610974,\n",
       " 5.662610334531417,\n",
       " 3.9096104080751335,\n",
       " 9.58873754271767,\n",
       " 9.261520247789962,\n",
       " 12.461204467560112,\n",
       " 8.406121078928154,\n",
       " 2.5928756552113956,\n",
       " 2.546444364908786,\n",
       " 6.2473047976039116,\n",
       " 3.0905881956141097,\n",
       " 2.6037087763886855,\n",
       " 4.400237070147706,\n",
       " 4.067966931113878,\n",
       " 6.110610637596458,\n",
       " 5.287710153638389,\n",
       " 6.4575427465275,\n",
       " 8.599154658002293,\n",
       " 2.0937722757578747,\n",
       " 4.878881591211651,\n",
       " 2.615147071661407,\n",
       " 3.0357122425159604,\n",
       " 2.3609833408422327,\n",
       " 4.078728724569668,\n",
       " 4.565766323962961,\n",
       " 5.145922248692863,\n",
       " 6.389979108561539,\n",
       " 3.018722052087478,\n",
       " 2.3859202463223017,\n",
       " 7.074591989234816,\n",
       " 4.720753236805173,\n",
       " 5.867933621942418,\n",
       " 1.6752048673462299,\n",
       " 6.219688829839692,\n",
       " 3.56763026065385,\n",
       " 6.166369768049406,\n",
       " 3.248508694387495,\n",
       " 6.864545393613871,\n",
       " 10.954651061960442,\n",
       " 6.107347540838801,\n",
       " 8.771135986330249,\n",
       " 4.67536091406044,\n",
       " 4.5792405941990895,\n",
       " 4.285308558693663,\n",
       " 6.936576067909455,\n",
       " 2.901578931891677,\n",
       " 6.022923601141136,\n",
       " 8.044120178883347,\n",
       " 5.739245490688588,\n",
       " 25.398869436140018,\n",
       " 5.951831193277373,\n",
       " 4.675057476947927,\n",
       " 3.2319636314437967,\n",
       " 12.002261129132178,\n",
       " 3.6886620849557294,\n",
       " 3.47491947457301,\n",
       " 5.148336610786209,\n",
       " 3.9064967335763745,\n",
       " 5.855208260151467,\n",
       " 6.539149246891095,\n",
       " 5.716489498987196,\n",
       " 13.968624813281396,\n",
       " 7.322095363226082,\n",
       " 8.9161733665845]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(1,14,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('alphas_100.txt', np.array(alphas))\n",
    "np.savetxt('alphas_15.txt', np.array(alphas_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7220b8a940>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7220c05a58>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(alphas_15)-np.array(alphas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [a.coef_ for a in results]\n",
    "A = [A]*19\n",
    "A = np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.59049561290934"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risque(A, new_X_train, new_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risque du modèle général: 89.59**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Created!\n",
      "n = 65\n",
      "Z2_train shape: (45, 556, 20)\n",
      "Z2_train shape: (45, 556, 21)\n",
      "Zt_train shape: (5, 45, 556, 5)\n",
      "Zt_test shape: (5, 20, 556, 5)\n",
      "Z Centré !\n",
      "9.671276125623585e-16\n"
     ]
    }
   ],
   "source": [
    "Z2 = []\n",
    "\n",
    "for i in range(int((speedDF.shape[1])/20)):\n",
    "    Z2.append(speedDF.iloc[:,i*20:(i+1)*20].values)\n",
    "\n",
    "print(\"Z Created!\")\n",
    "n = len(Z2)\n",
    "print(\"n =\", n)\n",
    "\n",
    "Z2 = np.array(Z2)\n",
    "\n",
    "Z2_train = Z[:45]\n",
    "Z2_test = Z[45:]\n",
    "\n",
    "\n",
    "print(\"Z2_train shape:\", Z2_train.shape)\n",
    "Z2_train = np.append(Z2_train, np.zeros((45,556,1)), axis=2)\n",
    "print(\"Z2_train shape:\", Z2_train.shape)\n",
    "\n",
    "Z2_test = np.append(Z2_test, np.zeros((20,556,1)), axis=2)\n",
    "\n",
    "\n",
    "Zt_train = []\n",
    "for i in range(5):\n",
    "    Zt_train.append(Z2_train[:,:,i*4:(i+1)*4+1])\n",
    "Zt_train = np.array(Zt_train)\n",
    "print(\"Zt_train shape:\", Zt_train.shape)\n",
    "\n",
    "\n",
    "Zt_test = []\n",
    "for i in range(5):\n",
    "    Zt_test.append(Z2_test[:,:,i*4:(i+1)*4+1])\n",
    "Zt_test = np.array(Zt_test)\n",
    "print(\"Zt_test shape:\", Zt_test.shape)\n",
    "\n",
    "\n",
    "for j in range(5):\n",
    "    M = (1/45)*Zt_train[j].sum(axis=0)\n",
    "\n",
    "    for i in range(45):\n",
    "        Zt_train[j][i] = Zt_train[j][i] - M\n",
    "    for i in range(65-45):\n",
    "        Zt_test[j][i] = Zt_test[j][i] - M\n",
    "    \n",
    "print(\"Z Centré !\")\n",
    "print(Zt_train[1,:,1,3].mean())\n",
    "\n",
    "X_train_time = [X_Y(Zt_train[i])[0] for i in range(4)]\n",
    "X_train_time.append(X_Y(Zt_train[-1][:,:,:-1])[0])\n",
    "Y_train_time = [X_Y(Zt_train[i])[1] for i in range(4)]\n",
    "Y_train_time.append(X_Y(Zt_train[-1][:,:,:-1])[1])\n",
    "\n",
    "X_test_time = [X_Y(Zt_test[i])[0] for i in range(4)]\n",
    "X_test_time.append(X_Y(Zt_test[-1][:,:,:-1])[0])\n",
    "Y_test_time = [X_Y(Zt_test[i])[1] for i in range(4)]\n",
    "Y_test_time.append(X_Y(Zt_test[-1][:,:,:-1])[1])\n",
    "#X_train_time, Y_train_time  = np.array([X_Y(Zt_train[i]) for i in range(5)])[:,0], np.array([X_Y(Zt_train[i]) for i in range(5)])[:,1]\n",
    "#print(X_train_time.shape, Y_train_time.shape)\n",
    "#X_test_time, Y_test_time = np.array([X_Y(Zt_test[i]) for i in range(5)])[:,0], np.array([X_Y(Zt_test[i]) for i in range(5)])[:,1]\n",
    "#print(X_test_time.shape, Y_test_time.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention X_train_time et cie listes de taille 5 avec les 4 premiers de shape 180,556 et le dernier de shape 135, 556**\n",
    "\n",
    "**Pour test_time c'est 80,556 et 60,556**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lasso_time = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments*5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lasso_time(i):\n",
    "    j = i % 556\n",
    "    k = i // 556\n",
    "    A_lasso_time[i].fit(X_train_time[k], Y_train_time[k][:, j])\n",
    "    print(\"timeframe:\", k, \"section:\", j, \"alpha:\", A_lasso_time[i].alpha_)\n",
    "    return A_lasso_time[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeframe: 0 section: 14 alpha: 9.158871517226588\n",
      "timeframe: 0 section: 308 alpha: 24.836508203648474\n",
      "timeframe: 1 section: 137 alpha: 30.13337522216871\n",
      "timeframe: 0 section: 105 alpha: 11.20191709682916\n",
      "timeframe: 0 section: 511 alpha: 10.054632219650879\n",
      "timeframe: 1 section: 18 alpha: 23.302316946114285\n",
      "timeframe: 0 section: 49 alpha: 9.031644436332076\n",
      "timeframe: 1 section: 67 alpha: 6.230083515277103\n",
      "timeframe: 0 section: 273 alpha: 18.960492308063678\n",
      "timeframe: 0 section: 504 alpha: 9.109787529005859\n",
      "timeframe: 0 section: 35 alpha: 7.4862650145321625\n",
      "timeframe: 0 section: 315 alpha: 86.63014077704382\n",
      "timeframe: 1 section: 123 alpha: 34.990680567941226\n",
      "timeframe: 1 section: 60 alpha: 18.53658055619706\n",
      "timeframe: 0 section: 77 alpha: 23.695614023762943\n",
      "timeframe: 0 section: 448 alpha: 8.792979834362272\n",
      "timeframe: 0 section: 364 alpha: 25.135349386754502\n",
      "timeframe: 0 section: 462 alpha: 95.47259606565194\n",
      "timeframe: 0 section: 126 alpha: 15.512514094954684\n",
      "timeframe: 0 section: 427 alpha: 49.051898010079\n",
      "timeframe: 0 section: 217 alpha: 28.964931102313738\n",
      "timeframe: 0 section: 168 alpha: 24.35117283677002\n",
      "timeframe: 0 section: 294 alpha: 40.61818043495898\n",
      "timeframe: 0 section: 455 alpha: 12.15787134325916\n",
      "timeframe: 0 section: 385 alpha: 8.381382289606014\n",
      "timeframe: 0 section: 63 alpha: 25.895694977806997\n",
      "timeframe: 0 section: 546 alpha: 25.31034410082712\n",
      "timeframe: 0 section: 483 alpha: 30.666727553683742\n",
      "timeframe: 0 section: 413 alpha: 16.479478463351693\n",
      "timeframe: 0 section: 553 alpha: 30.72078418620627\n",
      "timeframe: 0 section: 420 alpha: 38.49855942269639\n",
      "timeframe: 0 section: 56 alpha: 15.875465897111857\n",
      "timeframe: 0 section: 336 alpha: 14.76241020221101\n",
      "timeframe: 0 section: 154 alpha: 31.47028808774156\n",
      "timeframe: 0 section: 203 alpha: 21.817526763137586\n",
      "timeframe: 0 section: 518 alpha: 15.59985945694936\n",
      "timeframe: 0 section: 532 alpha: 19.357386300566443\n",
      "timeframe: 0 section: 252 alpha: 33.00011969446421\n",
      "timeframe: 0 section: 539 alpha: 20.00935986219533\n",
      "timeframe: 0 section: 441 alpha: 30.420548760076965\n",
      "timeframe: 0 section: 343 alpha: 23.317749814947902\n",
      "timeframe: 0 section: 406 alpha: 24.401749022519635\n",
      "timeframe: 0 section: 357 alpha: 40.06566547072606\n",
      "timeframe: 0 section: 84 alpha: 40.10821278309014\n",
      "timeframe: 0 section: 434 alpha: 28.85704074009336\n",
      "timeframe: 0 section: 28 alpha: 24.781444556095614\n",
      "timeframe: 0 section: 287 alpha: 14.360243596526594\n",
      "timeframe: 0 section: 189 alpha: 35.3676626441784\n",
      "timeframe: 0 section: 42 alpha: 8.27282666094049\n",
      "timeframe: 0 section: 497 alpha: 35.188371503957846\n",
      "timeframe: 0 section: 266 alpha: 18.220963319033977\n",
      "timeframe: 0 section: 70 alpha: 9.397468523086212\n",
      "timeframe: 0 section: 196 alpha: 44.76797158890647\n",
      "timeframe: 0 section: 175 alpha: 16.36318022653274\n",
      "timeframe: 0 section: 350 alpha: 15.67366218860942\n",
      "timeframe: 0 section: 392 alpha: 19.966759563703217\n",
      "timeframe: 0 section: 98 alpha: 44.59817162167\n",
      "timeframe: 0 section: 161 alpha: 36.70444559137205\n",
      "timeframe: 0 section: 147 alpha: 14.56740133269027\n",
      "timeframe: 0 section: 91 alpha: 20.267523341117332\n",
      "timeframe: 0 section: 21 alpha: 7.004073901688471\n",
      "timeframe: 0 section: 469 alpha: 31.96677649798148\n",
      "timeframe: 1 section: 116 alpha: 27.314891300467234\n",
      "timeframe: 0 section: 280 alpha: 13.718746366938753\n",
      "timeframe: 0 section: 210 alpha: 29.82713937338252\n",
      "timeframe: 0 section: 371 alpha: 1.604342871406509\n",
      "timeframe: 0 section: 238 alpha: 30.114727624474632\n",
      "timeframe: 0 section: 133 alpha: 41.8881063139285\n",
      "timeframe: 0 section: 322 alpha: 41.66863282050503\n",
      "timeframe: 1 section: 39 alpha: 21.52618622796296\n",
      "timeframe: 0 section: 399 alpha: 15.877646840134522\n",
      "timeframe: 0 section: 119 alpha: 19.05883763214897\n",
      "timeframe: 1 section: 25 alpha: 29.862113626567638\n",
      "timeframe: 0 section: 301 alpha: 11.438230090033908\n",
      "timeframe: 0 section: 182 alpha: 27.914849411163335\n",
      "timeframe: 1 section: 53 alpha: 18.23619118891072\n",
      "timeframe: 0 section: 7 alpha: 15.156751178802585\n",
      "timeframe: 1 section: 102 alpha: 29.78252233632866\n",
      "timeframe: 0 section: 231 alpha: 26.026387695847767\n",
      "timeframe: 0 section: 378 alpha: 9.620199083733233\n",
      "timeframe: 1 section: 95 alpha: 11.466903673095912\n",
      "timeframe: 1 section: 81 alpha: 4.113475423524585\n",
      "timeframe: 0 section: 140 alpha: 59.059078670809335\n",
      "timeframe: 0 section: 329 alpha: 7.667232543584663\n",
      "timeframe: 1 section: 88 alpha: 29.47693188432084\n",
      "timeframe: 0 section: 490 alpha: 30.79034821868498\n",
      "timeframe: 0 section: 224 alpha: 29.05083977425613\n",
      "timeframe: 0 section: 112 alpha: 15.088044319833617\n",
      "timeframe: 0 section: 476 alpha: 39.36956490711738\n",
      "timeframe: 0 section: 525 alpha: 39.604707424637105\n",
      "timeframe: 0 section: 0 alpha: 22.943930153447113\n",
      "timeframe: 0 section: 15 alpha: 38.34340940596447\n",
      "timeframe: 0 section: 259 alpha: 44.79649356091141\n",
      "timeframe: 1 section: 32 alpha: 64.47326260971143\n",
      "timeframe: 0 section: 245 alpha: 5.956289043983178\n",
      "timeframe: 1 section: 46 alpha: 17.926097691392016\n",
      "timeframe: 0 section: 36 alpha: 5.623924664728957\n",
      "timeframe: 1 section: 4 alpha: 14.02864569752742\n",
      "timeframe: 0 section: 57 alpha: 16.92232923431794\n",
      "timeframe: 1 section: 11 alpha: 22.67535427348642\n",
      "timeframe: 1 section: 109 alpha: 17.08589289364362\n",
      "timeframe: 1 section: 74 alpha: 5.254865786927431\n",
      "timeframe: 0 section: 50 alpha: 55.295368087267235\n",
      "timeframe: 0 section: 71 alpha: 122.74152609796735\n",
      "timeframe: 0 section: 43 alpha: 13.10629448837723\n",
      "timeframe: 0 section: 78 alpha: 27.37261046371649\n",
      "timeframe: 1 section: 130 alpha: 28.23910034567773\n",
      "timeframe: 0 section: 1 alpha: 22.079713791276028\n",
      "timeframe: 0 section: 29 alpha: 17.475320755325008\n",
      "timeframe: 0 section: 64 alpha: 21.354698546110235\n",
      "timeframe: 0 section: 8 alpha: 27.17365659235975\n",
      "timeframe: 0 section: 22 alpha: 13.310473308761356\n",
      "timeframe: 0 section: 225 alpha: 28.76960514841055\n",
      "timeframe: 0 section: 183 alpha: 22.54216099337072\n",
      "timeframe: 0 section: 176 alpha: 20.73868002598715\n",
      "timeframe: 0 section: 211 alpha: 34.45948565877267\n",
      "timeframe: 0 section: 323 alpha: 24.0984086768311\n",
      "timeframe: 0 section: 309 alpha: 14.553224799565715\n",
      "timeframe: 1 section: 5 alpha: 10.621699746518738\n",
      "timeframe: 0 section: 449 alpha: 57.84890813452603\n",
      "timeframe: 0 section: 477 alpha: 33.714283953584676\n",
      "timeframe: 0 section: 372 alpha: 74.48092694420771\n",
      "timeframe: 0 section: 232 alpha: 10.263700512520408\n",
      "timeframe: 0 section: 134 alpha: 20.519672868719656\n",
      "timeframe: 0 section: 519 alpha: 29.35165016898342\n",
      "timeframe: 0 section: 456 alpha: 32.47684133166833\n",
      "timeframe: 0 section: 393 alpha: 16.357896981840973\n",
      "timeframe: 0 section: 330 alpha: 6.7387165813464796\n",
      "timeframe: 0 section: 463 alpha: 51.35493139380583\n",
      "timeframe: 0 section: 435 alpha: 8.283631390031221\n",
      "timeframe: 0 section: 344 alpha: 12.225527223610394\n",
      "timeframe: 0 section: 470 alpha: 13.134909851397104\n",
      "timeframe: 0 section: 120 alpha: 11.059055939130715\n",
      "timeframe: 0 section: 386 alpha: 23.408481218419105\n",
      "timeframe: 0 section: 547 alpha: 15.348945966682663\n",
      "timeframe: 1 section: 12 alpha: 39.60433858681448\n",
      "timeframe: 0 section: 316 alpha: 29.7498311902283\n",
      "timeframe: 1 section: 131 alpha: 20.213491106121392\n",
      "timeframe: 0 section: 162 alpha: 13.333227330086297\n",
      "timeframe: 1 section: 124 alpha: 23.58919565841936\n",
      "timeframe: 1 section: 117 alpha: 22.313457898018985\n",
      "timeframe: 0 section: 92 alpha: 27.684270442017645\n",
      "timeframe: 1 section: 19 alpha: 23.779354525880223\n",
      "timeframe: 0 section: 274 alpha: 11.359216903455305\n",
      "timeframe: 0 section: 533 alpha: 19.63231749788409\n",
      "timeframe: 0 section: 505 alpha: 8.72622503206388\n",
      "timeframe: 0 section: 442 alpha: 8.558310727035892\n",
      "timeframe: 0 section: 85 alpha: 29.77333403045389\n",
      "timeframe: 0 section: 23 alpha: 14.110257963801057\n",
      "timeframe: 0 section: 218 alpha: 23.77502919760389\n",
      "timeframe: 0 section: 204 alpha: 15.086561711825157\n",
      "timeframe: 1 section: 33 alpha: 53.7790570732634\n",
      "timeframe: 0 section: 79 alpha: 26.943190202586283\n",
      "timeframe: 0 section: 16 alpha: 8.75256515951086\n",
      "timeframe: 0 section: 295 alpha: 13.346042110474256\n",
      "timeframe: 0 section: 155 alpha: 26.29764796802295\n",
      "timeframe: 0 section: 414 alpha: 26.037186463492876\n",
      "timeframe: 0 section: 197 alpha: 28.90426271708546\n",
      "timeframe: 0 section: 30 alpha: 16.5275373428668\n",
      "timeframe: 0 section: 428 alpha: 25.924423299676654\n",
      "timeframe: 0 section: 400 alpha: 21.257910486559982\n",
      "timeframe: 1 section: 61 alpha: 18.109458167145807\n",
      "timeframe: 0 section: 58 alpha: 59.04895088174379\n",
      "timeframe: 0 section: 421 alpha: 29.956541440115377\n",
      "timeframe: 0 section: 358 alpha: 15.577342621660668\n",
      "timeframe: 0 section: 302 alpha: 15.89062711688227\n",
      "timeframe: 0 section: 106 alpha: 19.99772090779075\n",
      "timeframe: 0 section: 99 alpha: 28.238002097427945\n",
      "timeframe: 0 section: 9 alpha: 8.550551807916873\n",
      "timeframe: 0 section: 484 alpha: 8.223003405763567\n",
      "timeframe: 0 section: 127 alpha: 23.449436058499092\n",
      "timeframe: 1 section: 68 alpha: 6.810349056631543\n",
      "timeframe: 0 section: 169 alpha: 3.508074823491784\n",
      "timeframe: 0 section: 554 alpha: 58.217829307117725\n",
      "timeframe: 0 section: 337 alpha: 12.080477441267954\n",
      "timeframe: 0 section: 113 alpha: 29.120599158132794\n",
      "timeframe: 0 section: 288 alpha: 19.275226408990083\n",
      "timeframe: 0 section: 491 alpha: 36.82391425723486\n",
      "timeframe: 0 section: 351 alpha: 16.108696617812313\n",
      "timeframe: 0 section: 190 alpha: 25.182589985580833\n",
      "timeframe: 0 section: 2 alpha: 24.217410007403203\n",
      "timeframe: 1 section: 110 alpha: 23.82677997399992\n",
      "timeframe: 1 section: 82 alpha: 25.707437716170496\n",
      "timeframe: 0 section: 246 alpha: 29.1003440863672\n",
      "timeframe: 0 section: 260 alpha: 20.09691022908788\n",
      "timeframe: 0 section: 498 alpha: 26.30134991477245\n",
      "timeframe: 1 section: 40 alpha: 15.49632176186505\n",
      "timeframe: 1 section: 138 alpha: 67.1385056754561\n",
      "timeframe: 0 section: 37 alpha: 11.156103835253735\n",
      "timeframe: 0 section: 526 alpha: 24.02360244751626\n",
      "timeframe: 0 section: 379 alpha: 16.267454670380964\n",
      "timeframe: 0 section: 253 alpha: 17.714660074758378\n",
      "timeframe: 0 section: 540 alpha: 20.973842729168265\n",
      "timeframe: 0 section: 512 alpha: 16.722531721956223\n",
      "timeframe: 0 section: 51 alpha: 12.304418374541179\n",
      "timeframe: 0 section: 141 alpha: 46.79268596347055\n",
      "timeframe: 1 section: 26 alpha: 12.301505741184604\n",
      "timeframe: 0 section: 239 alpha: 25.409099839253635\n",
      "timeframe: 0 section: 148 alpha: 13.265886005643067\n",
      "timeframe: 1 section: 47 alpha: 5.626759593921438\n",
      "timeframe: 1 section: 75 alpha: 30.85845783557586\n",
      "timeframe: 0 section: 267 alpha: 59.05525315426707\n",
      "timeframe: 0 section: 450 alpha: 13.314295639610158\n",
      "timeframe: 0 section: 226 alpha: 20.6927305154695\n",
      "timeframe: 0 section: 44 alpha: 19.63949487444136\n",
      "timeframe: 0 section: 72 alpha: 10.140228361387864\n",
      "timeframe: 1 section: 96 alpha: 17.94879359873126\n",
      "timeframe: 1 section: 54 alpha: 11.465664888604923\n",
      "timeframe: 0 section: 365 alpha: 22.69154498615258\n",
      "timeframe: 1 section: 89 alpha: 33.75763746422529\n",
      "timeframe: 0 section: 233 alpha: 8.999124707499982\n",
      "timeframe: 0 section: 373 alpha: 5.3077427022161485\n",
      "timeframe: 0 section: 310 alpha: 43.21153227186119\n",
      "timeframe: 1 section: 103 alpha: 39.2463836502861\n",
      "timeframe: 0 section: 548 alpha: 13.81120332552261\n",
      "timeframe: 0 section: 65 alpha: 27.72675348738669\n",
      "timeframe: 0 section: 184 alpha: 26.157595900781416\n",
      "timeframe: 0 section: 324 alpha: 52.13916572211123\n",
      "timeframe: 0 section: 436 alpha: 80.38165208187422\n",
      "timeframe: 0 section: 407 alpha: 25.448208882748354\n",
      "timeframe: 0 section: 135 alpha: 11.846905104703298\n",
      "timeframe: 0 section: 177 alpha: 23.682370401630738\n",
      "timeframe: 0 section: 275 alpha: 6.50230760266381\n",
      "timeframe: 0 section: 93 alpha: 8.906004904289397\n",
      "timeframe: 0 section: 317 alpha: 14.472604612850024\n",
      "timeframe: 0 section: 212 alpha: 27.664983871623427\n",
      "timeframe: 0 section: 464 alpha: 15.134099818195127\n",
      "timeframe: 0 section: 457 alpha: 19.966510928112317\n",
      "timeframe: 0 section: 471 alpha: 25.79022940673524\n",
      "timeframe: 0 section: 163 alpha: 4.122836085468986\n",
      "timeframe: 0 section: 478 alpha: 16.386838338346717\n",
      "timeframe: 0 section: 520 alpha: 17.80641181028696\n",
      "timeframe: 0 section: 394 alpha: 28.05952599351658\n",
      "timeframe: 0 section: 281 alpha: 26.61913415521561\n",
      "timeframe: 0 section: 331 alpha: 10.69393703975937\n",
      "timeframe: 0 section: 506 alpha: 17.587388503550862\n",
      "timeframe: 0 section: 10 alpha: 75.00999015876808\n",
      "timeframe: 0 section: 86 alpha: 15.754731380881644\n",
      "timeframe: 0 section: 443 alpha: 31.456448198855494\n",
      "timeframe: 0 section: 345 alpha: 29.974267220450745\n",
      "timeframe: 1 section: 6 alpha: 19.911276711494132\n",
      "timeframe: 0 section: 121 alpha: 40.91467183333673\n",
      "timeframe: 0 section: 198 alpha: 8.988125197907099\n",
      "timeframe: 0 section: 17 alpha: 29.316997530717046\n",
      "timeframe: 0 section: 205 alpha: 41.66578215263697\n",
      "timeframe: 0 section: 387 alpha: 25.22265193518089\n",
      "timeframe: 0 section: 114 alpha: 10.581308882648928\n",
      "timeframe: 0 section: 534 alpha: 23.854469878803087\n",
      "timeframe: 0 section: 80 alpha: 22.292901974489094\n",
      "timeframe: 0 section: 401 alpha: 29.94760461427225\n",
      "timeframe: 0 section: 52 alpha: 2.5491821821038485\n",
      "timeframe: 0 section: 296 alpha: 22.822404962133827\n",
      "timeframe: 0 section: 415 alpha: 38.46734611613544\n",
      "timeframe: 0 section: 24 alpha: 4.6311176875927345\n",
      "timeframe: 1 section: 20 alpha: 15.457394655919215\n",
      "timeframe: 0 section: 100 alpha: 16.297568196070813\n",
      "timeframe: 0 section: 492 alpha: 14.648471352811818\n",
      "timeframe: 0 section: 359 alpha: 12.008319394409298\n",
      "timeframe: 0 section: 107 alpha: 30.449150228880487\n",
      "timeframe: 0 section: 170 alpha: 37.07137992243559\n",
      "timeframe: 1 section: 132 alpha: 15.644385459281107\n",
      "timeframe: 0 section: 261 alpha: 12.29063404944488\n",
      "timeframe: 0 section: 191 alpha: 27.07271093119248\n",
      "timeframe: 0 section: 3 alpha: 45.63852985048973\n",
      "timeframe: 0 section: 513 alpha: 14.154797825670341\n",
      "timeframe: 0 section: 338 alpha: 13.317123021097034\n",
      "timeframe: 1 section: 13 alpha: 32.130273261145966\n",
      "timeframe: 0 section: 31 alpha: 24.171480566403012\n",
      "timeframe: 1 section: 34 alpha: 9.241136902175448\n",
      "timeframe: 0 section: 380 alpha: 41.45923028375866\n",
      "timeframe: 0 section: 422 alpha: 11.915157261361566\n",
      "timeframe: 0 section: 429 alpha: 58.257769332522294\n",
      "timeframe: 0 section: 128 alpha: 24.994454421653256\n",
      "timeframe: 0 section: 374 alpha: 17.854886515887554\n",
      "timeframe: 0 section: 555 alpha: 29.083917131644686\n",
      "timeframe: 0 section: 303 alpha: 34.18384312367895\n",
      "timeframe: 0 section: 38 alpha: 73.16749630775952\n",
      "timeframe: 0 section: 247 alpha: 20.227131034642127\n",
      "timeframe: 0 section: 254 alpha: 28.009961307842737\n",
      "timeframe: 0 section: 240 alpha: 15.919571364775567\n",
      "timeframe: 0 section: 45 alpha: 27.761572733273386\n",
      "timeframe: 0 section: 541 alpha: 27.52889599630964\n",
      "timeframe: 0 section: 59 alpha: 18.42898554119147\n",
      "timeframe: 0 section: 73 alpha: 16.652273856230128\n",
      "timeframe: 0 section: 499 alpha: 16.247833368382313\n",
      "timeframe: 0 section: 219 alpha: 9.06639567965265\n",
      "timeframe: 0 section: 527 alpha: 10.197701111800066\n",
      "timeframe: 0 section: 485 alpha: 15.542369513430257\n",
      "timeframe: 0 section: 149 alpha: 19.818390932778307\n",
      "timeframe: 1 section: 125 alpha: 22.291789527612536\n",
      "timeframe: 1 section: 55 alpha: 18.916294745617304\n",
      "timeframe: 0 section: 289 alpha: 19.77311008708123\n",
      "timeframe: 0 section: 185 alpha: 18.788063980215902\n",
      "timeframe: 0 section: 268 alpha: 9.357044397321923\n",
      "timeframe: 0 section: 227 alpha: 15.087601893882612\n",
      "timeframe: 0 section: 451 alpha: 9.432042878129934\n",
      "timeframe: 1 section: 83 alpha: 19.164517202053965\n",
      "timeframe: 1 section: 118 alpha: 26.378304418341312\n",
      "timeframe: 1 section: 139 alpha: 32.607749936715514\n",
      "timeframe: 1 section: 76 alpha: 79.05759487495897\n",
      "timeframe: 0 section: 549 alpha: 2.1821508769560327\n",
      "timeframe: 0 section: 352 alpha: 19.992369147477923\n",
      "timeframe: 0 section: 142 alpha: 18.2751723447653\n",
      "timeframe: 0 section: 156 alpha: 26.93666510595105\n",
      "timeframe: 0 section: 318 alpha: 15.622491963920872\n",
      "timeframe: 0 section: 66 alpha: 14.473678461013426\n",
      "timeframe: 1 section: 111 alpha: 19.1117776759859\n",
      "timeframe: 1 section: 41 alpha: 35.017684524936975\n",
      "timeframe: 0 section: 366 alpha: 36.39202782511218\n",
      "timeframe: 0 section: 164 alpha: 12.297781269774962\n",
      "timeframe: 1 section: 62 alpha: 18.797030081684976\n",
      "timeframe: 0 section: 213 alpha: 17.697339366825787\n",
      "timeframe: 0 section: 311 alpha: 40.81803298734798\n",
      "timeframe: 0 section: 408 alpha: 39.77331073667344\n",
      "timeframe: 0 section: 507 alpha: 88.64328998640032\n",
      "timeframe: 0 section: 234 alpha: 40.07663765927286\n",
      "timeframe: 0 section: 94 alpha: 21.795617909282335\n",
      "timeframe: 1 section: 27 alpha: 18.80160335360486\n",
      "timeframe: 0 section: 122 alpha: 22.297137104743577\n",
      "timeframe: 0 section: 276 alpha: 14.784297375441975\n",
      "timeframe: 1 section: 104 alpha: 23.34571393793821\n",
      "timeframe: 1 section: 48 alpha: 12.618598159246046\n",
      "timeframe: 1 section: 69 alpha: 11.192040446440512\n",
      "timeframe: 0 section: 332 alpha: 15.995368829775291\n",
      "timeframe: 0 section: 465 alpha: 40.17202709864032\n",
      "timeframe: 0 section: 458 alpha: 32.97192976612135\n",
      "timeframe: 0 section: 178 alpha: 33.01993940683001\n",
      "timeframe: 0 section: 325 alpha: 34.47501391178016\n",
      "timeframe: 0 section: 479 alpha: 12.297820470610217\n",
      "timeframe: 0 section: 437 alpha: 20.791263585891798\n",
      "timeframe: 1 section: 90 alpha: 38.158634611924555\n",
      "timeframe: 0 section: 521 alpha: 44.175433814935936\n",
      "timeframe: 0 section: 282 alpha: 36.06755778477166\n",
      "timeframe: 0 section: 108 alpha: 15.69049171474496\n",
      "timeframe: 0 section: 388 alpha: 12.730093246437686\n",
      "timeframe: 0 section: 87 alpha: 47.788657376930566\n",
      "timeframe: 0 section: 18 alpha: 5.333857113449612\n",
      "timeframe: 0 section: 444 alpha: 16.699969251808998\n",
      "timeframe: 0 section: 199 alpha: 13.193533217675032\n",
      "timeframe: 1 section: 35 alpha: 30.531133586893464\n",
      "timeframe: 0 section: 472 alpha: 37.89983941340852\n",
      "timeframe: 0 section: 136 alpha: 20.601022636277577\n",
      "timeframe: 1 section: 97 alpha: 22.2318726096383\n",
      "timeframe: 0 section: 206 alpha: 22.23871260271625\n",
      "timeframe: 0 section: 402 alpha: 23.039522043207867\n",
      "timeframe: 0 section: 430 alpha: 4.362116102641049\n",
      "timeframe: 0 section: 60 alpha: 3.4874140904304594\n",
      "timeframe: 0 section: 81 alpha: 9.781111926171796\n",
      "timeframe: 0 section: 4 alpha: 0.8521235866326837\n",
      "timeframe: 0 section: 395 alpha: 29.510890732152927\n",
      "timeframe: 0 section: 53 alpha: 29.621952177591957\n",
      "timeframe: 0 section: 339 alpha: 9.977241017663962\n",
      "timeframe: 0 section: 115 alpha: 74.7703822054687\n",
      "timeframe: 0 section: 39 alpha: 12.031588595372716\n",
      "timeframe: 0 section: 192 alpha: 15.974558149112411\n",
      "timeframe: 1 section: 14 alpha: 17.058596065057866\n",
      "timeframe: 0 section: 514 alpha: 19.67920231589246\n",
      "timeframe: 0 section: 535 alpha: 26.783791897705374\n",
      "timeframe: 0 section: 297 alpha: 11.505398348987239\n",
      "timeframe: 0 section: 493 alpha: 37.18610409313447\n",
      "timeframe: 1 section: 56 alpha: 14.839924043756211\n",
      "timeframe: 0 section: 346 alpha: 20.71330303585436\n",
      "timeframe: 0 section: 360 alpha: 8.077384839017691\n",
      "timeframe: 0 section: 269 alpha: 66.98823927076197\n",
      "timeframe: 0 section: 129 alpha: 30.824812667886906\n",
      "timeframe: 0 section: 423 alpha: 25.048559171950718\n",
      "timeframe: 0 section: 416 alpha: 28.102045915049345\n",
      "timeframe: 0 section: 101 alpha: 29.65951122496461\n",
      "timeframe: 0 section: 542 alpha: 25.556875987432427\n",
      "timeframe: 1 section: 133 alpha: 48.50826833160386\n",
      "timeframe: 0 section: 25 alpha: 34.94624806739945\n",
      "timeframe: 0 section: 500 alpha: 11.280245496751549\n",
      "timeframe: 0 section: 486 alpha: 13.180445325764229\n",
      "timeframe: 0 section: 262 alpha: 33.096812113302555\n",
      "timeframe: 0 section: 74 alpha: 14.252889823690689\n",
      "timeframe: 0 section: 248 alpha: 13.93443047481191\n",
      "timeframe: 0 section: 11 alpha: 17.335455558122117\n",
      "timeframe: 0 section: 32 alpha: 59.389558145323726\n",
      "timeframe: 0 section: 67 alpha: 2.9181537436306346\n",
      "timeframe: 0 section: 381 alpha: 19.588233791165976\n",
      "timeframe: 0 section: 319 alpha: 26.259642780542688\n",
      "timeframe: 0 section: 46 alpha: 14.305882842093116\n",
      "timeframe: 0 section: 150 alpha: 27.167390035442587\n",
      "timeframe: 1 section: 21 alpha: 24.416764016253893\n",
      "timeframe: 0 section: 143 alpha: 17.569760189845454\n",
      "timeframe: 0 section: 304 alpha: 70.25733988309656\n",
      "timeframe: 0 section: 528 alpha: 26.885216448665282\n",
      "timeframe: 0 section: 290 alpha: 19.236484675028446\n",
      "timeframe: 0 section: 171 alpha: 23.70611333614323\n",
      "timeframe: 1 section: 7 alpha: 35.32328424503377\n",
      "timeframe: 0 section: 220 alpha: 22.880924392927994\n",
      "timeframe: 0 section: 375 alpha: 13.472860149160427\n",
      "timeframe: 0 section: 353 alpha: 20.768984804300803\n",
      "timeframe: 1 section: 49 alpha: 13.69203789556921\n",
      "timeframe: 0 section: 241 alpha: 26.967255170966503\n",
      "timeframe: 0 section: 186 alpha: 25.78138685218782\n",
      "timeframe: 0 section: 228 alpha: 37.75090335453348\n",
      "timeframe: 0 section: 157 alpha: 17.387450731591553\n",
      "timeframe: 1 section: 126 alpha: 10.77244172307615\n",
      "timeframe: 0 section: 123 alpha: 55.47865001072553\n",
      "timeframe: 0 section: 550 alpha: 29.65638538891922\n",
      "timeframe: 0 section: 452 alpha: 37.87984534846002\n",
      "timeframe: 1 section: 105 alpha: 15.1660614431096\n",
      "timeframe: 0 section: 367 alpha: 24.962721067434273\n",
      "timeframe: 1 section: 77 alpha: 26.928059515716374\n",
      "timeframe: 0 section: 255 alpha: 92.62678336139977\n",
      "timeframe: 0 section: 277 alpha: 64.37807089419051\n",
      "timeframe: 0 section: 522 alpha: 12.48452883362626\n",
      "timeframe: 0 section: 480 alpha: 8.137920129755669\n",
      "timeframe: 0 section: 409 alpha: 25.68921561520709\n",
      "timeframe: 0 section: 459 alpha: 60.009281702311135\n",
      "timeframe: 0 section: 389 alpha: 4.138461975957951\n",
      "timeframe: 0 section: 19 alpha: 9.616290303303197\n",
      "timeframe: 0 section: 95 alpha: 10.725264690777745\n",
      "timeframe: 0 section: 137 alpha: 0.8610270731158133\n",
      "timeframe: 0 section: 431 alpha: 7.146127336676015\n",
      "timeframe: 1 section: 0 alpha: 25.09782652553778\n",
      "timeframe: 1 section: 42 alpha: 10.96036202104601\n",
      "timeframe: 0 section: 445 alpha: 6.423621548602475\n",
      "timeframe: 0 section: 508 alpha: 12.368546643304995\n",
      "timeframe: 0 section: 214 alpha: 17.473863217263546\n",
      "timeframe: 0 section: 438 alpha: 23.473023089093243\n",
      "timeframe: 1 section: 36 alpha: 43.889382374478515\n",
      "timeframe: 0 section: 333 alpha: 14.813063678288644\n",
      "timeframe: 1 section: 84 alpha: 40.42353331683037\n",
      "timeframe: 0 section: 312 alpha: 25.146662239087632\n",
      "timeframe: 0 section: 283 alpha: 50.30391065491235\n",
      "timeframe: 0 section: 235 alpha: 26.86304149934419\n",
      "timeframe: 0 section: 179 alpha: 13.57037887590443\n",
      "timeframe: 1 section: 119 alpha: 12.141523391168473\n",
      "timeframe: 0 section: 473 alpha: 9.665291139719905\n",
      "timeframe: 1 section: 140 alpha: 31.435762849892686\n",
      "timeframe: 0 section: 61 alpha: 21.487940769421744\n",
      "timeframe: 1 section: 63 alpha: 25.013003490862168\n",
      "timeframe: 0 section: 396 alpha: 56.33831298826988\n",
      "timeframe: 0 section: 200 alpha: 21.85495608504827\n",
      "timeframe: 0 section: 165 alpha: 40.83479922120751\n",
      "timeframe: 0 section: 466 alpha: 40.86747995114278\n",
      "timeframe: 0 section: 88 alpha: 28.752806002492136\n",
      "timeframe: 1 section: 28 alpha: 25.055780439252793\n",
      "timeframe: 0 section: 82 alpha: 6.401721963602635\n",
      "timeframe: 0 section: 193 alpha: 8.155572673365565\n",
      "timeframe: 0 section: 249 alpha: 0.1954745577339185\n",
      "timeframe: 0 section: 340 alpha: 35.82787265349992\n",
      "timeframe: 0 section: 536 alpha: 91.60669402432343\n",
      "timeframe: 0 section: 270 alpha: 6.924190783023239\n",
      "timeframe: 0 section: 403 alpha: 20.324298806621854\n",
      "timeframe: 0 section: 130 alpha: 48.714246230795396\n",
      "timeframe: 0 section: 116 alpha: 37.03476924347884\n",
      "timeframe: 1 section: 112 alpha: 14.342782531054414\n",
      "timeframe: 0 section: 326 alpha: 24.634381097845267\n",
      "timeframe: 0 section: 298 alpha: 8.679284487395268\n",
      "timeframe: 1 section: 91 alpha: 28.665922747632784\n",
      "timeframe: 0 section: 424 alpha: 19.079456619122052\n",
      "timeframe: 0 section: 102 alpha: 20.380881161636392\n",
      "timeframe: 0 section: 417 alpha: 8.193266049574614\n",
      "timeframe: 0 section: 5 alpha: 19.46907812412813\n",
      "timeframe: 1 section: 15 alpha: 42.908909412422545\n",
      "timeframe: 0 section: 207 alpha: 30.03009678846125\n",
      "timeframe: 0 section: 494 alpha: 20.773236556327852\n",
      "timeframe: 0 section: 109 alpha: 18.893018236178488\n",
      "timeframe: 0 section: 543 alpha: 25.37616529167296\n",
      "timeframe: 0 section: 347 alpha: 9.799675840453173\n",
      "timeframe: 0 section: 361 alpha: 40.344091730633565\n",
      "timeframe: 1 section: 70 alpha: 20.198978129679098\n",
      "timeframe: 0 section: 151 alpha: 19.46661961467611\n",
      "timeframe: 0 section: 487 alpha: 19.336456179110666\n",
      "timeframe: 0 section: 54 alpha: 15.500050722220255\n",
      "timeframe: 0 section: 501 alpha: 79.18686431845617\n",
      "timeframe: 0 section: 40 alpha: 30.58619474849357\n",
      "timeframe: 0 section: 47 alpha: 15.681298285399913\n",
      "timeframe: 0 section: 515 alpha: 26.92655814988586\n",
      "timeframe: 0 section: 529 alpha: 15.984476782724668\n",
      "timeframe: 0 section: 26 alpha: 19.5315527879777\n",
      "timeframe: 0 section: 75 alpha: 19.74183852453506\n",
      "timeframe: 0 section: 263 alpha: 33.94807656075707\n",
      "timeframe: 0 section: 305 alpha: 42.18464286193106\n",
      "timeframe: 1 section: 98 alpha: 37.808969081998484\n",
      "timeframe: 0 section: 158 alpha: 22.573943732811795\n",
      "timeframe: 0 section: 242 alpha: 4.012310928701355\n",
      "timeframe: 0 section: 68 alpha: 14.271813072995455\n",
      "timeframe: 1 section: 50 alpha: 25.26308780259527\n",
      "timeframe: 0 section: 376 alpha: 22.55366364903583\n",
      "timeframe: 0 section: 382 alpha: 22.953950437427554\n",
      "timeframe: 0 section: 291 alpha: 27.803004929335017\n",
      "timeframe: 0 section: 172 alpha: 23.678578889362857\n",
      "timeframe: 0 section: 221 alpha: 28.285580500283533\n",
      "timeframe: 0 section: 33 alpha: 31.845371929030833\n",
      "timeframe: 0 section: 144 alpha: 17.875817099415016\n",
      "timeframe: 1 section: 57 alpha: 14.434219696351052\n",
      "timeframe: 0 section: 523 alpha: 24.021552301231885\n",
      "timeframe: 0 section: 354 alpha: 14.16390903193974\n",
      "timeframe: 0 section: 229 alpha: 22.527364758828465\n",
      "timeframe: 0 section: 187 alpha: 33.34525270619039\n",
      "timeframe: 0 section: 320 alpha: 16.048026577851033\n",
      "timeframe: 0 section: 20 alpha: 26.038648247282893\n",
      "timeframe: 0 section: 124 alpha: 35.576908347132246\n",
      "timeframe: 0 section: 12 alpha: 34.99185798143643\n",
      "timeframe: 1 section: 134 alpha: 39.46522174686381\n",
      "timeframe: 0 section: 432 alpha: 12.884803534402101\n",
      "timeframe: 0 section: 439 alpha: 25.833232440358973\n",
      "timeframe: 0 section: 278 alpha: 19.4049478799567\n",
      "timeframe: 1 section: 22 alpha: 14.000620064890459\n",
      "timeframe: 0 section: 138 alpha: 17.60545457328073\n",
      "timeframe: 0 section: 446 alpha: 20.994331653964394\n",
      "timeframe: 0 section: 368 alpha: 40.100155027260826\n",
      "timeframe: 0 section: 509 alpha: 11.865442465892077\n",
      "timeframe: 0 section: 62 alpha: 25.775211886945595\n",
      "timeframe: 0 section: 215 alpha: 22.364680027380615\n",
      "timeframe: 0 section: 256 alpha: 52.38976569785\n",
      "timeframe: 0 section: 83 alpha: 15.427534968867965\n",
      "timeframe: 0 section: 551 alpha: 16.200237896859473\n",
      "timeframe: 0 section: 96 alpha: 18.386165464480378\n",
      "timeframe: 0 section: 474 alpha: 30.231553195096584\n",
      "timeframe: 1 section: 127 alpha: 8.738840558651274\n",
      "timeframe: 0 section: 284 alpha: 20.891310715835186\n",
      "timeframe: 0 section: 410 alpha: 8.081523502880763\n",
      "timeframe: 0 section: 460 alpha: 13.265576807487403\n",
      "timeframe: 1 section: 120 alpha: 27.905306837149272\n",
      "timeframe: 0 section: 481 alpha: 27.37300061507442\n",
      "timeframe: 1 section: 16 alpha: 16.148961963192015\n",
      "timeframe: 0 section: 313 alpha: 31.683185475050173\n",
      "timeframe: 0 section: 341 alpha: 6.318006655482067\n",
      "timeframe: 0 section: 166 alpha: 26.980115484615517\n",
      "timeframe: 0 section: 397 alpha: 32.87893388481517\n",
      "timeframe: 0 section: 180 alpha: 20.214214143370892\n",
      "timeframe: 1 section: 106 alpha: 27.20399754058622\n",
      "timeframe: 1 section: 43 alpha: 18.28832011550916\n",
      "timeframe: 0 section: 334 alpha: 32.719422773224245\n",
      "timeframe: 0 section: 467 alpha: 18.678990772339723\n",
      "timeframe: 0 section: 271 alpha: 22.418868673931968\n",
      "timeframe: 0 section: 453 alpha: 27.137075422317633\n",
      "timeframe: 0 section: 390 alpha: 28.278866060141414\n",
      "timeframe: 0 section: 6 alpha: 18.935886810659575\n",
      "timeframe: 1 section: 64 alpha: 27.212020555638965\n",
      "timeframe: 0 section: 250 alpha: 64.32383026719067\n",
      "timeframe: 0 section: 131 alpha: 19.72972112931785\n",
      "timeframe: 0 section: 502 alpha: 18.168910557918053\n",
      "timeframe: 0 section: 208 alpha: 1.6923644575731287\n",
      "timeframe: 0 section: 362 alpha: 28.46872787914899\n",
      "timeframe: 0 section: 194 alpha: 10.135269488014105\n",
      "timeframe: 0 section: 110 alpha: 19.957997183283876\n",
      "timeframe: 0 section: 236 alpha: 21.661995557220035\n",
      "timeframe: 0 section: 537 alpha: 14.8443413921493\n",
      "timeframe: 0 section: 327 alpha: 16.58096064204818\n",
      "timeframe: 0 section: 117 alpha: 22.050037364363686\n",
      "timeframe: 0 section: 103 alpha: 24.21219963272812\n",
      "timeframe: 1 section: 8 alpha: 7.211955034284505\n",
      "timeframe: 0 section: 152 alpha: 21.841604473762104\n",
      "timeframe: 1 section: 141 alpha: 37.14868013211017\n",
      "timeframe: 1 section: 85 alpha: 29.16289327175018\n",
      "timeframe: 0 section: 201 alpha: 26.466697791972358\n",
      "timeframe: 0 section: 425 alpha: 27.920529763975242\n",
      "timeframe: 0 section: 34 alpha: 55.69182143316209\n",
      "timeframe: 0 section: 243 alpha: 22.67706299412238\n",
      "timeframe: 0 section: 264 alpha: 35.095378205626986\n",
      "timeframe: 1 section: 29 alpha: 17.1726205148558\n",
      "timeframe: 0 section: 159 alpha: 13.474916393182257\n",
      "timeframe: 1 section: 1 alpha: 19.373227740930815\n",
      "timeframe: 0 section: 55 alpha: 87.47755814914147\n",
      "timeframe: 1 section: 37 alpha: 8.168785122795782\n",
      "timeframe: 1 section: 78 alpha: 32.38372425464863\n",
      "timeframe: 0 section: 418 alpha: 26.80449172589117\n",
      "timeframe: 0 section: 89 alpha: 45.31326484266015\n",
      "timeframe: 0 section: 544 alpha: 16.726845957125306\n",
      "timeframe: 0 section: 495 alpha: 49.76223527139441\n",
      "timeframe: 0 section: 488 alpha: 31.22568129683449\n",
      "timeframe: 0 section: 299 alpha: 20.7447252169363\n",
      "timeframe: 0 section: 306 alpha: 16.777442239874368\n",
      "timeframe: 1 section: 51 alpha: 13.836438885807826\n",
      "timeframe: 0 section: 348 alpha: 27.39947485409257\n",
      "timeframe: 1 section: 92 alpha: 22.75764364156772\n",
      "timeframe: 0 section: 173 alpha: 15.00600669288422\n",
      "timeframe: 0 section: 377 alpha: 35.642822096958156\n",
      "timeframe: 0 section: 440 alpha: 41.62784253802792\n",
      "timeframe: 0 section: 41 alpha: 33.445866585873816\n",
      "timeframe: 0 section: 292 alpha: 29.574927918045304\n",
      "timeframe: 0 section: 48 alpha: 10.091756603458617\n",
      "timeframe: 0 section: 69 alpha: 13.734443194038247\n",
      "timeframe: 1 section: 113 alpha: 16.85374768460191\n",
      "timeframe: 0 section: 383 alpha: 11.553000475230311\n",
      "timeframe: 0 section: 404 alpha: 19.398760554340047\n",
      "timeframe: 0 section: 321 alpha: 37.25102845019099\n",
      "timeframe: 0 section: 125 alpha: 20.539690577475827\n",
      "timeframe: 0 section: 530 alpha: 45.76871684188496\n",
      "timeframe: 0 section: 230 alpha: 13.44698832556615\n",
      "timeframe: 0 section: 342 alpha: 24.764131806941915\n",
      "timeframe: 0 section: 524 alpha: 16.19414897424433\n",
      "timeframe: 0 section: 145 alpha: 15.385775190816833\n",
      "timeframe: 0 section: 222 alpha: 30.389008512622777\n",
      "timeframe: 0 section: 355 alpha: 16.622950625839046\n",
      "timeframe: 0 section: 76 alpha: 31.75453123029986\n",
      "timeframe: 0 section: 433 alpha: 29.476700752931013\n",
      "timeframe: 1 section: 71 alpha: 49.01808535562791\n",
      "timeframe: 0 section: 257 alpha: 18.90126431319667\n",
      "timeframe: 1 section: 23 alpha: 36.03334766623373\n",
      "timeframe: 0 section: 181 alpha: 23.649356293221853\n",
      "timeframe: 0 section: 391 alpha: 0.8911118937307172\n",
      "timeframe: 0 section: 285 alpha: 25.551548661786562\n",
      "timeframe: 0 section: 216 alpha: 31.065454900860228\n",
      "timeframe: 0 section: 97 alpha: 27.152957684616137\n",
      "timeframe: 0 section: 279 alpha: 21.72199270578258\n",
      "timeframe: 0 section: 447 alpha: 15.02146012100537\n",
      "timeframe: 0 section: 188 alpha: 16.75281562731036\n",
      "timeframe: 1 section: 144 alpha: 16.92320502081457\n",
      "timeframe: 0 section: 139 alpha: 12.59974639162361\n",
      "timeframe: 0 section: 369 alpha: 13.684979044993879\n",
      "timeframe: 0 section: 468 alpha: 25.572620628510812\n",
      "timeframe: 0 section: 461 alpha: 39.19950910971355\n",
      "timeframe: 0 section: 552 alpha: 36.59191054119697\n",
      "timeframe: 1 section: 128 alpha: 19.25148483931938\n",
      "timeframe: 1 section: 99 alpha: 6.555002565140548\n",
      "timeframe: 0 section: 516 alpha: 20.108147676667997\n",
      "timeframe: 0 section: 314 alpha: 8.88596254568124\n",
      "timeframe: 1 section: 151 alpha: 30.506861254390945\n",
      "timeframe: 0 section: 209 alpha: 13.119538696051263\n",
      "timeframe: 0 section: 27 alpha: 13.863322890024671\n",
      "timeframe: 0 section: 398 alpha: 15.261556820687382\n",
      "timeframe: 0 section: 104 alpha: 12.099464228689687\n",
      "timeframe: 0 section: 13 alpha: 35.13995965933177\n",
      "timeframe: 0 section: 475 alpha: 11.452935110086667\n",
      "timeframe: 0 section: 482 alpha: 16.4380497306168\n",
      "timeframe: 0 section: 167 alpha: 10.522444597356264\n",
      "timeframe: 0 section: 510 alpha: 10.6087240725613\n",
      "timeframe: 1 section: 121 alpha: 43.49558751258135\n",
      "timeframe: 1 section: 158 alpha: 39.22275645364219\n",
      "timeframe: 1 section: 135 alpha: 20.86052939847719\n",
      "timeframe: 0 section: 363 alpha: 23.469063109795563\n",
      "timeframe: 0 section: 195 alpha: 16.597360524340264\n",
      "timeframe: 0 section: 153 alpha: 16.556832984695927\n",
      "timeframe: 0 section: 411 alpha: 8.610732260826511\n",
      "timeframe: 1 section: 58 alpha: 13.262649019482682\n",
      "timeframe: 0 section: 272 alpha: 31.05790411178807\n",
      "timeframe: 1 section: 107 alpha: 31.543505881736856\n",
      "timeframe: 0 section: 454 alpha: 21.350843900424934\n",
      "timeframe: 1 section: 93 alpha: 20.349427465592264\n",
      "timeframe: 0 section: 328 alpha: 23.87838861841318\n",
      "timeframe: 0 section: 419 alpha: 18.447917784422994\n",
      "timeframe: 0 section: 349 alpha: 5.619612693781422\n",
      "timeframe: 1 section: 9 alpha: 12.563437359901789\n",
      "timeframe: 1 section: 142 alpha: 10.988630754797887\n",
      "timeframe: 0 section: 503 alpha: 20.522921019265375\n",
      "timeframe: 1 section: 17 alpha: 25.595639559437334\n",
      "timeframe: 0 section: 545 alpha: 45.08568265363842\n",
      "timeframe: 0 section: 293 alpha: 36.79810116418487\n",
      "timeframe: 1 section: 114 alpha: 20.869784372876875\n",
      "timeframe: 0 section: 426 alpha: 23.39236386448617\n",
      "timeframe: 1 section: 249 alpha: 11.387678382619882\n",
      "timeframe: 0 section: 237 alpha: 41.643810669136464\n",
      "timeframe: 0 section: 244 alpha: 19.72325561092547\n",
      "timeframe: 0 section: 111 alpha: 21.7094081129875\n",
      "timeframe: 1 section: 65 alpha: 39.77884847588231\n",
      "timeframe: 0 section: 265 alpha: 15.64782626566218\n",
      "timeframe: 0 section: 174 alpha: 29.705176003306338\n",
      "timeframe: 0 section: 160 alpha: 43.43574716589579\n",
      "timeframe: 1 section: 30 alpha: 27.945416979323205\n",
      "timeframe: 1 section: 165 alpha: 31.816482197842564\n",
      "timeframe: 0 section: 118 alpha: 13.855224113325349\n",
      "timeframe: 0 section: 300 alpha: 51.46278131339344\n",
      "timeframe: 0 section: 335 alpha: 40.754332319537376\n",
      "timeframe: 1 section: 86 alpha: 22.14124560836582\n",
      "timeframe: 1 section: 193 alpha: 22.4297709147441\n",
      "timeframe: 1 section: 44 alpha: 25.640829979406302\n",
      "timeframe: 0 section: 202 alpha: 32.09028189814775\n",
      "timeframe: 0 section: 251 alpha: 38.56112568726233\n",
      "timeframe: 1 section: 38 alpha: 20.257125127839654\n",
      "timeframe: 0 section: 307 alpha: 20.552627856581196\n",
      "timeframe: 0 section: 90 alpha: 41.91844692934602\n",
      "timeframe: 0 section: 132 alpha: 30.880656000645303\n",
      "timeframe: 0 section: 531 alpha: 28.21353970686085\n",
      "timeframe: 1 section: 79 alpha: 18.80453607109749\n",
      "timeframe: 0 section: 223 alpha: 10.004141529070287\n",
      "timeframe: 0 section: 496 alpha: 33.75503480022528\n",
      "timeframe: 0 section: 538 alpha: 17.127185000865126\n",
      "timeframe: 0 section: 370 alpha: 11.889184633109226\n",
      "timeframe: 0 section: 489 alpha: 29.48816201014133\n",
      "timeframe: 0 section: 286 alpha: 21.352689785062797\n",
      "timeframe: 1 section: 145 alpha: 13.540598822040717\n",
      "timeframe: 0 section: 356 alpha: 22.587797695461152\n",
      "timeframe: 0 section: 405 alpha: 24.013665271071122\n",
      "timeframe: 1 section: 242 alpha: 15.07556426495751\n",
      "timeframe: 1 section: 179 alpha: 24.137672016960135\n",
      "timeframe: 0 section: 146 alpha: 15.104100774933361\n",
      "timeframe: 1 section: 389 alpha: 3.9833061053574386\n",
      "timeframe: 1 section: 52 alpha: 74.00428406648139\n",
      "timeframe: 1 section: 263 alpha: 22.608742287644198\n",
      "timeframe: 1 section: 207 alpha: 49.52145077560852\n",
      "timeframe: 0 section: 258 alpha: 27.135142075211075\n",
      "timeframe: 1 section: 375 alpha: 19.33413588281447\n",
      "timeframe: 0 section: 384 alpha: 32.098589077848445\n",
      "timeframe: 1 section: 186 alpha: 23.67378731317843\n",
      "timeframe: 1 section: 24 alpha: 15.97926775885603\n",
      "timeframe: 1 section: 228 alpha: 17.81902572934988\n",
      "timeframe: 1 section: 235 alpha: 15.830759887234422\n",
      "timeframe: 1 section: 221 alpha: 22.44555872633176\n",
      "timeframe: 1 section: 431 alpha: 13.967558442295292\n",
      "timeframe: 1 section: 333 alpha: 23.201170440253517\n",
      "timeframe: 1 section: 277 alpha: 11.958521012388921\n",
      "timeframe: 1 section: 319 alpha: 28.468928366780922\n",
      "timeframe: 1 section: 214 alpha: 14.396039088827424\n",
      "timeframe: 1 section: 256 alpha: 36.33244290721126\n",
      "timeframe: 1 section: 340 alpha: 36.68659007381494\n",
      "timeframe: 1 section: 10 alpha: 17.15063896572458\n",
      "timeframe: 1 section: 298 alpha: 5.896377196185812\n",
      "timeframe: 1 section: 326 alpha: 8.439509938358846\n",
      "timeframe: 0 section: 517 alpha: 14.960620335635403\n",
      "timeframe: 1 section: 2 alpha: 27.361871787431316\n",
      "timeframe: 1 section: 312 alpha: 21.037012450859866\n",
      "timeframe: 1 section: 200 alpha: 22.486722947263296\n",
      "timeframe: 1 section: 305 alpha: 41.507233849266036\n",
      "timeframe: 1 section: 270 alpha: 16.775094602154546\n",
      "timeframe: 1 section: 172 alpha: 20.551737036585592\n",
      "timeframe: 1 section: 424 alpha: 30.120651647503095\n",
      "timeframe: 1 section: 250 alpha: 43.78733036297901\n",
      "timeframe: 1 section: 445 alpha: 19.87142773780565\n",
      "timeframe: 0 section: 412 alpha: 11.039004403867827\n",
      "timeframe: 1 section: 159 alpha: 10.056558574446662\n",
      "timeframe: 1 section: 347 alpha: 22.01483718487715\n",
      "timeframe: 1 section: 508 alpha: 14.549716035747176\n",
      "timeframe: 1 section: 459 alpha: 36.33529881508791\n",
      "timeframe: 1 section: 438 alpha: 38.12585402525519\n",
      "timeframe: 1 section: 466 alpha: 31.51829046060011\n",
      "timeframe: 1 section: 108 alpha: 14.429249341200922\n",
      "timeframe: 1 section: 417 alpha: 19.891017442749277\n",
      "timeframe: 1 section: 368 alpha: 20.65936489067903\n",
      "timeframe: 1 section: 122 alpha: 16.951475080371125\n",
      "timeframe: 1 section: 354 alpha: 15.174406407087652\n",
      "timeframe: 1 section: 284 alpha: 24.979346696364367\n",
      "timeframe: 1 section: 487 alpha: 24.05236665674178\n",
      "timeframe: 1 section: 59 alpha: 14.85692686170478\n",
      "timeframe: 1 section: 494 alpha: 46.148065453739456\n",
      "timeframe: 1 section: 403 alpha: 51.0920091657469\n",
      "timeframe: 1 section: 129 alpha: 37.85474921299264\n",
      "timeframe: 2 section: 15 alpha: 53.089146540349724\n",
      "timeframe: 1 section: 143 alpha: 13.314436805884322\n",
      "timeframe: 1 section: 72 alpha: 10.938399604099002\n",
      "timeframe: 1 section: 522 alpha: 32.51248657663508\n",
      "timeframe: 1 section: 194 alpha: 18.580842244484398\n",
      "timeframe: 1 section: 452 alpha: 32.30164821335314\n",
      "timeframe: 2 section: 50 alpha: 33.37385657185193\n",
      "timeframe: 1 section: 480 alpha: 33.37248437127777\n",
      "timeframe: 1 section: 382 alpha: 20.062811967570727\n",
      "timeframe: 1 section: 152 alpha: 26.0348093876808\n",
      "timeframe: 1 section: 410 alpha: 16.892722774453826\n",
      "timeframe: 1 section: 361 alpha: 31.461412211249737\n",
      "timeframe: 1 section: 94 alpha: 25.31539834507249\n",
      "timeframe: 1 section: 264 alpha: 10.008458790546696\n",
      "timeframe: 1 section: 136 alpha: 14.89843962645163\n",
      "timeframe: 1 section: 396 alpha: 34.74664998164273\n",
      "timeframe: 1 section: 291 alpha: 22.198267882560955\n",
      "timeframe: 1 section: 501 alpha: 35.460603294510406\n",
      "timeframe: 1 section: 100 alpha: 10.315171005418367\n",
      "timeframe: 1 section: 45 alpha: 11.917950629976193\n",
      "timeframe: 1 section: 390 alpha: 29.64606879436351\n",
      "timeframe: 1 section: 550 alpha: 21.490683796414018\n",
      "timeframe: 1 section: 80 alpha: 13.71061176008325\n",
      "timeframe: 1 section: 31 alpha: 42.460890302315576\n",
      "timeframe: 1 section: 115 alpha: 58.82818969878794\n",
      "timeframe: 1 section: 432 alpha: 39.51531538330543\n",
      "timeframe: 1 section: 166 alpha: 23.296277332165207\n",
      "timeframe: 1 section: 543 alpha: 28.546188545473488\n",
      "timeframe: 2 section: 36 alpha: 25.46624766857692\n",
      "timeframe: 2 section: 148 alpha: 28.500313101884558\n",
      "timeframe: 1 section: 87 alpha: 44.44728485743864\n",
      "timeframe: 1 section: 529 alpha: 22.63069599708301\n",
      "timeframe: 1 section: 473 alpha: 15.098461193356234\n",
      "timeframe: 1 section: 515 alpha: 59.99416595487786\n",
      "timeframe: 2 section: 120 alpha: 37.735426072552634\n",
      "timeframe: 1 section: 257 alpha: 10.361675037398893\n",
      "timeframe: 1 section: 146 alpha: 11.307814015620224\n",
      "timeframe: 1 section: 180 alpha: 27.07097425580682\n",
      "timeframe: 2 section: 127 alpha: 32.176976529077905\n",
      "timeframe: 2 section: 22 alpha: 11.617103711272716\n",
      "timeframe: 1 section: 66 alpha: 19.39176460557516\n",
      "timeframe: 2 section: 57 alpha: 15.376055186493204\n",
      "timeframe: 2 section: 78 alpha: 8.91833997766649\n",
      "timeframe: 1 section: 187 alpha: 48.711593315634026\n",
      "timeframe: 2 section: 85 alpha: 19.72348349789999\n",
      "timeframe: 1 section: 376 alpha: 27.919760957338468\n",
      "timeframe: 1 section: 536 alpha: 40.82924089187664\n",
      "timeframe: 1 section: 243 alpha: 17.26941524925068\n",
      "timeframe: 2 section: 71 alpha: 64.7921211850008\n",
      "timeframe: 2 section: 43 alpha: 20.136458927853674\n",
      "timeframe: 1 section: 229 alpha: 20.48985154715419\n",
      "timeframe: 2 section: 29 alpha: 11.329763037208998\n",
      "timeframe: 1 section: 3 alpha: 33.794494205675264\n",
      "timeframe: 1 section: 313 alpha: 24.93730238027299\n",
      "timeframe: 2 section: 106 alpha: 28.138611441906413\n",
      "timeframe: 1 section: 334 alpha: 25.58447176356574\n",
      "timeframe: 1 section: 509 alpha: 23.479507063261444\n",
      "timeframe: 2 section: 169 alpha: 32.68760003104248\n",
      "timeframe: 1 section: 251 alpha: 25.570336444908925\n",
      "timeframe: 1 section: 271 alpha: 25.02851191883562\n",
      "timeframe: 2 section: 204 alpha: 26.459562871517036\n",
      "timeframe: 1 section: 236 alpha: 28.56387935413278\n",
      "timeframe: 1 section: 460 alpha: 37.366532968593795\n",
      "timeframe: 2 section: 8 alpha: 42.497245792203856\n",
      "timeframe: 2 section: 64 alpha: 23.053638030894387\n",
      "timeframe: 1 section: 502 alpha: 7.094944579883225\n",
      "timeframe: 2 section: 155 alpha: 8.79312199359504\n",
      "timeframe: 1 section: 425 alpha: 11.392859618305668\n",
      "timeframe: 1 section: 327 alpha: 11.466001958553186\n",
      "timeframe: 1 section: 306 alpha: 30.433579255617502\n",
      "timeframe: 1 section: 369 alpha: 20.378182770349877\n",
      "timeframe: 2 section: 1 alpha: 72.95117853372078\n",
      "timeframe: 2 section: 141 alpha: 41.99147690111843\n",
      "timeframe: 1 section: 222 alpha: 41.292111708045674\n",
      "timeframe: 2 section: 92 alpha: 6.023895145415591\n",
      "timeframe: 1 section: 160 alpha: 33.16503658077746\n",
      "timeframe: 1 section: 467 alpha: 26.215442105455804\n",
      "timeframe: 1 section: 391 alpha: 12.880802752072432\n",
      "timeframe: 2 section: 16 alpha: 10.85640698207691\n",
      "timeframe: 1 section: 215 alpha: 19.66576570850203\n",
      "timeframe: 1 section: 173 alpha: 20.99718977658713\n",
      "timeframe: 1 section: 348 alpha: 33.39738212259655\n",
      "timeframe: 1 section: 383 alpha: 21.514579415961364\n",
      "timeframe: 2 section: 99 alpha: 18.71312262635136\n",
      "timeframe: 1 section: 320 alpha: 14.067339556873055\n",
      "timeframe: 2 section: 162 alpha: 14.380835057717299\n",
      "timeframe: 1 section: 201 alpha: 37.42116111178327\n",
      "timeframe: 1 section: 341 alpha: 14.089333586507394\n",
      "timeframe: 1 section: 523 alpha: 48.927495401881764\n",
      "timeframe: 1 section: 446 alpha: 20.02971766088982\n",
      "timeframe: 1 section: 404 alpha: 21.670883911647568\n",
      "timeframe: 1 section: 101 alpha: 22.804478005091383\n",
      "timeframe: 1 section: 418 alpha: 30.932346014950983\n",
      "timeframe: 1 section: 299 alpha: 20.211926050627014\n",
      "timeframe: 2 section: 51 alpha: 21.078481023320375\n",
      "timeframe: 1 section: 208 alpha: 18.986431999250023\n",
      "timeframe: 1 section: 278 alpha: 36.03508708584137\n",
      "timeframe: 1 section: 195 alpha: 22.427902860116443\n",
      "timeframe: 1 section: 439 alpha: 13.817375070242841\n",
      "timeframe: 1 section: 481 alpha: 43.15633860122796\n",
      "timeframe: 1 section: 495 alpha: 41.122716674492615\n",
      "timeframe: 2 section: 134 alpha: 29.590094593035673\n",
      "timeframe: 2 section: 113 alpha: 45.85761808404276\n",
      "timeframe: 1 section: 453 alpha: 26.641001760515607\n",
      "timeframe: 1 section: 544 alpha: 14.596383229596917\n",
      "timeframe: 1 section: 411 alpha: 12.931457822295481\n",
      "timeframe: 1 section: 285 alpha: 26.23499708069829\n",
      "timeframe: 1 section: 153 alpha: 7.475929034190987\n",
      "timeframe: 1 section: 258 alpha: 18.532221283202006\n",
      "timeframe: 1 section: 551 alpha: 26.09784163931689\n",
      "timeframe: 1 section: 292 alpha: 20.205648575214216\n",
      "timeframe: 1 section: 362 alpha: 28.669553873401068\n",
      "timeframe: 1 section: 488 alpha: 18.685070108286666\n",
      "timeframe: 2 section: 23 alpha: 12.787286553869174\n",
      "timeframe: 2 section: 37 alpha: 10.578986233950594\n",
      "timeframe: 2 section: 239 alpha: 7.630736368169255\n",
      "timeframe: 2 section: 79 alpha: 35.4846280716058\n",
      "timeframe: 1 section: 530 alpha: 30.888933765738248\n",
      "timeframe: 1 section: 516 alpha: 12.811097503569322\n",
      "timeframe: 2 section: 190 alpha: 12.238361176347995\n",
      "timeframe: 2 section: 30 alpha: 30.507120254878778\n",
      "timeframe: 2 section: 197 alpha: 21.160534816607907\n",
      "timeframe: 1 section: 167 alpha: 4.924921022167001\n",
      "timeframe: 2 section: 183 alpha: 49.502167814090214\n",
      "timeframe: 2 section: 149 alpha: 10.659812769296956\n",
      "timeframe: 2 section: 170 alpha: 24.784180999623423\n",
      "timeframe: 2 section: 232 alpha: 14.145825383742896\n",
      "timeframe: 1 section: 73 alpha: 8.812252452472505\n",
      "timeframe: 1 section: 433 alpha: 20.634362838825535\n",
      "timeframe: 1 section: 397 alpha: 40.34290942589053\n",
      "timeframe: 1 section: 537 alpha: 17.241701095953296\n",
      "timeframe: 1 section: 244 alpha: 9.643573299675488\n",
      "timeframe: 1 section: 474 alpha: 21.229045917665484\n",
      "timeframe: 1 section: 503 alpha: 42.170974403552144\n",
      "timeframe: 1 section: 188 alpha: 49.64250833967857\n",
      "timeframe: 2 section: 253 alpha: 18.427190875279052\n",
      "timeframe: 1 section: 370 alpha: 9.095530214778801\n",
      "timeframe: 1 section: 314 alpha: 9.114142196119655\n",
      "timeframe: 2 section: 218 alpha: 30.079238003607866\n",
      "timeframe: 2 section: 225 alpha: 30.28798421145836\n",
      "timeframe: 2 section: 86 alpha: 45.88051533986312\n",
      "timeframe: 1 section: 342 alpha: 4.815454609305599\n",
      "timeframe: 1 section: 328 alpha: 24.205399547999825\n",
      "timeframe: 2 section: 58 alpha: 27.149166841815696\n",
      "timeframe: 1 section: 147 alpha: 15.885764912874434\n",
      "timeframe: 1 section: 230 alpha: 20.170464514801367\n",
      "timeframe: 1 section: 524 alpha: 8.993282059508909\n",
      "timeframe: 1 section: 161 alpha: 4.371415450118129\n",
      "timeframe: 1 section: 355 alpha: 8.27769852451976\n",
      "timeframe: 1 section: 252 alpha: 26.01284938014353\n",
      "timeframe: 2 section: 267 alpha: 30.65494114885566\n",
      "timeframe: 1 section: 349 alpha: 20.22071891068231\n",
      "timeframe: 1 section: 335 alpha: 37.32915463960092\n",
      "timeframe: 1 section: 265 alpha: 4.07830105404423\n",
      "timeframe: 2 section: 9 alpha: 8.832757613866422\n",
      "timeframe: 2 section: 211 alpha: 45.87584770565356\n",
      "timeframe: 1 section: 468 alpha: 10.732157314996954\n",
      "timeframe: 2 section: 176 alpha: 16.74192863746355\n",
      "timeframe: 1 section: 426 alpha: 23.352058884580913\n",
      "timeframe: 1 section: 510 alpha: 13.613127908839047\n",
      "timeframe: 2 section: 121 alpha: 31.43481732134005\n",
      "timeframe: 1 section: 216 alpha: 23.333360446269804\n",
      "timeframe: 1 section: 405 alpha: 34.569251005910694\n",
      "timeframe: 1 section: 181 alpha: 23.601574452509233\n",
      "timeframe: 2 section: 205 alpha: 53.77529783509302\n",
      "timeframe: 1 section: 209 alpha: 3.942785851465657\n",
      "timeframe: 1 section: 237 alpha: 19.8997023872077\n",
      "timeframe: 1 section: 307 alpha: 13.368760587410641\n",
      "timeframe: 1 section: 440 alpha: 6.324850285081416\n",
      "timeframe: 2 section: 2 alpha: 25.35647139873494\n",
      "timeframe: 1 section: 174 alpha: 32.38900266945552\n",
      "timeframe: 1 section: 454 alpha: 24.17823170845762\n",
      "timeframe: 1 section: 272 alpha: 27.29583939068226\n",
      "timeframe: 1 section: 392 alpha: 16.4028082400964\n",
      "timeframe: 2 section: 246 alpha: 32.093665524171456\n",
      "timeframe: 1 section: 482 alpha: 13.729870030193897\n",
      "timeframe: 1 section: 377 alpha: 30.311575157149814\n",
      "timeframe: 1 section: 223 alpha: 37.710512147058374\n",
      "timeframe: 1 section: 321 alpha: 38.235602760775755\n",
      "timeframe: 2 section: 93 alpha: 15.995400085436199\n",
      "timeframe: 1 section: 202 alpha: 50.69527979478725\n",
      "timeframe: 2 section: 72 alpha: 8.88708828112943\n",
      "timeframe: 2 section: 156 alpha: 10.340543419947483\n",
      "timeframe: 1 section: 300 alpha: 45.235294322617946\n",
      "timeframe: 1 section: 196 alpha: 22.288006945161502\n",
      "timeframe: 2 section: 260 alpha: 10.938712278728737\n",
      "timeframe: 1 section: 447 alpha: 22.7910948289553\n",
      "timeframe: 1 section: 461 alpha: 19.89863776485899\n",
      "timeframe: 2 section: 44 alpha: 21.38954117407071\n",
      "timeframe: 1 section: 286 alpha: 44.16525638888582\n",
      "timeframe: 2 section: 100 alpha: 12.81573582444796\n",
      "timeframe: 1 section: 363 alpha: 20.78419339954445\n",
      "timeframe: 2 section: 38 alpha: 2.3470642324243425\n",
      "timeframe: 1 section: 419 alpha: 20.283387237881474\n",
      "timeframe: 1 section: 293 alpha: 41.67002513072371\n",
      "timeframe: 1 section: 154 alpha: 8.503118780292468\n",
      "timeframe: 2 section: 17 alpha: 14.301800261310925\n",
      "timeframe: 1 section: 148 alpha: 8.501501873042697\n",
      "timeframe: 1 section: 552 alpha: 20.852124361532727\n",
      "timeframe: 1 section: 279 alpha: 17.08579505236288\n",
      "timeframe: 2 section: 233 alpha: 11.672170579274908\n",
      "timeframe: 2 section: 52 alpha: 10.603928310301383\n",
      "timeframe: 2 section: 128 alpha: 27.87867899703414\n",
      "timeframe: 1 section: 315 alpha: 19.96695755741762\n",
      "timeframe: 1 section: 545 alpha: 55.755822496952405\n",
      "timeframe: 1 section: 412 alpha: 40.92656754335809\n",
      "timeframe: 1 section: 489 alpha: 20.110309761006885\n",
      "timeframe: 1 section: 371 alpha: 32.19182107258514\n",
      "timeframe: 1 section: 434 alpha: 22.276053523498234\n",
      "timeframe: 1 section: 384 alpha: 33.320128993933345\n",
      "timeframe: 2 section: 274 alpha: 4.912397290538469\n",
      "timeframe: 1 section: 259 alpha: 48.12115440739715\n",
      "timeframe: 1 section: 496 alpha: 48.82397778863603\n",
      "timeframe: 1 section: 538 alpha: 38.73466504400192\n",
      "timeframe: 1 section: 504 alpha: 10.146350939011567\n",
      "timeframe: 2 section: 24 alpha: 14.725259037727293\n",
      "timeframe: 1 section: 517 alpha: 38.13668147360264\n",
      "timeframe: 2 section: 184 alpha: 24.54564793336815\n",
      "timeframe: 1 section: 531 alpha: 57.246732492921744\n",
      "timeframe: 1 section: 398 alpha: 4.029438310157201\n",
      "timeframe: 1 section: 168 alpha: 16.41350792481189\n",
      "timeframe: 2 section: 114 alpha: 7.4572889524953405\n",
      "timeframe: 1 section: 189 alpha: 31.714358449188154\n",
      "timeframe: 2 section: 135 alpha: 5.897215945583959\n",
      "timeframe: 2 section: 107 alpha: 37.441317825638876\n",
      "timeframe: 1 section: 253 alpha: 10.276611174226508\n",
      "timeframe: 2 section: 142 alpha: 18.045348739536312\n",
      "timeframe: 1 section: 336 alpha: 37.17517187626529\n",
      "timeframe: 1 section: 245 alpha: 61.00782542928356\n",
      "timeframe: 2 section: 171 alpha: 26.939793123557774\n",
      "timeframe: 1 section: 356 alpha: 30.146086807417277\n",
      "timeframe: 1 section: 475 alpha: 15.998511757030412\n",
      "timeframe: 2 section: 191 alpha: 46.85639718342539\n",
      "timeframe: 2 section: 268 alpha: 9.690341110935655\n",
      "timeframe: 1 section: 217 alpha: 24.694424080554697\n",
      "timeframe: 1 section: 343 alpha: 21.24686003023584\n",
      "timeframe: 2 section: 10 alpha: 2.053581021521457\n",
      "timeframe: 1 section: 525 alpha: 60.67255040292375\n",
      "timeframe: 2 section: 3 alpha: 23.75939152073207\n",
      "timeframe: 1 section: 231 alpha: 16.297356798751824\n",
      "timeframe: 2 section: 240 alpha: 19.759370326362873\n",
      "timeframe: 2 section: 80 alpha: 18.2249725544339\n",
      "timeframe: 1 section: 210 alpha: 13.303861502742288\n",
      "timeframe: 1 section: 441 alpha: 30.21570682798321\n",
      "timeframe: 2 section: 65 alpha: 34.09262081521984\n",
      "timeframe: 1 section: 469 alpha: 36.168782893323744\n",
      "timeframe: 1 section: 162 alpha: 13.676149011052775\n",
      "timeframe: 2 section: 18 alpha: 41.74004414190007\n",
      "timeframe: 1 section: 393 alpha: 18.049562067204842\n",
      "timeframe: 2 section: 261 alpha: 12.509575696021717\n",
      "timeframe: 2 section: 254 alpha: 8.089487943443991\n",
      "timeframe: 1 section: 294 alpha: 19.993598631950956\n",
      "timeframe: 1 section: 301 alpha: 13.10244450328055\n",
      "timeframe: 1 section: 266 alpha: 19.921094788164343\n",
      "timeframe: 1 section: 483 alpha: 30.81939851654023\n",
      "timeframe: 2 section: 59 alpha: 13.215557409704385\n",
      "timeframe: 1 section: 511 alpha: 25.372243760519346\n",
      "timeframe: 1 section: 203 alpha: 22.071112468334313\n",
      "timeframe: 1 section: 329 alpha: 15.568352593536558\n",
      "timeframe: 1 section: 182 alpha: 25.152427433985544\n",
      "timeframe: 1 section: 273 alpha: 18.251514350231176\n",
      "timeframe: 1 section: 175 alpha: 21.186108210491817\n",
      "timeframe: 2 section: 206 alpha: 71.43026683598298\n",
      "timeframe: 1 section: 224 alpha: 25.839503046491206\n",
      "timeframe: 1 section: 406 alpha: 50.412096612171695\n",
      "timeframe: 2 section: 94 alpha: 17.2218539128019\n",
      "timeframe: 1 section: 155 alpha: 16.120322312350673\n",
      "timeframe: 1 section: 378 alpha: 5.040835672366839\n",
      "timeframe: 2 section: 281 alpha: 80.98781092276951\n",
      "timeframe: 2 section: 163 alpha: 24.016356693180285\n",
      "timeframe: 1 section: 413 alpha: 17.077876396199304\n",
      "timeframe: 2 section: 150 alpha: 36.84643048608933\n",
      "timeframe: 1 section: 287 alpha: 25.509094282314678\n",
      "timeframe: 1 section: 427 alpha: 62.110601473197214\n",
      "timeframe: 1 section: 350 alpha: 23.146104612557416\n",
      "timeframe: 1 section: 197 alpha: 21.568346491657753\n",
      "timeframe: 1 section: 455 alpha: 23.271839498160983\n",
      "timeframe: 2 section: 157 alpha: 13.37371398294266\n",
      "timeframe: 1 section: 238 alpha: 26.14836451731281\n",
      "timeframe: 1 section: 420 alpha: 12.86813260166316\n",
      "timeframe: 2 section: 31 alpha: 14.933459546798778\n",
      "timeframe: 2 section: 212 alpha: 45.883949772807114\n",
      "timeframe: 2 section: 87 alpha: 37.5140133308953\n",
      "timeframe: 2 section: 226 alpha: 43.06662308098646\n",
      "timeframe: 1 section: 553 alpha: 34.28257436116043\n",
      "timeframe: 1 section: 462 alpha: 11.554171035588366\n",
      "timeframe: 2 section: 247 alpha: 58.95416315066123\n",
      "timeframe: 1 section: 435 alpha: 10.614257395706383\n",
      "timeframe: 1 section: 322 alpha: 48.145983619415894\n",
      "timeframe: 1 section: 149 alpha: 12.128498184395921\n",
      "timeframe: 2 section: 219 alpha: 14.79500498620871\n",
      "timeframe: 2 section: 129 alpha: 27.76612538868911\n",
      "timeframe: 2 section: 198 alpha: 23.487056417942195\n",
      "timeframe: 1 section: 280 alpha: 28.775001976873035\n",
      "timeframe: 1 section: 372 alpha: 34.613426044068945\n",
      "timeframe: 1 section: 546 alpha: 18.628163072878905\n",
      "timeframe: 1 section: 490 alpha: 20.27709650989079\n",
      "timeframe: 1 section: 169 alpha: 27.182881552376372\n",
      "timeframe: 1 section: 316 alpha: 30.920265753817002\n",
      "timeframe: 1 section: 497 alpha: 30.456144554576852\n",
      "timeframe: 1 section: 448 alpha: 28.07976123890499\n",
      "timeframe: 1 section: 254 alpha: 15.294178593756506\n",
      "timeframe: 2 section: 39 alpha: 8.761482321789762\n",
      "timeframe: 2 section: 275 alpha: 10.355434506857224\n",
      "timeframe: 1 section: 385 alpha: 24.438180605399015\n",
      "timeframe: 1 section: 308 alpha: 23.77330191349095\n",
      "timeframe: 2 section: 53 alpha: 43.192524491673886\n",
      "timeframe: 2 section: 122 alpha: 20.717099107866368\n",
      "timeframe: 2 section: 177 alpha: 21.3526086949127\n",
      "timeframe: 2 section: 101 alpha: 15.902987995671147\n",
      "timeframe: 2 section: 185 alpha: 13.3116045357814\n",
      "timeframe: 2 section: 73 alpha: 0.07153162068555032\n",
      "timeframe: 1 section: 539 alpha: 9.192087416030922\n",
      "timeframe: 1 section: 337 alpha: 17.247269092343096\n",
      "timeframe: 1 section: 364 alpha: 24.430784746920953\n",
      "timeframe: 1 section: 505 alpha: 11.861622923301795\n",
      "timeframe: 1 section: 204 alpha: 30.624218533667307\n",
      "timeframe: 1 section: 532 alpha: 13.343525784721\n",
      "timeframe: 2 section: 60 alpha: 14.065476541851893\n",
      "timeframe: 2 section: 108 alpha: 15.735145998651415\n",
      "timeframe: 1 section: 512 alpha: 120.86890208097309\n",
      "timeframe: 1 section: 357 alpha: 24.988130337551702\n",
      "timeframe: 1 section: 518 alpha: 22.507641915161535\n",
      "timeframe: 2 section: 19 alpha: 52.676132198355255\n",
      "timeframe: 1 section: 476 alpha: 22.967401501239806\n",
      "timeframe: 1 section: 163 alpha: 25.557444064162958\n",
      "timeframe: 1 section: 156 alpha: 44.51081320497248\n",
      "timeframe: 1 section: 267 alpha: 142.56447040241727\n",
      "timeframe: 1 section: 232 alpha: 22.77829595034465\n",
      "timeframe: 1 section: 260 alpha: 17.037490600372255\n",
      "timeframe: 2 section: 241 alpha: 42.856216387701984\n",
      "timeframe: 1 section: 344 alpha: 14.93122629275026\n",
      "timeframe: 1 section: 399 alpha: 16.37714143318872\n",
      "timeframe: 1 section: 190 alpha: 23.854375103205342\n",
      "timeframe: 2 section: 269 alpha: 28.33989378458569\n",
      "timeframe: 1 section: 225 alpha: 23.14623905926651\n",
      "timeframe: 1 section: 526 alpha: 18.256024858318597\n",
      "timeframe: 2 section: 25 alpha: 16.440276242456633\n",
      "timeframe: 2 section: 45 alpha: 18.156538152487656\n",
      "timeframe: 1 section: 211 alpha: 27.874594270262666\n",
      "timeframe: 1 section: 246 alpha: 26.040817301285966\n",
      "timeframe: 1 section: 183 alpha: 46.4418391078833\n",
      "timeframe: 1 section: 330 alpha: 7.029213196946473\n",
      "timeframe: 2 section: 81 alpha: 13.071430971853808\n",
      "timeframe: 2 section: 66 alpha: 37.81780217199218\n",
      "timeframe: 2 section: 136 alpha: 18.37032148344595\n",
      "timeframe: 1 section: 274 alpha: 5.732065047226923\n",
      "timeframe: 1 section: 484 alpha: 30.692904151702198\n",
      "timeframe: 1 section: 414 alpha: 14.801080596445885\n",
      "timeframe: 1 section: 436 alpha: 36.740305269383406\n",
      "timeframe: 2 section: 4 alpha: 23.67583512133441\n",
      "timeframe: 1 section: 239 alpha: 23.66183664134373\n",
      "timeframe: 1 section: 407 alpha: 50.316680049677124\n",
      "timeframe: 1 section: 176 alpha: 45.72780052038666\n",
      "timeframe: 1 section: 302 alpha: 13.645826650953941\n",
      "timeframe: 1 section: 442 alpha: 13.981681948575973\n",
      "timeframe: 1 section: 456 alpha: 27.314162030387674\n",
      "timeframe: 1 section: 317 alpha: 14.433130212878922\n",
      "timeframe: 1 section: 470 alpha: 24.300985083270092\n",
      "timeframe: 1 section: 351 alpha: 32.043564393968715\n",
      "timeframe: 1 section: 295 alpha: 11.496155539094605\n",
      "timeframe: 1 section: 170 alpha: 35.94393407109937\n",
      "timeframe: 2 section: 255 alpha: 96.5499908189353\n",
      "timeframe: 2 section: 123 alpha: 31.993516440238526\n",
      "timeframe: 1 section: 218 alpha: 20.113991622729113\n",
      "timeframe: 1 section: 394 alpha: 9.146120389715412\n",
      "timeframe: 1 section: 198 alpha: 18.376252838820623\n",
      "timeframe: 2 section: 248 alpha: 34.18605440004701\n",
      "timeframe: 2 section: 95 alpha: 13.22902410045708\n",
      "timeframe: 1 section: 373 alpha: 6.8770415019107745\n",
      "timeframe: 2 section: 234 alpha: 10.594942784238949\n",
      "timeframe: 1 section: 463 alpha: 46.02515954846311\n",
      "timeframe: 1 section: 379 alpha: 7.621104495595128\n",
      "timeframe: 1 section: 554 alpha: 19.039550554985595\n",
      "timeframe: 1 section: 547 alpha: 10.976289090712488\n",
      "timeframe: 2 section: 276 alpha: 21.4855116497053\n",
      "timeframe: 1 section: 281 alpha: 29.969736645257225\n",
      "timeframe: 2 section: 32 alpha: 41.31193452152078\n",
      "timeframe: 2 section: 172 alpha: 31.344286257084775\n",
      "timeframe: 1 section: 428 alpha: 34.05827888424823\n",
      "timeframe: 1 section: 205 alpha: 28.828582651772606\n",
      "timeframe: 2 section: 192 alpha: 18.94575772079014\n",
      "timeframe: 2 section: 143 alpha: 39.70878756000179\n",
      "timeframe: 1 section: 498 alpha: 31.14895548459849\n",
      "timeframe: 1 section: 386 alpha: 26.971661162074025\n",
      "timeframe: 2 section: 74 alpha: 15.641715866624576\n",
      "timeframe: 1 section: 323 alpha: 41.94542081417378\n",
      "timeframe: 1 section: 491 alpha: 34.218230789596475\n",
      "timeframe: 1 section: 421 alpha: 20.155079845497205\n",
      "timeframe: 2 section: 151 alpha: 35.672310897676674\n",
      "timeframe: 1 section: 268 alpha: 13.41988716881941\n",
      "timeframe: 1 section: 506 alpha: 41.78069433494101\n",
      "timeframe: 2 section: 11 alpha: 7.759588768193784\n",
      "timeframe: 1 section: 255 alpha: 16.79390040518987\n",
      "timeframe: 1 section: 261 alpha: 9.28064050060248\n",
      "timeframe: 2 section: 158 alpha: 64.83802345221433\n",
      "timeframe: 2 section: 54 alpha: 21.222872434375347\n",
      "timeframe: 1 section: 513 alpha: 18.105655566977564\n",
      "timeframe: 1 section: 150 alpha: 14.401577152821044\n",
      "timeframe: 2 section: 213 alpha: 25.22386400897521\n",
      "timeframe: 1 section: 358 alpha: 7.0733007222032365\n",
      "timeframe: 1 section: 275 alpha: 0.6230566540000955\n",
      "timeframe: 1 section: 233 alpha: 3.3740516504514533\n",
      "timeframe: 2 section: 207 alpha: 27.803467777556143\n",
      "timeframe: 2 section: 164 alpha: 64.26748286517808\n",
      "timeframe: 1 section: 288 alpha: 24.089440111786576\n",
      "timeframe: 2 section: 178 alpha: 26.721670628970475\n",
      "timeframe: 2 section: 227 alpha: 19.244643965926173\n",
      "timeframe: 2 section: 242 alpha: 19.640225077544414\n",
      "timeframe: 2 section: 82 alpha: 31.872611084979972\n",
      "timeframe: 1 section: 345 alpha: 33.26009899969295\n",
      "timeframe: 1 section: 437 alpha: 19.83976225900481\n",
      "timeframe: 2 section: 262 alpha: 25.87428931966713\n",
      "timeframe: 1 section: 338 alpha: 18.80157326059433\n",
      "timeframe: 2 section: 67 alpha: 35.13432717470852\n",
      "timeframe: 1 section: 191 alpha: 27.03720720149982\n",
      "timeframe: 2 section: 130 alpha: 13.301037525042986\n",
      "timeframe: 2 section: 220 alpha: 18.726754749648926\n",
      "timeframe: 2 section: 137 alpha: 35.49480525252873\n",
      "timeframe: 1 section: 533 alpha: 24.438526027765484\n",
      "timeframe: 1 section: 365 alpha: 41.36274798167893\n",
      "timeframe: 1 section: 449 alpha: 18.045295213371617\n",
      "timeframe: 1 section: 226 alpha: 23.63085130939712\n",
      "timeframe: 2 section: 186 alpha: 44.13779558501139\n",
      "timeframe: 1 section: 485 alpha: 21.362032585289707\n",
      "timeframe: 1 section: 164 alpha: 13.090269044770753\n",
      "timeframe: 1 section: 477 alpha: 45.94546061937789\n",
      "timeframe: 1 section: 400 alpha: 3.5082662430620317\n",
      "timeframe: 1 section: 540 alpha: 25.40465717904508\n",
      "timeframe: 2 section: 61 alpha: 6.3108801601206075\n",
      "timeframe: 1 section: 519 alpha: 10.520719574759397\n",
      "timeframe: 1 section: 157 alpha: 16.79386365808232\n",
      "timeframe: 2 section: 249 alpha: 22.539482953980638\n",
      "timeframe: 1 section: 296 alpha: 15.467271387914371\n",
      "timeframe: 1 section: 247 alpha: 12.81496254020314\n",
      "timeframe: 2 section: 282 alpha: 46.69716447444952\n",
      "timeframe: 1 section: 240 alpha: 13.061099246952223\n",
      "timeframe: 2 section: 102 alpha: 43.141162385693505\n",
      "timeframe: 1 section: 380 alpha: 30.93922303305201\n",
      "timeframe: 2 section: 199 alpha: 27.085138182608127\n",
      "timeframe: 1 section: 318 alpha: 7.922723666254957\n",
      "timeframe: 1 section: 457 alpha: 24.046955738930592\n",
      "timeframe: 1 section: 309 alpha: 30.618702801928805\n",
      "timeframe: 1 section: 331 alpha: 11.393475882207799\n",
      "timeframe: 2 section: 40 alpha: 45.75192419844964\n",
      "timeframe: 1 section: 184 alpha: 39.040133221966464\n",
      "timeframe: 1 section: 507 alpha: 5.777947483662034\n",
      "timeframe: 1 section: 548 alpha: 32.80769895437275\n",
      "timeframe: 1 section: 527 alpha: 36.46182308681542\n",
      "timeframe: 1 section: 415 alpha: 30.000701313318448\n",
      "timeframe: 1 section: 422 alpha: 30.660438486047195\n",
      "timeframe: 1 section: 471 alpha: 30.571031932005443\n",
      "timeframe: 2 section: 277 alpha: 6.207503453984217\n",
      "timeframe: 2 section: 5 alpha: 22.66031362444414\n",
      "timeframe: 1 section: 555 alpha: 27.785140217564116\n",
      "timeframe: 2 section: 193 alpha: 14.802489861453017\n",
      "timeframe: 1 section: 199 alpha: 20.786016531581986\n",
      "timeframe: 1 section: 276 alpha: 4.534179702924347\n",
      "timeframe: 1 section: 352 alpha: 14.787765070349305\n",
      "timeframe: 1 section: 269 alpha: 45.10530842231748\n",
      "timeframe: 1 section: 408 alpha: 23.609513623742064\n",
      "timeframe: 2 section: 20 alpha: 10.110655514217902\n",
      "timeframe: 2 section: 26 alpha: 10.25967967080304\n",
      "timeframe: 1 section: 374 alpha: 32.6498514299474\n",
      "timeframe: 1 section: 395 alpha: 25.418404494401493\n",
      "timeframe: 1 section: 429 alpha: 25.83110050846717\n",
      "timeframe: 2 section: 270 alpha: 29.456970494807376\n",
      "timeframe: 1 section: 499 alpha: 14.833775112612068\n",
      "timeframe: 1 section: 219 alpha: 6.922386198746823\n",
      "timeframe: 2 section: 109 alpha: 42.37267554966221\n",
      "timeframe: 1 section: 464 alpha: 8.500389572371478\n",
      "timeframe: 2 section: 159 alpha: 24.350004505714452\n",
      "timeframe: 1 section: 212 alpha: 29.052364258294627\n",
      "timeframe: 1 section: 324 alpha: 33.6433706383134\n",
      "timeframe: 1 section: 492 alpha: 33.702901019703646\n",
      "timeframe: 1 section: 359 alpha: 10.304791007572343\n",
      "timeframe: 1 section: 206 alpha: 34.16150711842147\n",
      "timeframe: 1 section: 450 alpha: 20.137831079407388\n",
      "timeframe: 1 section: 171 alpha: 38.49126751634045\n",
      "timeframe: 2 section: 46 alpha: 18.38447262502289\n",
      "timeframe: 1 section: 282 alpha: 16.29406581160242\n",
      "timeframe: 2 section: 115 alpha: 53.94782273766732\n",
      "timeframe: 2 section: 144 alpha: 10.48374791761311\n",
      "timeframe: 1 section: 443 alpha: 27.619781105917802\n",
      "timeframe: 1 section: 192 alpha: 13.463956584562288\n",
      "timeframe: 2 section: 88 alpha: 30.92477721917159\n",
      "timeframe: 1 section: 303 alpha: 46.39299637437969\n",
      "timeframe: 2 section: 124 alpha: 17.089513210790578\n",
      "timeframe: 1 section: 514 alpha: 23.08541137223455\n",
      "timeframe: 2 section: 55 alpha: 5.812886120463306\n",
      "timeframe: 2 section: 256 alpha: 56.817139694687235\n",
      "timeframe: 1 section: 234 alpha: 29.51073062815641\n",
      "timeframe: 1 section: 387 alpha: 31.124708006504193\n",
      "timeframe: 1 section: 289 alpha: 32.59137034505263\n",
      "timeframe: 2 section: 173 alpha: 15.245528967874712\n",
      "timeframe: 1 section: 177 alpha: 43.26832736742588\n",
      "timeframe: 1 section: 227 alpha: 10.442027188744008\n",
      "timeframe: 1 section: 346 alpha: 23.43022664134672\n",
      "timeframe: 1 section: 541 alpha: 8.792668882244659\n",
      "timeframe: 1 section: 520 alpha: 11.549015660082807\n",
      "timeframe: 1 section: 262 alpha: 30.1443839079947\n",
      "timeframe: 2 section: 96 alpha: 11.956014633106602\n",
      "timeframe: 1 section: 486 alpha: 19.539067348369926\n",
      "timeframe: 2 section: 165 alpha: 25.268825886606276\n",
      "timeframe: 2 section: 12 alpha: 25.832057284753283\n",
      "timeframe: 1 section: 366 alpha: 20.429865103546522\n",
      "timeframe: 2 section: 214 alpha: 11.255237606676506\n",
      "timeframe: 2 section: 138 alpha: 14.562637801896388\n",
      "timeframe: 1 section: 430 alpha: 13.371536281328593\n",
      "timeframe: 1 section: 534 alpha: 28.31282795439347\n",
      "timeframe: 2 section: 179 alpha: 19.71602909190644\n",
      "timeframe: 2 section: 221 alpha: 30.32506558471125\n",
      "timeframe: 2 section: 302 alpha: 4.901980037334073\n",
      "timeframe: 2 section: 152 alpha: 31.44695132954509\n",
      "timeframe: 2 section: 83 alpha: 35.96106331764213\n",
      "timeframe: 1 section: 332 alpha: 8.684168483792035\n",
      "timeframe: 1 section: 381 alpha: 18.65414054093332\n",
      "timeframe: 1 section: 241 alpha: 32.50403927677215\n",
      "timeframe: 2 section: 33 alpha: 40.02000154587825\n",
      "timeframe: 2 section: 68 alpha: 5.949644120283858\n",
      "timeframe: 1 section: 297 alpha: 18.34553846410854\n",
      "timeframe: 1 section: 458 alpha: 19.244263249978292\n",
      "timeframe: 2 section: 75 alpha: 36.8253699854\n",
      "timeframe: 1 section: 549 alpha: 15.14432012983672\n",
      "timeframe: 2 section: 62 alpha: 15.28771264680896\n",
      "timeframe: 1 section: 339 alpha: 22.09258868993345\n",
      "timeframe: 1 section: 401 alpha: 27.835787116721356\n",
      "timeframe: 2 section: 131 alpha: 20.932814677549146\n",
      "timeframe: 1 section: 185 alpha: 12.871487793642848\n",
      "timeframe: 2 section: 235 alpha: 16.01349831746031\n",
      "timeframe: 2 section: 250 alpha: 38.202515511657396\n",
      "timeframe: 2 section: 200 alpha: 10.817693574239499\n",
      "timeframe: 2 section: 208 alpha: 15.964850459304387\n",
      "timeframe: 2 section: 288 alpha: 27.519235869304882\n",
      "timeframe: 2 section: 330 alpha: 0.11513894733080586\n",
      "timeframe: 1 section: 451 alpha: 25.518271367638174\n",
      "timeframe: 2 section: 358 alpha: 61.6620280215463\n",
      "timeframe: 2 section: 243 alpha: 47.885422230063206\n",
      "timeframe: 2 section: 263 alpha: 32.3086328370581\n",
      "timeframe: 1 section: 310 alpha: 56.05072796040979\n",
      "timeframe: 2 section: 309 alpha: 24.99682238269183\n",
      "timeframe: 1 section: 416 alpha: 26.577830715243802\n",
      "timeframe: 1 section: 423 alpha: 32.236419162066134\n",
      "timeframe: 1 section: 248 alpha: 19.481963527026355\n",
      "timeframe: 2 section: 228 alpha: 15.886451880098171\n",
      "timeframe: 2 section: 271 alpha: 30.154893563829894\n",
      "timeframe: 1 section: 472 alpha: 41.48459367346186\n",
      "timeframe: 2 section: 337 alpha: 20.035686848402417\n",
      "timeframe: 2 section: 316 alpha: 74.22851066991868\n",
      "timeframe: 2 section: 257 alpha: 16.843659758602332\n",
      "timeframe: 2 section: 160 alpha: 26.49241153929628\n",
      "timeframe: 2 section: 145 alpha: 57.3238499548421\n",
      "timeframe: 2 section: 372 alpha: 26.836334353935097\n",
      "timeframe: 1 section: 478 alpha: 21.337908461530606\n",
      "timeframe: 1 section: 353 alpha: 24.510642108221464\n",
      "timeframe: 1 section: 409 alpha: 23.971443583233846\n",
      "timeframe: 1 section: 360 alpha: 9.813052957312863\n",
      "timeframe: 1 section: 528 alpha: 24.88047427253543\n",
      "timeframe: 2 section: 187 alpha: 28.466820646958862\n",
      "timeframe: 1 section: 325 alpha: 28.328439870728083\n",
      "timeframe: 2 section: 27 alpha: 11.770307450382482\n",
      "timeframe: 1 section: 500 alpha: 30.540979176475\n",
      "timeframe: 2 section: 194 alpha: 18.013847299266345\n",
      "timeframe: 1 section: 465 alpha: 16.014530329660854\n",
      "timeframe: 1 section: 283 alpha: 38.82887088816222\n",
      "timeframe: 2 section: 295 alpha: 18.000945228527367\n",
      "timeframe: 2 section: 379 alpha: 20.46257896227869\n",
      "timeframe: 2 section: 365 alpha: 18.019940979169753\n",
      "timeframe: 2 section: 323 alpha: 56.9870034875844\n",
      "timeframe: 2 section: 278 alpha: 11.750389640300861\n",
      "timeframe: 2 section: 351 alpha: 50.574764103175134\n",
      "timeframe: 1 section: 388 alpha: 21.855192213854643\n",
      "timeframe: 2 section: 400 alpha: 9.750749953838616\n",
      "timeframe: 1 section: 444 alpha: 22.540258173362712\n",
      "timeframe: 2 section: 103 alpha: 42.20402985434506\n",
      "timeframe: 2 section: 6 alpha: 14.976740304756547\n",
      "timeframe: 1 section: 213 alpha: 19.916638947746197\n",
      "timeframe: 1 section: 220 alpha: 13.132236637637684\n",
      "timeframe: 1 section: 290 alpha: 18.03745035314064\n",
      "timeframe: 2 section: 393 alpha: 22.10332897180949\n",
      "timeframe: 1 section: 178 alpha: 18.16517970329182\n",
      "timeframe: 1 section: 535 alpha: 17.372918460483312\n",
      "timeframe: 2 section: 21 alpha: 19.582500752382497\n",
      "timeframe: 2 section: 125 alpha: 19.47768225552962\n",
      "timeframe: 2 section: 0 alpha: 22.791007900058176\n",
      "timeframe: 2 section: 283 alpha: 32.764356873871435\n",
      "timeframe: 2 section: 41 alpha: 41.209629891994304\n",
      "timeframe: 2 section: 110 alpha: 12.422661541308198\n",
      "timeframe: 1 section: 304 alpha: 50.633838270667006\n",
      "timeframe: 2 section: 435 alpha: 10.534523606278324\n",
      "timeframe: 1 section: 542 alpha: 22.31350962269167\n",
      "timeframe: 2 section: 34 alpha: 41.445418188645654\n",
      "timeframe: 2 section: 56 alpha: 24.132598017425046\n",
      "timeframe: 1 section: 521 alpha: 29.794129518117387\n",
      "timeframe: 2 section: 47 alpha: 11.626501364520648\n",
      "timeframe: 2 section: 116 alpha: 40.92120132772147\n",
      "timeframe: 2 section: 244 alpha: 6.601030765892766\n",
      "timeframe: 1 section: 493 alpha: 19.310777781482447\n",
      "timeframe: 2 section: 421 alpha: 18.76437809450842\n",
      "timeframe: 2 section: 344 alpha: 13.225027506452381\n",
      "timeframe: 2 section: 373 alpha: 16.053070133172643\n",
      "timeframe: 2 section: 174 alpha: 11.71487666264793\n",
      "timeframe: 2 section: 180 alpha: 40.55562437815558\n",
      "timeframe: 2 section: 442 alpha: 10.65261026493482\n",
      "timeframe: 2 section: 258 alpha: 58.73485382600498\n",
      "timeframe: 2 section: 264 alpha: 6.1435635744061745\n",
      "timeframe: 2 section: 386 alpha: 23.28893657914104\n",
      "timeframe: 1 section: 367 alpha: 21.368314552534713\n",
      "timeframe: 2 section: 414 alpha: 37.931583241556005\n",
      "timeframe: 1 section: 402 alpha: 31.041821642204695\n",
      "timeframe: 2 section: 449 alpha: 21.72416062563762\n",
      "timeframe: 2 section: 407 alpha: 52.48364130482851\n",
      "timeframe: 2 section: 463 alpha: 65.79666056543773\n",
      "timeframe: 2 section: 491 alpha: 32.852271891083724\n",
      "timeframe: 2 section: 89 alpha: 27.813587074371657\n",
      "timeframe: 2 section: 380 alpha: 14.194645089303641\n",
      "timeframe: 2 section: 153 alpha: 36.7341746913963\n",
      "timeframe: 2 section: 166 alpha: 37.941986229199415\n",
      "timeframe: 2 section: 338 alpha: 10.197765873316085\n",
      "timeframe: 2 section: 215 alpha: 30.832917805581765\n",
      "timeframe: 2 section: 331 alpha: 12.531425968201276\n",
      "timeframe: 2 section: 139 alpha: 11.472434992536236\n",
      "timeframe: 2 section: 146 alpha: 7.432471698661496\n",
      "timeframe: 2 section: 97 alpha: 21.091705316507497\n",
      "timeframe: 2 section: 512 alpha: 14.520723755141109\n",
      "timeframe: 2 section: 303 alpha: 25.904007033577848\n",
      "timeframe: 2 section: 456 alpha: 12.649895095294376\n",
      "timeframe: 2 section: 13 alpha: 59.01225973046023\n",
      "timeframe: 1 section: 479 alpha: 6.926464993400979\n",
      "timeframe: 2 section: 209 alpha: 25.97698276058564\n",
      "timeframe: 2 section: 104 alpha: 43.29389443695751\n",
      "timeframe: 2 section: 317 alpha: 20.922099844129967\n",
      "timeframe: 3 section: 5 alpha: 0.41737403492745956\n",
      "timeframe: 2 section: 251 alpha: 17.753439960490542\n",
      "timeframe: 1 section: 311 alpha: 22.3020694300224\n",
      "timeframe: 2 section: 272 alpha: 18.03723648169562\n",
      "timeframe: 2 section: 201 alpha: 64.18959793089662\n",
      "timeframe: 2 section: 310 alpha: 19.024682056989565\n",
      "timeframe: 2 section: 519 alpha: 10.789664166526137\n",
      "timeframe: 2 section: 505 alpha: 17.739786953471903\n",
      "timeframe: 2 section: 289 alpha: 17.644138059445638\n",
      "timeframe: 3 section: 82 alpha: 39.49181220023859\n",
      "timeframe: 2 section: 132 alpha: 13.529517936881186\n",
      "timeframe: 2 section: 484 alpha: 22.327047961219254\n",
      "timeframe: 2 section: 428 alpha: 22.52498654306995\n",
      "timeframe: 2 section: 245 alpha: 32.65063849091136\n",
      "timeframe: 2 section: 470 alpha: 8.799683825569845\n",
      "timeframe: 2 section: 436 alpha: 9.333027453047626\n",
      "timeframe: 2 section: 63 alpha: 12.019103911810388\n",
      "timeframe: 2 section: 161 alpha: 12.878206639598963\n",
      "timeframe: 2 section: 498 alpha: 48.32168992566313\n",
      "timeframe: 2 section: 126 alpha: 76.47796010902111\n",
      "timeframe: 3 section: 19 alpha: 19.55614018740912\n",
      "timeframe: 3 section: 12 alpha: 21.808632380658572\n",
      "timeframe: 2 section: 352 alpha: 48.89236664218977\n",
      "timeframe: 2 section: 229 alpha: 42.61405906836659\n",
      "timeframe: 2 section: 324 alpha: 14.233714685599798\n",
      "timeframe: 2 section: 69 alpha: 11.124646434604083\n",
      "timeframe: 2 section: 422 alpha: 29.696372466123464\n",
      "timeframe: 2 section: 477 alpha: 60.669132889583125\n",
      "timeframe: 2 section: 84 alpha: 32.39735552124286\n",
      "timeframe: 2 section: 359 alpha: 28.595426844338643\n",
      "timeframe: 2 section: 222 alpha: 54.28250505580453\n",
      "timeframe: 2 section: 366 alpha: 74.31995781944299\n",
      "timeframe: 2 section: 181 alpha: 24.601532394005435\n",
      "timeframe: 3 section: 54 alpha: 42.76354714861761\n",
      "timeframe: 2 section: 188 alpha: 35.00602156524012\n",
      "timeframe: 2 section: 533 alpha: 21.045788694799302\n",
      "timeframe: 2 section: 28 alpha: 42.37117376596227\n",
      "timeframe: 3 section: 61 alpha: 15.978188759100897\n",
      "timeframe: 2 section: 7 alpha: 27.732313678742564\n",
      "timeframe: 2 section: 394 alpha: 27.59327140102818\n",
      "timeframe: 3 section: 26 alpha: 11.408186984861894\n",
      "timeframe: 2 section: 76 alpha: 66.26408917058286\n",
      "timeframe: 2 section: 35 alpha: 23.96559857178781\n",
      "timeframe: 2 section: 443 alpha: 29.930783085596893\n",
      "timeframe: 2 section: 265 alpha: 4.009054079676756\n",
      "timeframe: 2 section: 345 alpha: 30.62065516836107\n",
      "timeframe: 2 section: 374 alpha: 15.032351017418316\n",
      "timeframe: 3 section: 47 alpha: 11.394962261463519\n",
      "timeframe: 2 section: 526 alpha: 33.810298466542854\n",
      "timeframe: 3 section: 145 alpha: 35.77661872401881\n",
      "timeframe: 3 section: 96 alpha: 22.91441705926424\n",
      "timeframe: 2 section: 195 alpha: 24.347399942424158\n",
      "timeframe: 2 section: 14 alpha: 28.96395299980698\n",
      "timeframe: 2 section: 450 alpha: 5.581509024478251\n",
      "timeframe: 2 section: 154 alpha: 8.130665929748277\n",
      "timeframe: 2 section: 105 alpha: 8.436764942926573\n",
      "timeframe: 2 section: 48 alpha: 4.015593496214981\n",
      "timeframe: 3 section: 68 alpha: 6.418712166821616\n",
      "timeframe: 2 section: 401 alpha: 26.27759250556272\n",
      "timeframe: 2 section: 279 alpha: 23.783754165340852\n",
      "timeframe: 2 section: 339 alpha: 11.666066409041779\n",
      "timeframe: 2 section: 236 alpha: 32.99403497773699\n",
      "timeframe: 2 section: 296 alpha: 49.782005005536135\n",
      "timeframe: 2 section: 42 alpha: 29.030799842539647\n",
      "timeframe: 2 section: 429 alpha: 45.93753410623391\n",
      "timeframe: 2 section: 540 alpha: 37.725708910796286\n",
      "timeframe: 2 section: 554 alpha: 12.51152483876142\n",
      "timeframe: 3 section: 103 alpha: 24.732201287120272\n",
      "timeframe: 3 section: 40 alpha: 31.79521841248843\n",
      "timeframe: 2 section: 147 alpha: 30.72603750514523\n",
      "timeframe: 3 section: 33 alpha: 26.565942183365713\n",
      "timeframe: 2 section: 70 alpha: 46.24735714280318\n",
      "timeframe: 2 section: 210 alpha: 15.924758060828777\n",
      "timeframe: 2 section: 284 alpha: 27.735300791873744\n",
      "timeframe: 2 section: 111 alpha: 28.43501827541854\n",
      "timeframe: 2 section: 547 alpha: 9.490164880710973\n",
      "timeframe: 2 section: 117 alpha: 19.762547366347814\n",
      "timeframe: 2 section: 216 alpha: 83.41266246307028\n",
      "timeframe: 2 section: 259 alpha: 136.4402613589485\n",
      "timeframe: 3 section: 124 alpha: 19.124614798729027\n",
      "timeframe: 2 section: 252 alpha: 55.139299369835\n",
      "timeframe: 2 section: 437 alpha: 24.647476252436824\n",
      "timeframe: 3 section: 89 alpha: 30.34314317980393\n",
      "timeframe: 2 section: 175 alpha: 46.947448398837146\n",
      "timeframe: 2 section: 304 alpha: 33.87726041234151\n",
      "timeframe: 2 section: 332 alpha: 4.407662339583215\n",
      "timeframe: 2 section: 471 alpha: 37.926932137153415\n",
      "timeframe: 3 section: 117 alpha: 57.55613336888079\n",
      "timeframe: 3 section: 75 alpha: 55.20440821999749\n",
      "timeframe: 2 section: 464 alpha: 8.700275557056004\n",
      "timeframe: 3 section: 55 alpha: 4.404401109194192\n",
      "timeframe: 2 section: 506 alpha: 23.89395408962022\n",
      "timeframe: 2 section: 387 alpha: 12.886134319131532\n",
      "timeframe: 2 section: 90 alpha: 51.63666786434038\n",
      "timeframe: 2 section: 140 alpha: 46.70222171216298\n",
      "timeframe: 2 section: 520 alpha: 8.759750286326724\n",
      "timeframe: 2 section: 513 alpha: 31.684877782044623\n",
      "timeframe: 2 section: 98 alpha: 84.94123132306667\n",
      "timeframe: 2 section: 444 alpha: 25.00254271839064\n",
      "timeframe: 2 section: 457 alpha: 27.469746808688882\n",
      "timeframe: 2 section: 408 alpha: 28.180895451193752\n",
      "timeframe: 2 section: 311 alpha: 40.90009774156755\n",
      "timeframe: 2 section: 492 alpha: 35.77803938226901\n",
      "timeframe: 2 section: 318 alpha: 9.939300717442597\n",
      "timeframe: 2 section: 395 alpha: 13.066223336721015\n",
      "timeframe: 3 section: 159 alpha: 1.3808690338436884\n",
      "timeframe: 2 section: 430 alpha: 50.94401004963951\n",
      "timeframe: 2 section: 49 alpha: 27.041056922415475\n",
      "timeframe: 2 section: 290 alpha: 11.57038050180437\n",
      "timeframe: 3 section: 131 alpha: 27.120508582326973\n",
      "timeframe: 2 section: 360 alpha: 7.851893806375671\n",
      "timeframe: 2 section: 273 alpha: 20.556047188725433\n",
      "timeframe: 2 section: 133 alpha: 65.91989688145891\n",
      "timeframe: 2 section: 415 alpha: 79.88219551889442\n",
      "timeframe: 2 section: 375 alpha: 8.192345917777741\n",
      "timeframe: 3 section: 110 alpha: 41.55417702149888\n",
      "timeframe: 3 section: 138 alpha: 22.59318156676389\n",
      "timeframe: 2 section: 485 alpha: 8.618699433651111\n",
      "timeframe: 3 section: 83 alpha: 13.876738644601648\n",
      "timeframe: 2 section: 423 alpha: 35.52072998545902\n",
      "timeframe: 3 section: 27 alpha: 161.98734611409847\n",
      "timeframe: 3 section: 173 alpha: 34.81304035691426\n",
      "timeframe: 3 section: 152 alpha: 25.649838506382\n",
      "timeframe: 2 section: 202 alpha: 55.409065282875744\n",
      "timeframe: 3 section: 257 alpha: 17.94701320490078\n",
      "timeframe: 2 section: 167 alpha: 17.733539238566127\n",
      "timeframe: 3 section: 208 alpha: 0.14312644140616976\n",
      "timeframe: 2 section: 353 alpha: 27.448431832854734\n",
      "timeframe: 2 section: 534 alpha: 25.820950611859516\n",
      "timeframe: 2 section: 451 alpha: 13.316461419296836\n",
      "timeframe: 2 section: 478 alpha: 22.71937253971139\n",
      "timeframe: 3 section: 187 alpha: 32.259382798570705\n",
      "timeframe: 3 section: 6 alpha: 42.71190876357838\n",
      "timeframe: 2 section: 112 alpha: 14.559831101960444\n",
      "timeframe: 2 section: 381 alpha: 34.52045163144473\n",
      "timeframe: 3 section: 20 alpha: 0.4991684909365498\n",
      "timeframe: 2 section: 499 alpha: 14.130413863744083\n",
      "timeframe: 2 section: 325 alpha: 55.22180033758338\n",
      "timeframe: 2 section: 266 alpha: 10.989465352428269\n",
      "timeframe: 2 section: 223 alpha: 28.976927119985206\n",
      "timeframe: 2 section: 507 alpha: 41.63408184552521\n",
      "timeframe: 2 section: 346 alpha: 24.379055407827074\n",
      "timeframe: 2 section: 548 alpha: 11.73238696277373\n",
      "timeframe: 2 section: 280 alpha: 17.51803827150464\n",
      "timeframe: 2 section: 230 alpha: 12.379963071261127\n",
      "timeframe: 3 section: 69 alpha: 49.73004385557247\n",
      "timeframe: 2 section: 189 alpha: 35.44435452831051\n",
      "timeframe: 2 section: 527 alpha: 43.15231795410291\n",
      "timeframe: 3 section: 215 alpha: 44.98560586568061\n",
      "timeframe: 2 section: 521 alpha: 25.181670577311245\n",
      "timeframe: 2 section: 388 alpha: 4.450788498991011\n",
      "timeframe: 2 section: 196 alpha: 25.42492050655225\n",
      "timeframe: 3 section: 180 alpha: 46.459494861063206\n",
      "timeframe: 3 section: 62 alpha: 26.272267279636544\n",
      "timeframe: 2 section: 182 alpha: 16.146008298523086\n",
      "timeframe: 2 section: 431 alpha: 44.71144445641223\n",
      "timeframe: 2 section: 340 alpha: 32.14827091800037\n",
      "timeframe: 2 section: 367 alpha: 22.990466683692283\n",
      "timeframe: 3 section: 166 alpha: 58.94442223200657\n",
      "timeframe: 3 section: 250 alpha: 64.04094715560345\n",
      "timeframe: 3 section: 146 alpha: 6.363796522483722\n",
      "timeframe: 3 section: 201 alpha: 26.486616809588426\n",
      "timeframe: 3 section: 48 alpha: 7.247119199562194\n",
      "timeframe: 3 section: 236 alpha: 28.726083988693823\n",
      "timeframe: 2 section: 555 alpha: 24.800213471858466\n",
      "timeframe: 2 section: 237 alpha: 30.791891907035552\n",
      "timeframe: 3 section: 243 alpha: 54.24364465035912\n",
      "timeframe: 3 section: 118 alpha: 21.63950110295386\n",
      "timeframe: 3 section: 104 alpha: 22.577923990455258\n",
      "timeframe: 3 section: 194 alpha: 48.2034297516448\n",
      "timeframe: 2 section: 217 alpha: 17.221272724142416\n",
      "timeframe: 3 section: 34 alpha: 17.284150655536553\n",
      "timeframe: 3 section: 229 alpha: 50.21272174230714\n",
      "timeframe: 2 section: 305 alpha: 27.41459254862206\n",
      "timeframe: 2 section: 465 alpha: 76.71966834640186\n",
      "timeframe: 2 section: 438 alpha: 42.81767097723607\n",
      "timeframe: 3 section: 271 alpha: 13.490307374679011\n",
      "timeframe: 2 section: 354 alpha: 17.70275042532607\n",
      "timeframe: 2 section: 297 alpha: 5.4381230609790965\n",
      "timeframe: 3 section: 90 alpha: 95.57446084121537\n",
      "timeframe: 2 section: 333 alpha: 17.115462636615035\n",
      "timeframe: 2 section: 416 alpha: 18.053641240899392\n",
      "timeframe: 3 section: 160 alpha: 12.701270561307245\n",
      "timeframe: 3 section: 258 alpha: 59.35922048173075\n",
      "timeframe: 3 section: 97 alpha: 20.864086944674963\n",
      "timeframe: 3 section: 278 alpha: 8.795351472197567\n",
      "timeframe: 2 section: 402 alpha: 21.645014601246693\n",
      "timeframe: 2 section: 376 alpha: 16.345117445256196\n",
      "timeframe: 2 section: 285 alpha: 14.643638869022583\n",
      "timeframe: 2 section: 445 alpha: 19.607300159251608\n",
      "timeframe: 3 section: 13 alpha: 51.49709639985356\n",
      "timeframe: 2 section: 396 alpha: 23.18350638480948\n",
      "timeframe: 2 section: 514 alpha: 13.406130323356738\n",
      "timeframe: 3 section: 125 alpha: 9.289157562201021\n",
      "timeframe: 2 section: 409 alpha: 31.554733204497705\n",
      "timeframe: 3 section: 56 alpha: 2.6809593870232864\n",
      "timeframe: 2 section: 77 alpha: 36.945931541792014\n",
      "timeframe: 2 section: 500 alpha: 21.730033939852817\n",
      "timeframe: 2 section: 118 alpha: 9.358310053611017\n",
      "timeframe: 3 section: 209 alpha: 1.9256022562045105\n",
      "timeframe: 2 section: 291 alpha: 25.507785163859644\n",
      "timeframe: 2 section: 224 alpha: 27.44943853622277\n",
      "timeframe: 3 section: 285 alpha: 16.54453685257966\n",
      "timeframe: 3 section: 70 alpha: 27.861526220488788\n",
      "timeframe: 3 section: 153 alpha: 17.367023654453863\n",
      "timeframe: 3 section: 76 alpha: 104.90461308898306\n",
      "timeframe: 3 section: 264 alpha: 6.583345035414013\n",
      "timeframe: 2 section: 493 alpha: 21.928759535547524\n",
      "timeframe: 2 section: 479 alpha: 5.768775931552751\n",
      "timeframe: 2 section: 486 alpha: 22.831343878486408\n",
      "timeframe: 2 section: 312 alpha: 28.657622099793407\n",
      "timeframe: 2 section: 541 alpha: 33.44775018894524\n",
      "timeframe: 2 section: 382 alpha: 13.875097050150329\n",
      "timeframe: 3 section: 306 alpha: 30.62150946411432\n",
      "timeframe: 2 section: 424 alpha: 56.07103126953882\n",
      "timeframe: 2 section: 389 alpha: 12.2794608869686\n",
      "timeframe: 2 section: 319 alpha: 18.793589556256602\n",
      "timeframe: 2 section: 432 alpha: 24.914583161799047\n",
      "timeframe: 2 section: 472 alpha: 21.61907268340392\n",
      "timeframe: 2 section: 361 alpha: 25.965260186519004\n",
      "timeframe: 3 section: 105 alpha: 6.333399003386408\n",
      "timeframe: 3 section: 181 alpha: 17.391842343206825\n",
      "timeframe: 3 section: 84 alpha: 12.30841965918114\n",
      "timeframe: 3 section: 244 alpha: 42.67676235622835\n",
      "timeframe: 3 section: 313 alpha: 8.473939655271904\n",
      "timeframe: 3 section: 49 alpha: 43.3248310943375\n",
      "timeframe: 3 section: 292 alpha: 9.928736808926955\n",
      "timeframe: 2 section: 549 alpha: 21.10423009191949\n",
      "timeframe: 3 section: 35 alpha: 50.57077754927614\n",
      "timeframe: 2 section: 508 alpha: 24.45739205068907\n",
      "timeframe: 3 section: 299 alpha: 17.65519140564572\n",
      "timeframe: 2 section: 535 alpha: 39.337978765214\n",
      "timeframe: 3 section: 111 alpha: 20.86640187824134\n",
      "timeframe: 3 section: 41 alpha: 13.296798375429136\n",
      "timeframe: 2 section: 168 alpha: 38.665855004866934\n",
      "timeframe: 3 section: 355 alpha: 9.686686884695177\n",
      "timeframe: 2 section: 458 alpha: 51.03596002027601\n",
      "timeframe: 2 section: 341 alpha: 18.685310359369264\n",
      "timeframe: 2 section: 91 alpha: 44.78409707003844\n",
      "timeframe: 3 section: 28 alpha: 44.96233533733951\n",
      "timeframe: 3 section: 174 alpha: 15.104889935230322\n",
      "timeframe: 2 section: 347 alpha: 16.015990787654673\n",
      "timeframe: 2 section: 515 alpha: 25.76664600982138\n",
      "timeframe: 2 section: 528 alpha: 12.843597309884622\n",
      "timeframe: 3 section: 222 alpha: 29.06741725605101\n",
      "timeframe: 2 section: 298 alpha: 13.033048945245486\n",
      "timeframe: 3 section: 341 alpha: 15.274102993077102\n",
      "timeframe: 2 section: 452 alpha: 24.659010011072656\n",
      "timeframe: 2 section: 203 alpha: 26.961652436055644\n",
      "timeframe: 3 section: 188 alpha: 42.71126629675839\n",
      "timeframe: 2 section: 466 alpha: 50.60328179223953\n",
      "timeframe: 3 section: 334 alpha: 33.99540419348933\n",
      "timeframe: 2 section: 231 alpha: 27.34096141659959\n",
      "timeframe: 3 section: 21 alpha: 10.936781088589685\n",
      "timeframe: 3 section: 126 alpha: 17.44281377581485\n",
      "timeframe: 3 section: 327 alpha: 13.970414861182592\n",
      "timeframe: 3 section: 154 alpha: 17.72620435894135\n",
      "timeframe: 3 section: 245 alpha: 75.01644354367977\n",
      "timeframe: 3 section: 14 alpha: 24.338161287556265\n",
      "timeframe: 2 section: 417 alpha: 8.551557250383595\n",
      "timeframe: 3 section: 161 alpha: 3.0176633473307306\n",
      "timeframe: 2 section: 334 alpha: 14.556128038548405\n",
      "timeframe: 2 section: 368 alpha: 17.619318849203047\n",
      "timeframe: 3 section: 216 alpha: 15.522868254210515\n",
      "timeframe: 2 section: 446 alpha: 14.84515090327669\n",
      "timeframe: 2 section: 522 alpha: 37.12295335130373\n",
      "timeframe: 2 section: 238 alpha: 14.525251672520406\n",
      "timeframe: 3 section: 320 alpha: 35.45642402013825\n",
      "timeframe: 3 section: 119 alpha: 15.832490012848092\n",
      "timeframe: 3 section: 0 alpha: 28.76292379830373\n",
      "timeframe: 2 section: 306 alpha: 19.144165991427197\n",
      "timeframe: 2 section: 355 alpha: 14.739986696001946\n",
      "timeframe: 3 section: 376 alpha: 33.00220601188993\n",
      "timeframe: 3 section: 139 alpha: 38.498626151392465\n",
      "timeframe: 2 section: 439 alpha: 26.38225112854436\n",
      "timeframe: 3 section: 202 alpha: 23.672857280529914\n",
      "timeframe: 3 section: 265 alpha: 1.4727356503529307\n",
      "timeframe: 3 section: 63 alpha: 15.559535178854953\n",
      "timeframe: 3 section: 71 alpha: 14.711516296254775\n",
      "timeframe: 3 section: 85 alpha: 24.316355013087644\n",
      "timeframe: 2 section: 326 alpha: 28.16482521715435\n",
      "timeframe: 2 section: 480 alpha: 49.40872532776916\n",
      "timeframe: 2 section: 501 alpha: 111.03849846407287\n",
      "timeframe: 3 section: 98 alpha: 21.56530676792568\n",
      "timeframe: 3 section: 36 alpha: 36.73217561370882\n",
      "timeframe: 2 section: 390 alpha: 17.175244566405496\n",
      "timeframe: 3 section: 348 alpha: 59.263334521860195\n",
      "timeframe: 3 section: 307 alpha: 17.87015986436721\n",
      "timeframe: 2 section: 397 alpha: 25.369013296004923\n",
      "timeframe: 3 section: 167 alpha: 7.367910972541703\n",
      "timeframe: 2 section: 410 alpha: 13.504820809467589\n",
      "timeframe: 2 section: 286 alpha: 40.736883540573245\n",
      "timeframe: 3 section: 279 alpha: 39.72289515175285\n",
      "timeframe: 3 section: 132 alpha: 26.338383383976534\n",
      "timeframe: 2 section: 425 alpha: 8.966284760054238\n",
      "timeframe: 3 section: 383 alpha: 1.4738733859377053\n",
      "timeframe: 3 section: 237 alpha: 33.35783388889968\n",
      "timeframe: 3 section: 147 alpha: 11.957039296602279\n",
      "timeframe: 3 section: 50 alpha: 43.086220417907995\n",
      "timeframe: 2 section: 516 alpha: 29.885870247270976\n",
      "timeframe: 3 section: 91 alpha: 23.841024762890285\n",
      "timeframe: 2 section: 403 alpha: 20.140122981334677\n",
      "timeframe: 3 section: 259 alpha: 32.348158824783646\n",
      "timeframe: 3 section: 369 alpha: 22.091029948594997\n",
      "timeframe: 2 section: 119 alpha: 20.675979464594135\n",
      "timeframe: 3 section: 362 alpha: 15.646076961190847\n",
      "timeframe: 2 section: 487 alpha: 22.064728359293415\n",
      "timeframe: 2 section: 377 alpha: 30.86946349414084\n",
      "timeframe: 3 section: 210 alpha: 9.719644614194353\n",
      "timeframe: 3 section: 286 alpha: 46.428981365204905\n",
      "timeframe: 2 section: 342 alpha: 10.76598356274252\n",
      "timeframe: 2 section: 383 alpha: 11.723764167609348\n",
      "timeframe: 3 section: 293 alpha: 123.65826844917615\n",
      "timeframe: 3 section: 112 alpha: 6.246059858722197\n",
      "timeframe: 3 section: 251 alpha: 50.772980905507005\n",
      "timeframe: 3 section: 7 alpha: 21.8497589693999\n",
      "timeframe: 2 section: 320 alpha: 13.715405333682323\n",
      "timeframe: 2 section: 459 alpha: 22.52819828376513\n",
      "timeframe: 3 section: 57 alpha: 1.8618852090154299\n",
      "timeframe: 3 section: 272 alpha: 54.368536159256045\n",
      "timeframe: 3 section: 300 alpha: 20.79724514224166\n",
      "timeframe: 2 section: 313 alpha: 62.641249185663156\n",
      "timeframe: 2 section: 542 alpha: 21.671604872142563\n",
      "timeframe: 3 section: 29 alpha: 1.9104729132873828\n",
      "timeframe: 3 section: 15 alpha: 25.55422624900394\n",
      "timeframe: 2 section: 292 alpha: 15.045469122392936\n",
      "timeframe: 2 section: 369 alpha: 22.404501614211078\n",
      "timeframe: 3 section: 342 alpha: 13.642323582547464\n",
      "timeframe: 3 section: 77 alpha: 49.17734672068181\n",
      "timeframe: 2 section: 502 alpha: 13.231562403110647\n",
      "timeframe: 2 section: 433 alpha: 43.1651402448088\n",
      "timeframe: 2 section: 473 alpha: 28.092625252452134\n",
      "timeframe: 2 section: 509 alpha: 35.60840667821473\n",
      "timeframe: 3 section: 314 alpha: 21.813491850273593\n",
      "timeframe: 3 section: 182 alpha: 29.920554652466738\n",
      "timeframe: 3 section: 42 alpha: 40.0002255537692\n",
      "timeframe: 3 section: 411 alpha: 2.917307202360684\n",
      "timeframe: 2 section: 299 alpha: 22.41544123931191\n",
      "timeframe: 2 section: 529 alpha: 16.89131326391272\n",
      "timeframe: 2 section: 356 alpha: 27.866055781983444\n",
      "timeframe: 2 section: 391 alpha: 19.74378854887462\n",
      "timeframe: 2 section: 467 alpha: 22.373043017138986\n",
      "timeframe: 3 section: 404 alpha: 49.860948249817284\n",
      "timeframe: 3 section: 356 alpha: 46.008361220954164\n",
      "timeframe: 2 section: 362 alpha: 37.50003092537454\n",
      "timeframe: 2 section: 494 alpha: 21.600511105071686\n",
      "timeframe: 3 section: 195 alpha: 8.727866605210426\n",
      "timeframe: 3 section: 308 alpha: 21.11471022976607\n",
      "timeframe: 3 section: 120 alpha: 15.282213642783095\n",
      "timeframe: 2 section: 523 alpha: 17.863931038254247\n",
      "timeframe: 3 section: 162 alpha: 10.657393117794552\n",
      "timeframe: 3 section: 230 alpha: 30.976360598151597\n",
      "timeframe: 3 section: 106 alpha: 36.167901427117066\n",
      "timeframe: 3 section: 86 alpha: 30.194535817507592\n",
      "timeframe: 2 section: 453 alpha: 25.718179717615644\n",
      "timeframe: 2 section: 307 alpha: 16.198269695613604\n",
      "timeframe: 2 section: 418 alpha: 13.270509964293005\n",
      "timeframe: 2 section: 481 alpha: 22.3704302588401\n",
      "timeframe: 2 section: 447 alpha: 11.252717745893044\n",
      "timeframe: 3 section: 155 alpha: 5.603901038601775\n",
      "timeframe: 3 section: 175 alpha: 27.017839584296038\n",
      "timeframe: 3 section: 370 alpha: 33.17764275535024\n",
      "timeframe: 3 section: 22 alpha: 13.9839674779004\n",
      "timeframe: 2 section: 536 alpha: 17.49267904429845\n",
      "timeframe: 3 section: 328 alpha: 11.401626741205206\n",
      "timeframe: 3 section: 223 alpha: 69.60694865951592\n",
      "timeframe: 3 section: 148 alpha: 16.247198168947914\n",
      "timeframe: 2 section: 517 alpha: 40.12450079606862\n",
      "timeframe: 2 section: 335 alpha: 38.21191087541993\n",
      "timeframe: 2 section: 411 alpha: 4.736396008147576\n",
      "timeframe: 2 section: 398 alpha: 5.886883198653346\n",
      "timeframe: 2 section: 348 alpha: 76.78589174447626\n",
      "timeframe: 3 section: 64 alpha: 17.664890367011616\n",
      "timeframe: 3 section: 16 alpha: 13.764837422367123\n",
      "timeframe: 3 section: 397 alpha: 24.049916370701425\n",
      "timeframe: 3 section: 189 alpha: 28.393781669831437\n",
      "timeframe: 3 section: 72 alpha: 12.36776724744131\n",
      "timeframe: 3 section: 266 alpha: 27.108027153899737\n",
      "timeframe: 2 section: 327 alpha: 40.70312273081427\n",
      "timeframe: 3 section: 30 alpha: 23.148395538589323\n",
      "timeframe: 3 section: 127 alpha: 28.48253565189208\n",
      "timeframe: 3 section: 51 alpha: 18.96477708767199\n",
      "timeframe: 2 section: 426 alpha: 10.153226507837143\n",
      "timeframe: 2 section: 404 alpha: 20.506498216808463\n",
      "timeframe: 2 section: 370 alpha: 34.09741605144887\n",
      "timeframe: 3 section: 377 alpha: 36.709250406793196\n",
      "timeframe: 2 section: 503 alpha: 18.353160691815027\n",
      "timeframe: 3 section: 1 alpha: 45.07895115558324\n",
      "timeframe: 2 section: 378 alpha: 30.66749462693212\n",
      "timeframe: 3 section: 217 alpha: 27.12208452862653\n",
      "timeframe: 3 section: 335 alpha: 69.0905038166314\n",
      "timeframe: 2 section: 468 alpha: 42.310255203836334\n",
      "timeframe: 3 section: 140 alpha: 29.714514623846195\n",
      "timeframe: 2 section: 440 alpha: 6.857195022543289\n",
      "timeframe: 2 section: 287 alpha: 29.061890536451003\n",
      "timeframe: 3 section: 99 alpha: 11.29121715385771\n",
      "timeframe: 3 section: 321 alpha: 35.57855822065244\n",
      "timeframe: 3 section: 58 alpha: 47.251217002018635\n",
      "timeframe: 2 section: 343 alpha: 35.52608681597712\n",
      "timeframe: 2 section: 293 alpha: 63.408158898501185\n",
      "timeframe: 3 section: 246 alpha: 22.431439453086217\n",
      "timeframe: 2 section: 550 alpha: 26.762718470129464\n",
      "timeframe: 2 section: 384 alpha: 13.532432813565794\n",
      "timeframe: 3 section: 238 alpha: 36.869833898160515\n",
      "timeframe: 3 section: 405 alpha: 38.756906520095725\n",
      "timeframe: 2 section: 300 alpha: 28.82721158801302\n",
      "timeframe: 2 section: 543 alpha: 13.075201417467625\n",
      "timeframe: 3 section: 273 alpha: 38.2883569275789\n",
      "timeframe: 3 section: 280 alpha: 30.79961125101474\n",
      "timeframe: 3 section: 37 alpha: 7.889884849492386\n",
      "timeframe: 3 section: 412 alpha: 12.676382387889369\n",
      "timeframe: 3 section: 349 alpha: 40.48781172194877\n",
      "timeframe: 2 section: 434 alpha: 66.42907900527771\n",
      "timeframe: 2 section: 488 alpha: 35.818232932457796\n",
      "timeframe: 3 section: 301 alpha: 22.00099574178594\n",
      "timeframe: 2 section: 460 alpha: 35.18166972888031\n",
      "timeframe: 2 section: 524 alpha: 7.146367898908304\n",
      "timeframe: 2 section: 474 alpha: 13.513274712735344\n",
      "timeframe: 3 section: 363 alpha: 18.301842159628563\n",
      "timeframe: 3 section: 113 alpha: 27.998142935553663\n",
      "timeframe: 3 section: 260 alpha: 52.42680051238485\n",
      "timeframe: 3 section: 23 alpha: 28.3947042261586\n",
      "timeframe: 2 section: 363 alpha: 17.260088389010733\n",
      "timeframe: 3 section: 329 alpha: 92.29317038760715\n",
      "timeframe: 3 section: 224 alpha: 37.6693315467859\n",
      "timeframe: 3 section: 371 alpha: 18.149077450930903\n",
      "timeframe: 3 section: 156 alpha: 20.200907103108893\n",
      "timeframe: 3 section: 92 alpha: 20.824710361802346\n",
      "timeframe: 2 section: 314 alpha: 31.92156095796506\n",
      "timeframe: 2 section: 371 alpha: 48.94248737354144\n",
      "timeframe: 2 section: 448 alpha: 99.59744338481967\n",
      "timeframe: 2 section: 392 alpha: 14.445288741014929\n",
      "timeframe: 3 section: 203 alpha: 32.328355987852476\n",
      "timeframe: 2 section: 510 alpha: 11.18509244684476\n",
      "timeframe: 3 section: 390 alpha: 19.974518798999433\n",
      "timeframe: 2 section: 405 alpha: 27.909556582896858\n",
      "timeframe: 3 section: 73 alpha: 0.17945987043229464\n",
      "timeframe: 3 section: 287 alpha: 5.809047108205939\n",
      "timeframe: 2 section: 454 alpha: 22.098208458372536\n",
      "timeframe: 3 section: 418 alpha: 42.02926870581506\n",
      "timeframe: 2 section: 321 alpha: 37.6611400641033\n",
      "timeframe: 2 section: 357 alpha: 37.287834101672786\n",
      "timeframe: 2 section: 308 alpha: 58.735468354625866\n",
      "timeframe: 2 section: 495 alpha: 48.31513988006026\n",
      "timeframe: 3 section: 168 alpha: 32.6030559219473\n",
      "timeframe: 3 section: 336 alpha: 15.77097934151125\n",
      "timeframe: 3 section: 384 alpha: 34.67398546327057\n",
      "timeframe: 2 section: 349 alpha: 38.77277876076483\n",
      "timeframe: 2 section: 482 alpha: 18.72137376648142\n",
      "timeframe: 3 section: 357 alpha: 53.2467133802132\n",
      "timeframe: 3 section: 211 alpha: 17.309558999394607\n",
      "timeframe: 3 section: 343 alpha: 25.52169221559426\n",
      "timeframe: 3 section: 252 alpha: 44.61298438307509\n",
      "timeframe: 2 section: 504 alpha: 28.49843364591706\n",
      "timeframe: 2 section: 336 alpha: 7.5427280421977505\n",
      "timeframe: 3 section: 149 alpha: 103.64375380956953\n",
      "timeframe: 3 section: 309 alpha: 33.48062662406354\n",
      "timeframe: 3 section: 183 alpha: 21.155475152243167\n",
      "timeframe: 2 section: 399 alpha: 9.971426804584137\n",
      "timeframe: 3 section: 398 alpha: 2.356899101674544\n",
      "timeframe: 3 section: 432 alpha: 45.91810501874527\n",
      "timeframe: 3 section: 43 alpha: 32.28437173203741\n",
      "timeframe: 3 section: 196 alpha: 11.101674585602339\n",
      "timeframe: 3 section: 121 alpha: 29.707124082372015\n",
      "timeframe: 2 section: 412 alpha: 17.629459697571406\n",
      "timeframe: 2 section: 419 alpha: 17.537112247461994\n",
      "timeframe: 3 section: 294 alpha: 71.48554393476495\n",
      "timeframe: 3 section: 8 alpha: 10.708158067561127\n",
      "timeframe: 2 section: 518 alpha: 26.119705798104782\n",
      "timeframe: 3 section: 315 alpha: 15.487787101204292\n",
      "timeframe: 3 section: 78 alpha: 40.44244668424271\n",
      "timeframe: 3 section: 93 alpha: 20.735283930579016\n",
      "timeframe: 3 section: 231 alpha: 31.334459888418962\n",
      "timeframe: 2 section: 530 alpha: 36.887212547070924\n",
      "timeframe: 3 section: 52 alpha: 40.957600808853236\n",
      "timeframe: 3 section: 391 alpha: 17.44888118368569\n",
      "timeframe: 3 section: 107 alpha: 36.09479842233626\n",
      "timeframe: 3 section: 204 alpha: 10.185774329594079\n",
      "timeframe: 2 section: 441 alpha: 52.18191580108299\n",
      "timeframe: 3 section: 413 alpha: 48.95018592590373\n",
      "timeframe: 3 section: 31 alpha: 46.1217477527071\n",
      "timeframe: 3 section: 176 alpha: 35.57174813992742\n",
      "timeframe: 3 section: 247 alpha: 83.48688192727481\n",
      "timeframe: 3 section: 87 alpha: 61.04703765930695\n",
      "timeframe: 3 section: 65 alpha: 27.581677650624503\n",
      "timeframe: 2 section: 537 alpha: 41.07050254325808\n",
      "timeframe: 3 section: 163 alpha: 24.219022068685813\n",
      "timeframe: 2 section: 427 alpha: 55.464057937428684\n",
      "timeframe: 3 section: 128 alpha: 33.14644036910582\n",
      "timeframe: 3 section: 114 alpha: 21.95315236041017\n",
      "timeframe: 3 section: 190 alpha: 16.154160526539364\n",
      "timeframe: 3 section: 330 alpha: 6.1825687761655415\n",
      "timeframe: 3 section: 218 alpha: 26.678315306884606\n",
      "timeframe: 3 section: 133 alpha: 40.434029648730615\n",
      "timeframe: 3 section: 141 alpha: 47.741582939067165\n",
      "timeframe: 3 section: 274 alpha: 8.104282476837987\n",
      "timeframe: 2 section: 544 alpha: 9.54977274282825\n",
      "timeframe: 2 section: 294 alpha: 39.647486555475645\n",
      "timeframe: 3 section: 406 alpha: 53.155437077531424\n",
      "timeframe: 3 section: 261 alpha: 15.25947643153075\n",
      "timeframe: 3 section: 24 alpha: 22.170430549231966\n",
      "timeframe: 3 section: 74 alpha: 9.29568131482821\n",
      "timeframe: 2 section: 315 alpha: 26.88380821646988\n",
      "timeframe: 2 section: 475 alpha: 11.637913391853516\n",
      "timeframe: 2 section: 322 alpha: 42.65210655867257\n",
      "timeframe: 3 section: 239 alpha: 52.584697997115704\n",
      "timeframe: 3 section: 2 alpha: 20.083671726145887\n",
      "timeframe: 2 section: 483 alpha: 42.15922948318212\n",
      "timeframe: 3 section: 267 alpha: 8.716045879235613\n",
      "timeframe: 2 section: 301 alpha: 38.289616278693444\n",
      "timeframe: 3 section: 281 alpha: 49.53419316246641\n",
      "timeframe: 3 section: 502 alpha: 4.327206096682704\n",
      "timeframe: 3 section: 59 alpha: 26.50942301324484\n",
      "timeframe: 3 section: 378 alpha: 19.88351578663228\n",
      "timeframe: 2 section: 328 alpha: 22.74082473583955\n",
      "timeframe: 2 section: 525 alpha: 57.94777385714968\n",
      "timeframe: 3 section: 350 alpha: 27.185255699525893\n",
      "timeframe: 3 section: 17 alpha: 19.426709917340144\n",
      "timeframe: 2 section: 413 alpha: 22.68529056431346\n",
      "timeframe: 3 section: 169 alpha: 32.616978252207836\n",
      "timeframe: 3 section: 439 alpha: 16.719551972855392\n",
      "timeframe: 3 section: 358 alpha: 67.26979355916649\n",
      "timeframe: 3 section: 38 alpha: 25.669103502566177\n",
      "timeframe: 3 section: 225 alpha: 38.22996614852481\n",
      "timeframe: 2 section: 469 alpha: 55.6912063138728\n",
      "timeframe: 3 section: 467 alpha: 16.686994533224627\n",
      "timeframe: 3 section: 100 alpha: 19.14559092968554\n",
      "timeframe: 3 section: 425 alpha: 28.86070880682945\n",
      "timeframe: 3 section: 337 alpha: 8.980932660100688\n",
      "timeframe: 2 section: 461 alpha: 48.463427399048655\n",
      "timeframe: 3 section: 474 alpha: 8.857159611634167\n",
      "timeframe: 3 section: 446 alpha: 68.39444940770403\n",
      "timeframe: 3 section: 322 alpha: 59.85299140367584\n",
      "timeframe: 2 section: 455 alpha: 42.89896999840819\n",
      "timeframe: 2 section: 511 alpha: 25.61797441876244\n",
      "timeframe: 3 section: 481 alpha: 29.515734983312115\n",
      "timeframe: 2 section: 489 alpha: 7.033165860802845\n",
      "timeframe: 3 section: 372 alpha: 20.057234583782048\n",
      "timeframe: 3 section: 495 alpha: 77.22253422575199\n",
      "timeframe: 3 section: 302 alpha: 5.4805226999865155\n",
      "timeframe: 2 section: 420 alpha: 16.860499785715174\n",
      "timeframe: 2 section: 496 alpha: 19.291945936951763\n",
      "timeframe: 2 section: 538 alpha: 32.86413803540015\n",
      "timeframe: 2 section: 406 alpha: 34.88674986360774\n",
      "timeframe: 3 section: 460 alpha: 11.770174290203068\n",
      "timeframe: 3 section: 288 alpha: 15.312527833818248\n",
      "timeframe: 3 section: 79 alpha: 47.78056428645566\n",
      "timeframe: 3 section: 453 alpha: 29.518483038591494\n",
      "timeframe: 3 section: 212 alpha: 31.716456961417034\n",
      "timeframe: 3 section: 108 alpha: 15.807748896650157\n",
      "timeframe: 3 section: 295 alpha: 20.682631497126447\n",
      "timeframe: 2 section: 364 alpha: 20.280890486146077\n",
      "timeframe: 4 section: 9 alpha: 40.630441936363006\n",
      "timeframe: 3 section: 205 alpha: 34.24087815174963\n",
      "timeframe: 2 section: 551 alpha: 19.088861599505243\n",
      "timeframe: 3 section: 157 alpha: 35.924614635564254\n",
      "timeframe: 3 section: 94 alpha: 7.978959258295244\n",
      "timeframe: 4 section: 16 alpha: 123.95393767553786\n",
      "timeframe: 3 section: 385 alpha: 79.20122989080079\n",
      "timeframe: 3 section: 275 alpha: 5.714636435745785\n",
      "timeframe: 2 section: 385 alpha: 11.469143629315244\n",
      "timeframe: 3 section: 399 alpha: 17.274316023096976\n",
      "timeframe: 3 section: 440 alpha: 21.47180007286057\n",
      "timeframe: 2 section: 350 alpha: 24.70075917448996\n",
      "timeframe: 3 section: 66 alpha: 3.9450809205457014\n",
      "timeframe: 3 section: 344 alpha: 50.8042025104731\n",
      "timeframe: 4 section: 30 alpha: 7.1402596674695795\n",
      "timeframe: 4 section: 23 alpha: 40.053337011240345\n",
      "timeframe: 4 section: 2 alpha: 33.714021968743104\n",
      "timeframe: 2 section: 476 alpha: 10.972192907894522\n",
      "timeframe: 3 section: 364 alpha: 24.490415540419882\n",
      "timeframe: 3 section: 9 alpha: 26.79454896365904\n",
      "timeframe: 3 section: 248 alpha: 141.08276583039054\n",
      "timeframe: 3 section: 122 alpha: 15.047509473506402\n",
      "timeframe: 3 section: 18 alpha: 13.662739243646257\n",
      "timeframe: 3 section: 197 alpha: 14.412398080445435\n",
      "timeframe: 3 section: 170 alpha: 30.052061458006676\n",
      "timeframe: 3 section: 544 alpha: 7.380096724189202\n",
      "timeframe: 3 section: 32 alpha: 56.68164122426367\n",
      "timeframe: 3 section: 60 alpha: 5.7127076554492335\n",
      "timeframe: 3 section: 150 alpha: 28.00826118756461\n",
      "timeframe: 4 section: 37 alpha: 7.699870922476338\n",
      "timeframe: 3 section: 488 alpha: 36.54402214746024\n",
      "timeframe: 3 section: 516 alpha: 19.19879882586521\n",
      "timeframe: 4 section: 51 alpha: 66.44506765100903\n",
      "timeframe: 4 section: 44 alpha: 38.05794044851691\n",
      "timeframe: 3 section: 164 alpha: 6.859241403020317\n",
      "timeframe: 3 section: 3 alpha: 61.53829774371485\n",
      "timeframe: 3 section: 331 alpha: 9.415926238826973\n",
      "timeframe: 3 section: 177 alpha: 26.448302000546747\n",
      "timeframe: 3 section: 44 alpha: 5.267673544645968\n",
      "timeframe: 3 section: 310 alpha: 56.25713473591761\n",
      "timeframe: 3 section: 419 alpha: 44.20150339332603\n",
      "timeframe: 3 section: 184 alpha: 28.19916445558985\n",
      "timeframe: 3 section: 253 alpha: 22.220457472004927\n",
      "timeframe: 3 section: 468 alpha: 26.718202287554504\n",
      "timeframe: 3 section: 523 alpha: 14.77155840310223\n",
      "timeframe: 3 section: 537 alpha: 125.37120001695583\n",
      "timeframe: 3 section: 503 alpha: 7.788292131156459\n",
      "timeframe: 3 section: 219 alpha: 3.798119907222088\n",
      "timeframe: 3 section: 191 alpha: 29.085711235561355\n",
      "timeframe: 3 section: 392 alpha: 90.02288948991706\n",
      "timeframe: 3 section: 379 alpha: 19.392924870883366\n",
      "timeframe: 3 section: 115 alpha: 54.8291775376378\n",
      "timeframe: 3 section: 268 alpha: 1.5541173980173335\n",
      "timeframe: 3 section: 316 alpha: 88.14158945626923\n",
      "timeframe: 3 section: 232 alpha: 6.333469118286738\n",
      "timeframe: 2 section: 531 alpha: 14.584211642978\n",
      "timeframe: 4 section: 58 alpha: 18.97366384364995\n",
      "timeframe: 3 section: 433 alpha: 14.075147130495898\n",
      "timeframe: 3 section: 53 alpha: 36.66450729099858\n",
      "timeframe: 2 section: 490 alpha: 15.063679260184834\n",
      "timeframe: 3 section: 407 alpha: 21.867688382688957\n",
      "timeframe: 4 section: 17 alpha: 11.592437495475341\n",
      "timeframe: 4 section: 10 alpha: 9.943197578107036\n",
      "timeframe: 3 section: 25 alpha: 37.57858364104829\n",
      "timeframe: 3 section: 509 alpha: 54.873760782816866\n",
      "timeframe: 3 section: 129 alpha: 15.147208284873056\n",
      "timeframe: 2 section: 329 alpha: 13.435302038787977\n",
      "timeframe: 4 section: 65 alpha: 27.12803709979647\n",
      "timeframe: 3 section: 282 alpha: 15.50373316090932\n",
      "timeframe: 4 section: 24 alpha: 12.1071792632996\n",
      "timeframe: 4 section: 72 alpha: 29.870904359980404\n",
      "timeframe: 4 section: 79 alpha: 25.419321631754826\n",
      "timeframe: 4 section: 31 alpha: 51.35204726444804\n",
      "timeframe: 3 section: 249 alpha: 38.517313844874934\n",
      "timeframe: 4 section: 86 alpha: 28.319354800467824\n",
      "timeframe: 4 section: 93 alpha: 18.305678580741862\n",
      "timeframe: 3 section: 373 alpha: 16.283402678852998\n",
      "timeframe: 3 section: 551 alpha: 65.41222514188854\n",
      "timeframe: 3 section: 338 alpha: 5.333591633272107\n",
      "timeframe: 3 section: 482 alpha: 17.862290976146394\n",
      "timeframe: 3 section: 426 alpha: 55.08651083735303\n",
      "timeframe: 3 section: 142 alpha: 30.28876255122676\n",
      "timeframe: 3 section: 134 alpha: 92.85202789920615\n",
      "timeframe: 2 section: 539 alpha: 19.586636295847107\n",
      "timeframe: 3 section: 67 alpha: 45.34468055180147\n",
      "timeframe: 3 section: 88 alpha: 50.672004294834714\n",
      "timeframe: 4 section: 3 alpha: 30.6109281510275\n",
      "timeframe: 4 section: 38 alpha: 62.63198213497086\n",
      "timeframe: 4 section: 45 alpha: 8.029975721922536\n",
      "timeframe: 3 section: 39 alpha: 28.083084737394195\n",
      "timeframe: 4 section: 52 alpha: 52.10101409967745\n",
      "timeframe: 4 section: 107 alpha: 31.51079973414003\n",
      "timeframe: 3 section: 530 alpha: 44.41202397816681\n",
      "timeframe: 4 section: 100 alpha: 19.755811908788512\n",
      "timeframe: 2 section: 545 alpha: 67.15807677374212\n",
      "timeframe: 3 section: 123 alpha: 54.84077331819899\n",
      "timeframe: 3 section: 447 alpha: 11.21424940818378\n",
      "timeframe: 3 section: 10 alpha: 10.976786749456531\n",
      "timeframe: 3 section: 359 alpha: 57.516386971151945\n",
      "timeframe: 4 section: 114 alpha: 12.666391537594679\n",
      "timeframe: 3 section: 80 alpha: 6.635764178529918\n",
      "timeframe: 2 section: 552 alpha: 21.772303057289758\n",
      "timeframe: 3 section: 240 alpha: 34.418019955886784\n",
      "timeframe: 3 section: 380 alpha: 30.820863906150002\n",
      "timeframe: 4 section: 66 alpha: 79.40085618909359\n",
      "timeframe: 3 section: 206 alpha: 22.91868139876421\n",
      "timeframe: 4 section: 11 alpha: 21.709243350637667\n",
      "timeframe: 3 section: 276 alpha: 5.2215759398487105\n",
      "timeframe: 3 section: 226 alpha: 35.43378671253277\n",
      "timeframe: 3 section: 101 alpha: 35.361140402964686\n",
      "timeframe: 2 section: 462 alpha: 39.668660083264236\n",
      "timeframe: 3 section: 262 alpha: 56.23292439974643\n",
      "timeframe: 3 section: 400 alpha: 17.001230709757078\n",
      "timeframe: 4 section: 135 alpha: 27.37516934095335\n",
      "timeframe: 4 section: 18 alpha: 21.17300807709102\n",
      "timeframe: 3 section: 496 alpha: 50.17961402536612\n",
      "timeframe: 4 section: 94 alpha: 19.765378527809332\n",
      "timeframe: 2 section: 497 alpha: 61.150519179447784\n",
      "timeframe: 4 section: 25 alpha: 27.8443569366654\n",
      "timeframe: 3 section: 233 alpha: 1.5671026424575365\n",
      "timeframe: 4 section: 121 alpha: 54.21677980581744\n",
      "timeframe: 4 section: 32 alpha: 30.142187312877837\n",
      "timeframe: 4 section: 80 alpha: 15.528884375816153\n",
      "timeframe: 3 section: 109 alpha: 31.275316674591874\n",
      "timeframe: 4 section: 73 alpha: 2.4498253074966287\n",
      "timeframe: 3 section: 323 alpha: 76.36404990079456\n",
      "timeframe: 3 section: 254 alpha: 7.85851612620772\n",
      "timeframe: 4 section: 170 alpha: 93.78478576445124\n",
      "timeframe: 3 section: 158 alpha: 48.588684252250495\n",
      "timeframe: 4 section: 87 alpha: 35.69575607624891\n",
      "timeframe: 3 section: 414 alpha: 44.402935366382806\n",
      "timeframe: 4 section: 142 alpha: 19.873090055169243\n",
      "timeframe: 4 section: 4 alpha: 11.789707863843528\n",
      "timeframe: 3 section: 303 alpha: 71.18618653179341\n",
      "timeframe: 3 section: 332 alpha: 3.697872310236767\n",
      "timeframe: 4 section: 39 alpha: 41.42698284320029\n",
      "timeframe: 4 section: 59 alpha: 34.254326643132295\n",
      "timeframe: 3 section: 345 alpha: 82.01720075307365\n",
      "timeframe: 4 section: 108 alpha: 17.48967452354523\n",
      "timeframe: 3 section: 351 alpha: 32.93673283840199\n",
      "timeframe: 4 section: 128 alpha: 31.75693796535363\n",
      "timeframe: 4 section: 156 alpha: 24.076522300595066\n",
      "timeframe: 3 section: 504 alpha: 26.121834708723537\n",
      "timeframe: 3 section: 524 alpha: 4.986573335176843\n",
      "timeframe: 3 section: 296 alpha: 27.819291634392663\n",
      "timeframe: 4 section: 163 alpha: 30.12809549578118\n",
      "timeframe: 3 section: 475 alpha: 47.63058663956202\n",
      "timeframe: 3 section: 185 alpha: 6.827427100245201\n",
      "timeframe: 3 section: 213 alpha: 21.02708042872076\n",
      "timeframe: 3 section: 289 alpha: 52.21351144907929\n",
      "timeframe: 3 section: 339 alpha: 186.81937091120363\n",
      "timeframe: 4 section: 67 alpha: 31.528096080218653\n",
      "timeframe: 3 section: 171 alpha: 21.933315267007753\n",
      "timeframe: 3 section: 4 alpha: 91.36748361238217\n",
      "timeframe: 4 section: 101 alpha: 38.34277030004953\n",
      "timeframe: 3 section: 386 alpha: 39.99924014033796\n",
      "timeframe: 4 section: 46 alpha: 27.240987494841892\n",
      "timeframe: 3 section: 365 alpha: 26.869497805103247\n",
      "timeframe: 3 section: 517 alpha: 24.299993544315033\n",
      "timeframe: 3 section: 454 alpha: 27.400395989876262\n",
      "timeframe: 4 section: 177 alpha: 50.41389400137873\n",
      "timeframe: 3 section: 441 alpha: 15.338611595851336\n",
      "timeframe: 4 section: 53 alpha: 26.72467256549536\n",
      "timeframe: 3 section: 143 alpha: 159.43325354631162\n",
      "timeframe: 3 section: 45 alpha: 12.26586278575696\n",
      "timeframe: 4 section: 149 alpha: 30.579006452895456\n",
      "timeframe: 3 section: 374 alpha: 20.26845241795183\n",
      "timeframe: 3 section: 178 alpha: 52.639307235199595\n",
      "timeframe: 4 section: 12 alpha: 54.11867380978684\n",
      "timeframe: 3 section: 393 alpha: 27.619176257974235\n",
      "timeframe: 3 section: 461 alpha: 42.07619801012955\n",
      "timeframe: 3 section: 317 alpha: 24.954240543076835\n",
      "timeframe: 4 section: 115 alpha: 126.14520793865137\n",
      "timeframe: 3 section: 469 alpha: 40.85473898416494\n",
      "timeframe: 3 section: 135 alpha: 9.619912998183764\n",
      "timeframe: 4 section: 184 alpha: 42.05315978588725\n",
      "timeframe: 3 section: 483 alpha: 21.643728940562426\n",
      "timeframe: 3 section: 95 alpha: 20.2401511071183\n",
      "timeframe: 4 section: 191 alpha: 51.660478310809125\n",
      "timeframe: 3 section: 545 alpha: 69.12984199712155\n",
      "timeframe: 3 section: 81 alpha: 5.906181526621717\n",
      "timeframe: 2 section: 546 alpha: 11.035727349099098\n",
      "timeframe: 4 section: 5 alpha: 5.298558553065205\n",
      "timeframe: 4 section: 198 alpha: 32.91283653932588\n",
      "timeframe: 4 section: 19 alpha: 45.15485152448354\n",
      "timeframe: 4 section: 136 alpha: 30.358511811996973\n",
      "timeframe: 4 section: 143 alpha: 176.46171632172982\n",
      "timeframe: 4 section: 74 alpha: 13.083694190846233\n",
      "timeframe: 4 section: 81 alpha: 16.668970571448565\n",
      "timeframe: 3 section: 165 alpha: 34.29093177888391\n",
      "timeframe: 3 section: 130 alpha: 75.74689438863902\n",
      "timeframe: 3 section: 311 alpha: 46.10179200002767\n",
      "timeframe: 4 section: 88 alpha: 28.797924122971807\n",
      "timeframe: 4 section: 171 alpha: 28.974192549187606\n",
      "timeframe: 4 section: 205 alpha: 35.795455543776285\n",
      "timeframe: 4 section: 33 alpha: 48.74886148689102\n",
      "timeframe: 4 section: 109 alpha: 17.459379840313453\n",
      "timeframe: 3 section: 489 alpha: 31.039042006330334\n",
      "timeframe: 3 section: 269 alpha: 13.575631293118835\n",
      "timeframe: 3 section: 241 alpha: 17.10056695580596\n",
      "timeframe: 4 section: 157 alpha: 25.13558675661237\n",
      "timeframe: 2 section: 532 alpha: 23.339307463131686\n",
      "timeframe: 4 section: 60 alpha: 1.2217331332239236\n",
      "timeframe: 4 section: 95 alpha: 13.987080587668526\n",
      "timeframe: 3 section: 116 alpha: 34.836046951920416\n",
      "timeframe: 4 section: 122 alpha: 85.04369844374467\n",
      "timeframe: 3 section: 510 alpha: 51.63997064002352\n",
      "timeframe: 3 section: 220 alpha: 20.2757233037834\n",
      "timeframe: 4 section: 164 alpha: 53.23410095142199\n",
      "timeframe: 3 section: 448 alpha: 4.531851994789432\n",
      "timeframe: 4 section: 129 alpha: 35.227176054583694\n",
      "timeframe: 4 section: 47 alpha: 23.522273100659497\n",
      "timeframe: 3 section: 538 alpha: 56.67735954094958\n",
      "timeframe: 3 section: 420 alpha: 48.17337844638183\n",
      "timeframe: 4 section: 68 alpha: 10.362225165738497\n",
      "timeframe: 4 section: 26 alpha: 7.0698455969953455\n",
      "timeframe: 4 section: 40 alpha: 50.05627865364337\n",
      "timeframe: 4 section: 102 alpha: 19.22907187234102\n",
      "timeframe: 4 section: 212 alpha: 34.5017015075189\n",
      "timeframe: 4 section: 54 alpha: 22.134050177930916\n",
      "timeframe: 3 section: 151 alpha: 32.77379346300473\n",
      "timeframe: 4 section: 178 alpha: 60.51780179298776\n",
      "timeframe: 4 section: 150 alpha: 19.839693698990455\n",
      "timeframe: 3 section: 552 alpha: 38.85324738791488\n",
      "timeframe: 4 section: 13 alpha: 45.52152282562735\n",
      "timeframe: 3 section: 360 alpha: 0.11917134977674324\n",
      "timeframe: 3 section: 427 alpha: 60.25913017762875\n",
      "timeframe: 3 section: 408 alpha: 29.362721709382395\n",
      "timeframe: 4 section: 137 alpha: 8.580604832540866\n",
      "timeframe: 3 section: 531 alpha: 7.30916275288905\n",
      "timeframe: 4 section: 185 alpha: 38.44052878478103\n",
      "timeframe: 2 section: 553 alpha: 34.188243990015536\n",
      "timeframe: 4 section: 226 alpha: 30.21495212087623\n",
      "timeframe: 3 section: 11 alpha: 49.74484331343944\n",
      "timeframe: 3 section: 198 alpha: 31.507562361797046\n",
      "timeframe: 4 section: 116 alpha: 68.94593314089927\n",
      "timeframe: 4 section: 20 alpha: 15.315210110717958\n",
      "timeframe: 3 section: 102 alpha: 29.876307192847126\n",
      "timeframe: 4 section: 219 alpha: 13.68895449398792\n",
      "timeframe: 4 section: 233 alpha: 4.111615290440502\n",
      "timeframe: 4 section: 6 alpha: 64.6338341127339\n",
      "timeframe: 4 section: 199 alpha: 17.88101773972136\n",
      "timeframe: 4 section: 144 alpha: 25.118549840574367\n",
      "timeframe: 3 section: 352 alpha: 9.157084501173962\n",
      "timeframe: 4 section: 192 alpha: 27.295318756769696\n",
      "timeframe: 4 section: 247 alpha: 26.665662027834045\n",
      "timeframe: 4 section: 89 alpha: 29.592631779143463\n",
      "timeframe: 4 section: 34 alpha: 19.028472331812875\n",
      "timeframe: 3 section: 283 alpha: 34.53214697198971\n",
      "timeframe: 3 section: 192 alpha: 16.866206290867446\n",
      "timeframe: 3 section: 340 alpha: 27.047053026561752\n",
      "timeframe: 3 section: 505 alpha: 11.890808502540708\n",
      "timeframe: 3 section: 144 alpha: 37.432561996193954\n",
      "timeframe: 4 section: 110 alpha: 34.95746490468492\n",
      "timeframe: 4 section: 240 alpha: 21.575277347839698\n",
      "timeframe: 3 section: 277 alpha: 8.10494140742507\n",
      "timeframe: 3 section: 234 alpha: 22.950277602649848\n",
      "timeframe: 3 section: 297 alpha: 6.385846178848886\n",
      "timeframe: 4 section: 75 alpha: 45.56336078524376\n",
      "timeframe: 3 section: 375 alpha: 23.322184921093186\n",
      "timeframe: 4 section: 172 alpha: 23.677332106396747\n",
      "timeframe: 4 section: 48 alpha: 10.83273415921639\n",
      "timeframe: 4 section: 96 alpha: 24.99891959327859\n",
      "timeframe: 4 section: 254 alpha: 6.392005684165447\n",
      "timeframe: 4 section: 206 alpha: 50.197865913222806\n",
      "timeframe: 4 section: 61 alpha: 32.54335758888658\n",
      "timeframe: 4 section: 123 alpha: 15.402993963148608\n",
      "timeframe: 3 section: 525 alpha: 35.01733449553428\n",
      "timeframe: 4 section: 82 alpha: 73.54266948785212\n",
      "timeframe: 3 section: 263 alpha: 11.768121149923209\n",
      "timeframe: 3 section: 207 alpha: 35.288624671202314\n",
      "timeframe: 4 section: 27 alpha: 8.237919050308076\n",
      "timeframe: 3 section: 333 alpha: 45.31069930358932\n",
      "timeframe: 3 section: 214 alpha: 11.892104130300728\n",
      "timeframe: 4 section: 165 alpha: 46.033486049423054\n",
      "timeframe: 3 section: 227 alpha: 25.75769979277342\n",
      "timeframe: 3 section: 324 alpha: 26.45471202319203\n",
      "timeframe: 4 section: 69 alpha: 10.977826508579184\n",
      "timeframe: 4 section: 261 alpha: 8.622907990843041\n",
      "timeframe: 4 section: 158 alpha: 63.019879640798436\n",
      "timeframe: 3 section: 394 alpha: 10.906590376618981\n",
      "timeframe: 4 section: 130 alpha: 29.631226860350765\n",
      "timeframe: 4 section: 41 alpha: 40.5298248772774\n",
      "timeframe: 3 section: 136 alpha: 17.91210769208259\n",
      "timeframe: 4 section: 14 alpha: 8.569542072288035\n",
      "timeframe: 4 section: 179 alpha: 7.767012816003643\n",
      "timeframe: 4 section: 213 alpha: 32.25003438791374\n",
      "timeframe: 3 section: 434 alpha: 13.04753081756864\n",
      "timeframe: 3 section: 242 alpha: 13.028527768089383\n",
      "timeframe: 3 section: 186 alpha: 23.30108456676574\n",
      "timeframe: 3 section: 470 alpha: 24.65880175226424\n",
      "timeframe: 4 section: 227 alpha: 10.177756720390738\n",
      "timeframe: 3 section: 346 alpha: 16.8730144963954\n",
      "timeframe: 4 section: 55 alpha: 3.5389258675070847\n",
      "timeframe: 4 section: 145 alpha: 24.42234330342397\n",
      "timeframe: 4 section: 103 alpha: 28.823054277330062\n",
      "timeframe: 4 section: 117 alpha: 20.950149894730977\n",
      "timeframe: 4 section: 275 alpha: 4.844086406749457\n",
      "timeframe: 4 section: 248 alpha: 168.45174546126404\n",
      "timeframe: 4 section: 138 alpha: 42.145006790103906\n",
      "timeframe: 3 section: 476 alpha: 12.775293777038137\n",
      "timeframe: 4 section: 151 alpha: 13.8537156358601\n",
      "timeframe: 3 section: 401 alpha: 24.662692312750387\n",
      "timeframe: 4 section: 234 alpha: 22.64270759609435\n",
      "timeframe: 4 section: 282 alpha: 34.230566479197876\n",
      "timeframe: 3 section: 304 alpha: 51.54586240128987\n",
      "timeframe: 3 section: 497 alpha: 25.395785501813723\n",
      "timeframe: 4 section: 268 alpha: 0.05840987282895103\n",
      "timeframe: 4 section: 220 alpha: 25.285475002157522\n",
      "timeframe: 3 section: 381 alpha: 22.880366902230072\n",
      "timeframe: 4 section: 200 alpha: 19.483153533516003\n",
      "timeframe: 4 section: 186 alpha: 28.32153294223793\n",
      "timeframe: 4 section: 49 alpha: 7.891151387504224\n",
      "timeframe: 4 section: 21 alpha: 24.797089159361473\n",
      "timeframe: 3 section: 546 alpha: 28.179292004557194\n",
      "timeframe: 3 section: 449 alpha: 7.079716286311815\n",
      "timeframe: 4 section: 7 alpha: 19.431782090931826\n",
      "timeframe: 3 section: 290 alpha: 71.36258403359021\n",
      "timeframe: 4 section: 289 alpha: 34.074994439107414\n",
      "timeframe: 4 section: 241 alpha: 50.96168318767486\n",
      "timeframe: 4 section: 90 alpha: 21.32683411119898\n",
      "timeframe: 4 section: 296 alpha: 48.4579956460657\n",
      "timeframe: 3 section: 490 alpha: 27.74843147621242\n",
      "timeframe: 4 section: 193 alpha: 34.7389507054891\n",
      "timeframe: 4 section: 76 alpha: 62.49171186511358\n",
      "timeframe: 4 section: 62 alpha: 20.120652295366636\n",
      "timeframe: 4 section: 255 alpha: 81.80289370227841\n",
      "timeframe: 4 section: 124 alpha: 37.02830719681213\n",
      "timeframe: 4 section: 173 alpha: 37.60486737946482\n",
      "timeframe: 4 section: 111 alpha: 22.860730966713056\n",
      "timeframe: 3 section: 442 alpha: 11.746768767416615\n",
      "timeframe: 3 section: 366 alpha: 52.96052729914799\n",
      "timeframe: 4 section: 35 alpha: 23.098060374806046\n",
      "timeframe: 4 section: 262 alpha: 27.29157321865556\n",
      "timeframe: 4 section: 97 alpha: 33.911505343190846\n",
      "timeframe: 3 section: 387 alpha: 44.00736643585603\n",
      "timeframe: 4 section: 303 alpha: 72.29024672118008\n",
      "timeframe: 4 section: 207 alpha: 37.69191803210387\n",
      "timeframe: 4 section: 310 alpha: 43.775766319790584\n",
      "timeframe: 4 section: 317 alpha: 50.17143332395241\n",
      "timeframe: 4 section: 345 alpha: 63.18454983868785\n",
      "timeframe: 3 section: 518 alpha: 42.74816593032081\n",
      "timeframe: 3 section: 511 alpha: 29.162083078539744\n",
      "timeframe: 3 section: 312 alpha: 32.238671263650396\n",
      "timeframe: 4 section: 331 alpha: 67.75887051855156\n",
      "timeframe: 4 section: 83 alpha: 33.71485907674447\n",
      "timeframe: 3 section: 318 alpha: 59.433117745537906\n",
      "timeframe: 4 section: 42 alpha: 30.274765745662304\n",
      "timeframe: 4 section: 70 alpha: 7.469941286794341\n",
      "timeframe: 4 section: 15 alpha: 31.22844379601518\n",
      "timeframe: 3 section: 270 alpha: 32.28182349589035\n",
      "timeframe: 4 section: 214 alpha: 7.795075022272686\n",
      "timeframe: 4 section: 324 alpha: 27.93570840086243\n",
      "timeframe: 4 section: 166 alpha: 45.10257219039491\n",
      "timeframe: 4 section: 180 alpha: 39.84560671033414\n",
      "timeframe: 4 section: 159 alpha: 19.599806151053873\n",
      "timeframe: 4 section: 56 alpha: 3.4224416117374705\n",
      "timeframe: 3 section: 353 alpha: 12.628779959859742\n",
      "timeframe: 4 section: 338 alpha: 21.145712581348867\n",
      "timeframe: 3 section: 506 alpha: 24.87605221198589\n",
      "timeframe: 4 section: 118 alpha: 22.760305015707733\n",
      "timeframe: 3 section: 255 alpha: 78.40743463384175\n",
      "timeframe: 4 section: 104 alpha: 22.561913098041654\n",
      "timeframe: 4 section: 249 alpha: 26.24076302121022\n",
      "timeframe: 4 section: 359 alpha: 20.11924398005362\n",
      "timeframe: 4 section: 276 alpha: 8.704217204559836\n",
      "timeframe: 4 section: 352 alpha: 26.981816570987085\n",
      "timeframe: 4 section: 228 alpha: 4.021288667875751\n",
      "timeframe: 3 section: 484 alpha: 28.221897756728104\n",
      "timeframe: 3 section: 415 alpha: 33.05051056956824\n",
      "timeframe: 4 section: 146 alpha: 15.71607926910962\n",
      "timeframe: 3 section: 46 alpha: 11.216159393631306\n",
      "timeframe: 3 section: 361 alpha: 15.31238578319146\n",
      "timeframe: 3 section: 137 alpha: 38.70337004097091\n",
      "timeframe: 4 section: 201 alpha: 42.96113052604515\n",
      "timeframe: 3 section: 193 alpha: 14.965899356728606\n",
      "timeframe: 4 section: 131 alpha: 20.96439548191693\n",
      "timeframe: 3 section: 298 alpha: 9.898759752541238\n",
      "timeframe: 4 section: 50 alpha: 34.12280586235867\n",
      "timeframe: 4 section: 283 alpha: 44.21262458194552\n",
      "timeframe: 4 section: 297 alpha: 10.434124971242419\n",
      "timeframe: 4 section: 28 alpha: 48.75915245785008\n",
      "timeframe: 4 section: 269 alpha: 6.1578412240078295\n",
      "timeframe: 3 section: 539 alpha: 49.5233608679334\n",
      "timeframe: 4 section: 235 alpha: 35.18670006111842\n",
      "timeframe: 4 section: 152 alpha: 52.81020782207707\n",
      "timeframe: 4 section: 221 alpha: 49.49245183547808\n",
      "timeframe: 4 section: 187 alpha: 13.663280157879134\n",
      "timeframe: 4 section: 290 alpha: 15.430036536936477\n",
      "timeframe: 4 section: 242 alpha: 38.170771406057845\n",
      "timeframe: 3 section: 455 alpha: 17.453433471367877\n",
      "timeframe: 3 section: 462 alpha: 48.84709830231145\n",
      "timeframe: 3 section: 221 alpha: 37.67548718247669\n",
      "timeframe: 4 section: 139 alpha: 13.35834359120028\n",
      "timeframe: 3 section: 532 alpha: 13.237720602498129\n",
      "timeframe: 3 section: 179 alpha: 80.72111839596306\n",
      "timeframe: 4 section: 77 alpha: 62.637450224724944\n",
      "timeframe: 4 section: 22 alpha: 11.511116842864324\n",
      "timeframe: 4 section: 263 alpha: 20.10818215940122\n",
      "timeframe: 4 section: 194 alpha: 23.581079070401476\n",
      "timeframe: 4 section: 373 alpha: 7.441411913037303\n",
      "timeframe: 4 section: 98 alpha: 26.74339526290131\n",
      "timeframe: 4 section: 208 alpha: 1.3418849285358525\n",
      "timeframe: 4 section: 256 alpha: 25.40370867437455\n",
      "timeframe: 4 section: 63 alpha: 19.56827093303407\n",
      "timeframe: 4 section: 8 alpha: 44.70814774793787\n",
      "timeframe: 3 section: 228 alpha: 7.017256398105832\n",
      "timeframe: 3 section: 235 alpha: 38.70783316365011\n",
      "timeframe: 3 section: 450 alpha: 43.5644704588825\n",
      "timeframe: 4 section: 332 alpha: 15.762227280464446\n",
      "timeframe: 3 section: 395 alpha: 55.57133952783433\n",
      "timeframe: 4 section: 167 alpha: 19.851276782188236\n",
      "timeframe: 3 section: 428 alpha: 49.18364499380532\n",
      "timeframe: 4 section: 181 alpha: 22.843509864181655\n",
      "timeframe: 4 section: 318 alpha: 28.06112280516857\n",
      "timeframe: 4 section: 304 alpha: 51.198786090796865\n",
      "timeframe: 3 section: 409 alpha: 12.90952034035647\n",
      "timeframe: 4 section: 36 alpha: 9.960585224668328\n",
      "timeframe: 4 section: 112 alpha: 17.409796436157343\n",
      "timeframe: 4 section: 174 alpha: 40.06313515055215\n",
      "timeframe: 4 section: 339 alpha: 9.890662047284579\n",
      "timeframe: 4 section: 366 alpha: 34.420928162073935\n",
      "timeframe: 4 section: 380 alpha: 121.08475344927197\n",
      "timeframe: 3 section: 172 alpha: 28.983569894650845\n",
      "timeframe: 3 section: 553 alpha: 48.339915365054324\n",
      "timeframe: 3 section: 284 alpha: 26.639158491413863\n",
      "timeframe: 4 section: 125 alpha: 36.80759004334412\n",
      "timeframe: 4 section: 43 alpha: 28.967873033332165\n",
      "timeframe: 4 section: 160 alpha: 99.96207566686869\n",
      "timeframe: 4 section: 71 alpha: 22.05023465050536\n",
      "timeframe: 4 section: 360 alpha: 81.64481104666703\n",
      "timeframe: 4 section: 277 alpha: 10.45610892245083\n",
      "timeframe: 4 section: 311 alpha: 62.45021547432452\n",
      "timeframe: 4 section: 84 alpha: 20.778205702835994\n",
      "timeframe: 4 section: 119 alpha: 15.755168012934565\n",
      "timeframe: 4 section: 353 alpha: 13.665618066549166\n",
      "timeframe: 4 section: 57 alpha: 22.65729667810393\n",
      "timeframe: 4 section: 105 alpha: 18.590388810273513\n",
      "timeframe: 4 section: 147 alpha: 28.29817949153524\n",
      "timeframe: 4 section: 250 alpha: 44.90185543329708\n",
      "timeframe: 3 section: 471 alpha: 13.366199098185227\n",
      "timeframe: 4 section: 346 alpha: 29.21790978601455\n",
      "timeframe: 4 section: 91 alpha: 43.21094248140361\n",
      "timeframe: 3 section: 507 alpha: 22.608829140513052\n",
      "timeframe: 4 section: 229 alpha: 43.98084948859738\n",
      "timeframe: 4 section: 215 alpha: 40.549714034315976\n",
      "timeframe: 4 section: 298 alpha: 69.07345376523381\n",
      "timeframe: 3 section: 421 alpha: 32.622060524173165\n",
      "timeframe: 4 section: 422 alpha: 5.615056346659833\n",
      "timeframe: 4 section: 270 alpha: 20.307690970750976\n",
      "timeframe: 4 section: 401 alpha: 37.560487806270295\n",
      "timeframe: 4 section: 325 alpha: 46.43711586734274\n",
      "timeframe: 3 section: 435 alpha: 41.66285139856966\n",
      "timeframe: 4 section: 202 alpha: 28.48898014489116\n",
      "timeframe: 3 section: 354 alpha: 24.86508637116814\n",
      "timeframe: 4 section: 387 alpha: 13.448573575176896\n",
      "timeframe: 3 section: 388 alpha: 5.3744806111982015\n",
      "timeframe: 4 section: 284 alpha: 13.017479444149826\n",
      "timeframe: 4 section: 408 alpha: 35.77004945490404\n",
      "timeframe: 4 section: 374 alpha: 6.325521497669625\n",
      "timeframe: 4 section: 394 alpha: 21.19712124648722\n",
      "timeframe: 4 section: 429 alpha: 22.50468508006115\n",
      "timeframe: 4 section: 415 alpha: 45.98587212744995\n",
      "timeframe: 3 section: 512 alpha: 7.858729098412525\n",
      "timeframe: 4 section: 243 alpha: 12.528917337684934\n",
      "timeframe: 4 section: 188 alpha: 34.41499022742884\n",
      "timeframe: 3 section: 443 alpha: 40.19712907791308\n",
      "timeframe: 4 section: 209 alpha: 4.32809354074208\n",
      "timeframe: 3 section: 199 alpha: 28.344497329375006\n",
      "timeframe: 4 section: 29 alpha: 17.356396707311387\n",
      "timeframe: 4 section: 436 alpha: 39.44904181723311\n",
      "timeframe: 4 section: 153 alpha: 62.344242116631484\n",
      "timeframe: 4 section: 257 alpha: 1.2436496927136411\n",
      "timeframe: 4 section: 132 alpha: 24.736745492932638\n",
      "timeframe: 4 section: 264 alpha: 5.426558618346356\n",
      "timeframe: 4 section: 443 alpha: 66.84557753032152\n",
      "timeframe: 3 section: 547 alpha: 40.528115754346324\n",
      "timeframe: 3 section: 382 alpha: 5.847967761637413\n",
      "timeframe: 4 section: 195 alpha: 27.56096633185151\n",
      "timeframe: 4 section: 450 alpha: 26.523404657740613\n",
      "timeframe: 3 section: 325 alpha: 33.023607320057245\n",
      "timeframe: 4 section: 99 alpha: 22.702997817083904\n",
      "timeframe: 4 section: 291 alpha: 16.102353652276918\n",
      "timeframe: 4 section: 222 alpha: 35.65569498845356\n",
      "timeframe: 4 section: 457 alpha: 36.08811638451133\n",
      "timeframe: 4 section: 471 alpha: 67.42820625523457\n",
      "timeframe: 4 section: 319 alpha: 29.41377209658491\n",
      "timeframe: 4 section: 64 alpha: 28.18672375886859\n",
      "timeframe: 3 section: 526 alpha: 40.11387253722251\n",
      "timeframe: 3 section: 519 alpha: 12.850314369123307\n",
      "timeframe: 4 section: 333 alpha: 25.12508175342\n",
      "timeframe: 4 section: 175 alpha: 43.13766298792399\n",
      "timeframe: 4 section: 140 alpha: 54.47705015676957\n",
      "timeframe: 4 section: 464 alpha: 19.564826746859858\n",
      "timeframe: 4 section: 168 alpha: 22.224522704674445\n",
      "timeframe: 4 section: 340 alpha: 33.6816805858588\n",
      "timeframe: 4 section: 161 alpha: 26.189569426184246\n",
      "timeframe: 4 section: 113 alpha: 25.446357256857347\n",
      "timeframe: 4 section: 182 alpha: 46.88533506517825\n",
      "timeframe: 4 section: 236 alpha: 28.828182953446284\n",
      "timeframe: 4 section: 367 alpha: 29.66596415666051\n",
      "timeframe: 4 section: 492 alpha: 11.689613417732744\n",
      "timeframe: 3 section: 305 alpha: 40.10347496355324\n",
      "timeframe: 4 section: 305 alpha: 56.72040313598782\n",
      "timeframe: 3 section: 291 alpha: 18.961186958929574\n",
      "timeframe: 4 section: 120 alpha: 73.04992308403223\n",
      "timeframe: 3 section: 498 alpha: 47.530857028927564\n",
      "timeframe: 4 section: 85 alpha: 33.651686695345155\n",
      "timeframe: 4 section: 278 alpha: 19.555844630398948\n",
      "timeframe: 4 section: 126 alpha: 1.384916469618075\n",
      "timeframe: 4 section: 78 alpha: 31.68036688050063\n",
      "timeframe: 4 section: 381 alpha: 34.845714921263564\n",
      "timeframe: 4 section: 148 alpha: 5.1600519460859315\n",
      "timeframe: 3 section: 319 alpha: 59.68072765659167\n",
      "timeframe: 4 section: 251 alpha: 40.52162233246214\n",
      "timeframe: 3 section: 477 alpha: 34.948619714939014\n",
      "timeframe: 4 section: 361 alpha: 32.30608580575261\n",
      "timeframe: 4 section: 478 alpha: 24.617392840494244\n",
      "timeframe: 4 section: 499 alpha: 22.42698227718545\n",
      "timeframe: 4 section: 216 alpha: 44.77773042596172\n",
      "timeframe: 4 section: 485 alpha: 24.951803852314452\n",
      "timeframe: 4 section: 312 alpha: 50.9931010486116\n",
      "timeframe: 4 section: 230 alpha: 22.287512571401255\n",
      "timeframe: 4 section: 506 alpha: 32.47446490167172\n",
      "timeframe: 4 section: 430 alpha: 45.87641956558297\n",
      "timeframe: 4 section: 299 alpha: 55.054079180832645\n",
      "timeframe: 3 section: 429 alpha: 52.711332090022324\n",
      "timeframe: 4 section: 388 alpha: 13.291939219927652\n",
      "timeframe: 4 section: 326 alpha: 58.80845741822886\n",
      "timeframe: 4 section: 203 alpha: 23.631001344636452\n",
      "timeframe: 3 section: 491 alpha: 43.8309556811632\n",
      "timeframe: 4 section: 402 alpha: 32.067485799842025\n",
      "timeframe: 4 section: 347 alpha: 40.23132105733828\n",
      "timeframe: 3 section: 402 alpha: 18.570222741026175\n",
      "timeframe: 4 section: 106 alpha: 33.345069779670624\n",
      "timeframe: 4 section: 513 alpha: 10.23148284716714\n",
      "timeframe: 4 section: 285 alpha: 23.297960606121286\n",
      "timeframe: 4 section: 375 alpha: 10.819426150512632\n",
      "timeframe: 4 section: 92 alpha: 21.857243556280295\n",
      "timeframe: 4 section: 409 alpha: 33.74319036050809\n",
      "timeframe: 3 section: 347 alpha: 61.3103352499375\n",
      "timeframe: 4 section: 423 alpha: 50.120253852213125\n",
      "timeframe: 3 section: 367 alpha: 38.33180728188072\n",
      "timeframe: 4 section: 416 alpha: 34.531611108987505\n",
      "timeframe: 4 section: 154 alpha: 68.60747490942727\n",
      "timeframe: 4 section: 395 alpha: 84.30097240116964\n",
      "timeframe: 4 section: 133 alpha: 14.251140223887434\n",
      "timeframe: 4 section: 196 alpha: 15.642612149120804\n",
      "timeframe: 4 section: 541 alpha: 125.70900647920669\n",
      "timeframe: 4 section: 520 alpha: 7.113710354992278\n",
      "timeframe: 3 section: 416 alpha: 15.574526343372028\n",
      "timeframe: 4 section: 292 alpha: 26.094103094435788\n",
      "timeframe: 4 section: 244 alpha: 8.000958661536403\n",
      "timeframe: 4 section: 271 alpha: 22.69565447235398\n",
      "timeframe: 4 section: 451 alpha: 18.921682119380772\n",
      "timeframe: 4 section: 444 alpha: 27.031661688837946\n",
      "timeframe: 4 section: 354 alpha: 61.714994092709404\n",
      "timeframe: 4 section: 258 alpha: 72.49446887222534\n",
      "timeframe: 4 section: 534 alpha: 28.00439947554198\n",
      "timeframe: 4 section: 465 alpha: 20.112065560715806\n",
      "timeframe: 4 section: 527 alpha: 59.07823933216568\n",
      "timeframe: 4 section: 472 alpha: 25.224916945603365\n",
      "timeframe: 4 section: 334 alpha: 35.80934298783374\n",
      "timeframe: 4 section: 265 alpha: 21.109496769285514\n",
      "timeframe: 4 section: 210 alpha: 61.94509825134134\n",
      "timeframe: 4 section: 169 alpha: 96.14165328983839\n",
      "timeframe: 3 section: 256 alpha: 30.684657381587506\n",
      "timeframe: 4 section: 458 alpha: 14.6400196621819\n",
      "timeframe: 4 section: 189 alpha: 27.609131091251157\n",
      "timeframe: 4 section: 320 alpha: 18.673242947957785\n",
      "timeframe: 4 section: 141 alpha: 52.21205510510067\n",
      "timeframe: 4 section: 223 alpha: 63.49749573704976\n",
      "timeframe: 4 section: 127 alpha: 34.874210261986164\n",
      "timeframe: 3 section: 444 alpha: 38.09393902858106\n",
      "timeframe: 4 section: 183 alpha: 45.90620194800794\n",
      "timeframe: 3 section: 456 alpha: 20.607285766617913\n",
      "timeframe: 4 section: 162 alpha: 18.79802617865689\n",
      "timeframe: 4 section: 341 alpha: 46.2793667088154\n",
      "timeframe: 4 section: 493 alpha: 10.310947913405348\n",
      "timeframe: 4 section: 176 alpha: 14.202372688650714\n",
      "timeframe: 4 section: 548 alpha: 22.917656906067897\n",
      "timeframe: 3 section: 451 alpha: 7.980416127622382\n",
      "timeframe: 3 section: 389 alpha: 11.197194413315701\n",
      "timeframe: 4 section: 279 alpha: 32.309881913358645\n",
      "timeframe: 4 section: 382 alpha: 32.045737374940984\n",
      "timeframe: 4 section: 431 alpha: 8.792221826880459\n",
      "timeframe: 4 section: 500 alpha: 5.379771702631341\n",
      "timeframe: 4 section: 507 alpha: 11.426631500949508\n",
      "timeframe: 3 section: 436 alpha: 9.01711978982913\n",
      "timeframe: 4 section: 368 alpha: 20.376213180031023\n",
      "timeframe: 4 section: 437 alpha: 67.36135193254135\n",
      "timeframe: 3 section: 548 alpha: 19.36825628491634\n",
      "timeframe: 4 section: 486 alpha: 45.55018332199128\n",
      "timeframe: 4 section: 306 alpha: 39.50802867436792\n",
      "timeframe: 4 section: 300 alpha: 55.3690059481457\n",
      "timeframe: 4 section: 313 alpha: 48.044095055258225\n",
      "timeframe: 4 section: 237 alpha: 32.11111718463086\n",
      "timeframe: 4 section: 389 alpha: 7.712982851351107\n",
      "timeframe: 4 section: 514 alpha: 25.379755135819465\n",
      "timeframe: 4 section: 217 alpha: 51.34024192903434\n",
      "timeframe: 4 section: 252 alpha: 33.37063691785233\n",
      "timeframe: 4 section: 204 alpha: 18.42875122582771\n",
      "timeframe: 4 section: 479 alpha: 38.56955747257411\n",
      "timeframe: 4 section: 403 alpha: 44.01374066081774\n",
      "timeframe: 4 section: 376 alpha: 14.569769347112908\n",
      "timeframe: 4 section: 410 alpha: 12.21503044165913\n",
      "timeframe: 4 section: 362 alpha: 25.842882731743906\n",
      "timeframe: 4 section: 555 alpha: 33.72574976060862\n",
      "timeframe: 3 section: 430 alpha: 21.39422052691968\n",
      "timeframe: 3 section: 508 alpha: 37.58092170067898\n",
      "timeframe: 4 section: 327 alpha: 18.49894118338074\n",
      "timeframe: 4 section: 155 alpha: 3.645979106561045\n",
      "timeframe: 3 section: 422 alpha: 10.513531494177105\n",
      "timeframe: 3 section: 396 alpha: 52.923794368747814\n",
      "timeframe: 4 section: 424 alpha: 44.47438203787004\n",
      "timeframe: 4 section: 231 alpha: 27.54092586846523\n",
      "timeframe: 4 section: 293 alpha: 126.53234861591176\n",
      "timeframe: 4 section: 286 alpha: 34.551739331796334\n",
      "timeframe: 4 section: 355 alpha: 20.95023668941471\n",
      "timeframe: 4 section: 134 alpha: 27.79547775466293\n",
      "timeframe: 4 section: 521 alpha: 50.75286670419143\n",
      "timeframe: 3 section: 533 alpha: 22.395492966699393\n",
      "timeframe: 4 section: 417 alpha: 43.552351494928885\n",
      "timeframe: 4 section: 197 alpha: 27.424868210367023\n",
      "timeframe: 3 section: 513 alpha: 38.004631253606874\n",
      "timeframe: 4 section: 396 alpha: 73.31036391645668\n",
      "timeframe: 4 section: 245 alpha: 54.87299822656628\n",
      "timeframe: 4 section: 445 alpha: 51.55715541721411\n",
      "timeframe: 4 section: 466 alpha: 24.956699162323844\n",
      "timeframe: 4 section: 542 alpha: 70.52869464326653\n",
      "timeframe: 4 section: 494 alpha: 8.32639214165123\n",
      "timeframe: 3 section: 463 alpha: 61.86185236681929\n",
      "timeframe: 3 section: 540 alpha: 32.48505608763809\n",
      "timeframe: 4 section: 272 alpha: 26.905515732496063\n",
      "timeframe: 4 section: 259 alpha: 38.71603729330396\n",
      "timeframe: 4 section: 432 alpha: 49.560255314942694\n",
      "timeframe: 4 section: 224 alpha: 53.380048082570255\n",
      "timeframe: 4 section: 211 alpha: 105.40440621042787\n",
      "timeframe: 4 section: 348 alpha: 27.15631607530532\n",
      "timeframe: 4 section: 452 alpha: 21.887253187487673\n",
      "timeframe: 4 section: 266 alpha: 36.2990947812704\n",
      "timeframe: 4 section: 549 alpha: 14.87713157999521\n",
      "timeframe: 4 section: 335 alpha: 50.56426123462648\n",
      "timeframe: 4 section: 459 alpha: 55.76713054901093\n",
      "timeframe: 4 section: 528 alpha: 38.049720630372946\n",
      "timeframe: 4 section: 190 alpha: 12.324527710281874\n",
      "timeframe: 3 section: 554 alpha: 63.51617907820069\n",
      "timeframe: 4 section: 383 alpha: 24.533354625222024\n",
      "timeframe: 4 section: 342 alpha: 15.748388232914888\n",
      "timeframe: 4 section: 369 alpha: 8.717470405878224\n",
      "timeframe: 4 section: 473 alpha: 14.937019095219581\n",
      "timeframe: 4 section: 508 alpha: 29.79036203305354\n",
      "timeframe: 4 section: 321 alpha: 62.923281017821125\n",
      "timeframe: 4 section: 238 alpha: 21.39397906586827\n",
      "timeframe: 3 section: 472 alpha: 52.36913361515521\n",
      "timeframe: 4 section: 280 alpha: 31.404950515454956\n",
      "timeframe: 4 section: 411 alpha: 71.27524235818628\n",
      "timeframe: 4 section: 535 alpha: 33.25974174743328\n",
      "timeframe: 4 section: 314 alpha: 15.495346942291306\n",
      "timeframe: 4 section: 487 alpha: 34.7854849275609\n",
      "timeframe: 4 section: 438 alpha: 45.707608429051334\n",
      "timeframe: 3 section: 445 alpha: 5.478434765610747\n",
      "timeframe: 4 section: 390 alpha: 40.43076426737122\n",
      "timeframe: 4 section: 501 alpha: 49.94446044596971\n",
      "timeframe: 4 section: 480 alpha: 21.63640447511656\n",
      "timeframe: 4 section: 363 alpha: 43.62892159776549\n",
      "timeframe: 4 section: 307 alpha: 44.180652814506416\n",
      "timeframe: 4 section: 301 alpha: 16.222938471785213\n",
      "timeframe: 4 section: 218 alpha: 22.535709198479417\n",
      "timeframe: 4 section: 404 alpha: 42.289107879794486\n",
      "timeframe: 4 section: 294 alpha: 19.02900408388714\n",
      "timeframe: 4 section: 328 alpha: 27.40519288008217\n",
      "timeframe: 4 section: 253 alpha: 20.801374050162917\n",
      "timeframe: 3 section: 437 alpha: 27.191313978387743\n",
      "timeframe: 3 section: 410 alpha: 28.349250619687762\n",
      "timeframe: 3 section: 417 alpha: 10.501289714436357\n",
      "timeframe: 3 section: 485 alpha: 24.105348491155443\n",
      "timeframe: 4 section: 515 alpha: 41.188714929659795\n",
      "timeframe: 4 section: 495 alpha: 73.89423630371658\n",
      "timeframe: 4 section: 425 alpha: 25.590762220986562\n",
      "timeframe: 4 section: 356 alpha: 34.814248883193734\n",
      "timeframe: 3 section: 431 alpha: 11.06342242224916\n",
      "timeframe: 4 section: 287 alpha: 19.531258346377953\n",
      "timeframe: 4 section: 522 alpha: 27.14766903611783\n",
      "timeframe: 4 section: 377 alpha: 72.34025719921875\n",
      "timeframe: 4 section: 467 alpha: 22.6584931797846\n",
      "timeframe: 4 section: 273 alpha: 24.84048746575948\n",
      "timeframe: 3 section: 499 alpha: 24.40940745182171\n",
      "timeframe: 4 section: 232 alpha: 31.98957868062122\n",
      "timeframe: 3 section: 200 alpha: 21.612258413644597\n",
      "timeframe: 4 section: 446 alpha: 4.995102063646492\n",
      "timeframe: 4 section: 336 alpha: 14.918046192528024\n",
      "timeframe: 3 section: 520 alpha: 4.67988569168438\n",
      "timeframe: 3 section: 368 alpha: 12.495322711667436\n",
      "timeframe: 4 section: 397 alpha: 34.73601761738233\n",
      "timeframe: 4 section: 453 alpha: 41.234757511372614\n",
      "timeframe: 4 section: 260 alpha: 12.222735558970129\n",
      "timeframe: 4 section: 543 alpha: 86.88430368260286\n",
      "timeframe: 4 section: 433 alpha: 37.28306011248104\n",
      "timeframe: 4 section: 246 alpha: 33.5116298902708\n",
      "timeframe: 3 section: 326 alpha: 23.275232367209274\n",
      "timeframe: 3 section: 549 alpha: 9.663695044258167\n",
      "timeframe: 4 section: 418 alpha: 19.609510961093836\n",
      "timeframe: 4 section: 550 alpha: 19.13906205575558\n",
      "timeframe: 4 section: 460 alpha: 36.638652061459226\n",
      "timeframe: 4 section: 474 alpha: 8.66523766048418\n",
      "timeframe: 4 section: 225 alpha: 30.81106031481939\n",
      "timeframe: 4 section: 267 alpha: 35.017970303592364\n",
      "timeframe: 4 section: 322 alpha: 50.17994788442528\n",
      "timeframe: 4 section: 439 alpha: 88.04537081319229\n",
      "timeframe: 4 section: 343 alpha: 31.191038756794544\n",
      "timeframe: 4 section: 391 alpha: 28.654840425888057\n",
      "timeframe: 3 section: 527 alpha: 36.79690812197816\n",
      "timeframe: 4 section: 509 alpha: 49.70036075556405\n",
      "timeframe: 3 section: 478 alpha: 33.75749106764092\n",
      "timeframe: 4 section: 536 alpha: 42.68037503339503\n",
      "timeframe: 4 section: 529 alpha: 40.430795855625824\n",
      "timeframe: 4 section: 370 alpha: 7.892570106350001\n",
      "timeframe: 4 section: 384 alpha: 38.43041465553349\n",
      "timeframe: 4 section: 405 alpha: 108.51704725264122\n",
      "timeframe: 4 section: 329 alpha: 82.19271736515728\n",
      "timeframe: 4 section: 412 alpha: 25.728564006133695\n",
      "timeframe: 4 section: 502 alpha: 17.12822413212557\n",
      "timeframe: 4 section: 308 alpha: 18.40976680615945\n",
      "timeframe: 4 section: 349 alpha: 38.008249586186764\n",
      "timeframe: 3 section: 492 alpha: 40.93885334735174\n",
      "timeframe: 3 section: 452 alpha: 42.64462154982059\n",
      "timeframe: 3 section: 403 alpha: 32.22393590879209\n",
      "timeframe: 4 section: 315 alpha: 33.01842498229051\n",
      "timeframe: 4 section: 488 alpha: 32.52433732865717\n",
      "timeframe: 4 section: 295 alpha: 22.98565346730697\n",
      "timeframe: 4 section: 481 alpha: 25.942027768406007\n",
      "timeframe: 4 section: 302 alpha: 9.286473735833393\n",
      "timeframe: 4 section: 239 alpha: 22.452252100024495\n",
      "timeframe: 4 section: 496 alpha: 52.89688736842045\n",
      "timeframe: 4 section: 364 alpha: 34.27768946707508\n",
      "timeframe: 4 section: 274 alpha: 16.776328722519295\n",
      "timeframe: 4 section: 357 alpha: 31.441272539778932\n",
      "timeframe: 4 section: 281 alpha: 71.01423072610991\n",
      "timeframe: 4 section: 544 alpha: 23.377919629577885\n",
      "timeframe: 4 section: 398 alpha: 9.464595295644036\n",
      "timeframe: 4 section: 426 alpha: 18.273492156992162\n",
      "timeframe: 4 section: 378 alpha: 18.942218408645044\n",
      "timeframe: 4 section: 288 alpha: 34.570105891267474\n",
      "timeframe: 3 section: 464 alpha: 9.934697406216289\n",
      "timeframe: 4 section: 523 alpha: 11.998676619867503\n",
      "timeframe: 4 section: 440 alpha: 10.620581657227582\n",
      "timeframe: 4 section: 468 alpha: 9.880619679000771\n",
      "timeframe: 4 section: 337 alpha: 1.4822199942691932\n",
      "timeframe: 4 section: 516 alpha: 29.52137532503808\n",
      "timeframe: 4 section: 434 alpha: 47.413405504102286\n",
      "timeframe: 4 section: 475 alpha: 26.220663317430976\n",
      "timeframe: 4 section: 447 alpha: 27.19244634895914\n",
      "timeframe: 3 section: 500 alpha: 36.35702452194277\n",
      "timeframe: 4 section: 419 alpha: 28.805747840257055\n",
      "timeframe: 3 section: 534 alpha: 27.34909092117659\n",
      "timeframe: 4 section: 461 alpha: 15.02074378243369\n",
      "timeframe: 4 section: 392 alpha: 39.06086637595441\n",
      "timeframe: 4 section: 537 alpha: 16.298847272593385\n",
      "timeframe: 4 section: 454 alpha: 35.0050546128726\n",
      "timeframe: 4 section: 551 alpha: 32.720324875373436\n",
      "timeframe: 4 section: 371 alpha: 24.748884114344648\n",
      "timeframe: 3 section: 457 alpha: 24.08049610706219\n",
      "timeframe: 4 section: 323 alpha: 52.79098330773437\n",
      "timeframe: 4 section: 330 alpha: 9.261206856901003\n",
      "timeframe: 4 section: 385 alpha: 20.84589871893891\n",
      "timeframe: 3 section: 423 alpha: 30.9071640132141\n",
      "timeframe: 3 section: 541 alpha: 107.37870987240197\n",
      "timeframe: 4 section: 344 alpha: 30.388613184177814\n",
      "timeframe: 4 section: 406 alpha: 75.14237331404858\n",
      "timeframe: 4 section: 530 alpha: 46.978068870306\n",
      "timeframe: 4 section: 489 alpha: 42.437174654144684\n",
      "timeframe: 4 section: 503 alpha: 18.787867299528386\n",
      "timeframe: 4 section: 350 alpha: 13.933443360072074\n",
      "timeframe: 4 section: 413 alpha: 40.55927251490226\n",
      "timeframe: 3 section: 514 alpha: 28.846378758166747\n",
      "timeframe: 4 section: 316 alpha: 88.7832069249758\n",
      "timeframe: 4 section: 358 alpha: 143.60840630795298\n",
      "timeframe: 4 section: 482 alpha: 21.480614574053533\n",
      "timeframe: 4 section: 510 alpha: 21.987212144391837\n",
      "timeframe: 4 section: 309 alpha: 64.27593138789298\n",
      "timeframe: 4 section: 517 alpha: 41.418707096187504\n",
      "timeframe: 4 section: 399 alpha: 16.069762994246958\n",
      "timeframe: 4 section: 469 alpha: 37.947414677680506\n",
      "timeframe: 4 section: 435 alpha: 18.292654854971985\n",
      "timeframe: 4 section: 427 alpha: 46.370404093750516\n",
      "timeframe: 4 section: 441 alpha: 35.203338587722165\n",
      "timeframe: 4 section: 538 alpha: 15.866491994938041\n",
      "timeframe: 4 section: 420 alpha: 34.05736823787121\n",
      "timeframe: 4 section: 379 alpha: 15.335638138307226\n",
      "timeframe: 4 section: 497 alpha: 36.14487614548779\n",
      "timeframe: 4 section: 524 alpha: 13.506368673265465\n",
      "timeframe: 4 section: 393 alpha: 19.437459971914667\n",
      "timeframe: 4 section: 462 alpha: 15.619481986475643\n",
      "timeframe: 4 section: 448 alpha: 34.8282250217404\n",
      "timeframe: 4 section: 476 alpha: 30.657763072373818\n",
      "timeframe: 3 section: 555 alpha: 37.570778125039745\n",
      "timeframe: 3 section: 438 alpha: 10.666508719898651\n",
      "timeframe: 4 section: 365 alpha: 27.196224983046527\n",
      "timeframe: 4 section: 414 alpha: 23.265069303893227\n",
      "timeframe: 4 section: 545 alpha: 54.209435723127854\n",
      "timeframe: 3 section: 479 alpha: 4.858138127369761\n",
      "timeframe: 4 section: 372 alpha: 53.45026707600299\n",
      "timeframe: 3 section: 486 alpha: 23.161547726828726\n",
      "timeframe: 4 section: 504 alpha: 25.24381748741113\n",
      "timeframe: 4 section: 407 alpha: 23.59360677800138\n",
      "timeframe: 4 section: 351 alpha: 35.401907132345656\n",
      "timeframe: 4 section: 386 alpha: 56.76535770118112\n",
      "timeframe: 4 section: 449 alpha: 130.9249816279951\n",
      "timeframe: 4 section: 552 alpha: 44.32637794645617\n",
      "timeframe: 4 section: 455 alpha: 30.62923397908853\n",
      "timeframe: 3 section: 473 alpha: 17.56841574455629\n",
      "timeframe: 4 section: 490 alpha: 40.30478142694165\n",
      "timeframe: 3 section: 521 alpha: 106.40213324543542\n",
      "timeframe: 4 section: 400 alpha: 30.876971568752534\n",
      "timeframe: 4 section: 483 alpha: 18.30519167231794\n",
      "timeframe: 4 section: 525 alpha: 26.79048967190312\n",
      "timeframe: 4 section: 442 alpha: 19.31850719033837\n",
      "timeframe: 4 section: 511 alpha: 52.72648203914942\n",
      "timeframe: 4 section: 463 alpha: 55.13966678479189\n",
      "timeframe: 4 section: 518 alpha: 23.841615302001163\n",
      "timeframe: 4 section: 470 alpha: 30.25052865300014\n",
      "timeframe: 4 section: 531 alpha: 22.19827401530145\n",
      "timeframe: 4 section: 539 alpha: 17.84423299862261\n",
      "timeframe: 4 section: 421 alpha: 39.206040877902105\n",
      "timeframe: 4 section: 505 alpha: 6.077160174058941\n",
      "timeframe: 4 section: 546 alpha: 47.206591426675104\n",
      "timeframe: 4 section: 477 alpha: 44.590318380091816\n",
      "timeframe: 4 section: 498 alpha: 36.797334666296024\n",
      "timeframe: 4 section: 428 alpha: 47.66865597842745\n",
      "timeframe: 4 section: 0 alpha: 28.977342492014\n",
      "timeframe: 4 section: 456 alpha: 51.911389166485975\n",
      "timeframe: 3 section: 493 alpha: 49.5961232328906\n",
      "timeframe: 4 section: 491 alpha: 19.417614315975445\n",
      "timeframe: 4 section: 553 alpha: 57.65430185667362\n",
      "timeframe: 4 section: 512 alpha: 1.5251105609768891\n",
      "timeframe: 4 section: 519 alpha: 10.177083422658253\n",
      "timeframe: 3 section: 424 alpha: 39.17222120813532\n",
      "timeframe: 4 section: 532 alpha: 101.13291679961141\n",
      "timeframe: 3 section: 528 alpha: 59.63248706099016\n",
      "timeframe: 4 section: 526 alpha: 43.198956360027644\n",
      "timeframe: 4 section: 540 alpha: 39.8132396032085\n",
      "timeframe: 4 section: 547 alpha: 12.891330862607893\n",
      "timeframe: 3 section: 542 alpha: 81.24854035266134\n",
      "timeframe: 4 section: 1 alpha: 17.3742502833032\n",
      "timeframe: 4 section: 484 alpha: 29.44094059416942\n",
      "timeframe: 3 section: 515 alpha: 16.439320572061867\n",
      "timeframe: 3 section: 494 alpha: 27.579966741867647\n",
      "timeframe: 3 section: 550 alpha: 31.50287949082069\n",
      "timeframe: 4 section: 533 alpha: 37.61602846777004\n",
      "timeframe: 3 section: 465 alpha: 37.54809448944159\n",
      "timeframe: 4 section: 554 alpha: 65.81229217328259\n",
      "timeframe: 3 section: 501 alpha: 34.98616490399832\n",
      "timeframe: 3 section: 458 alpha: 41.95410934675149\n",
      "timeframe: 3 section: 543 alpha: 4.893749603859307\n",
      "timeframe: 3 section: 480 alpha: 46.15905645793437\n",
      "timeframe: 3 section: 522 alpha: 42.026696610761505\n",
      "timeframe: 3 section: 535 alpha: 20.145690981649146\n",
      "timeframe: 3 section: 487 alpha: 43.93162774195336\n",
      "timeframe: 3 section: 466 alpha: 29.72880386629883\n",
      "timeframe: 3 section: 529 alpha: 21.4418362352855\n",
      "timeframe: 3 section: 459 alpha: 34.7295455827712\n",
      "timeframe: 3 section: 536 alpha: 36.45049988558566\n",
      "CPU times: user 3.76 s, sys: 12.3 s, total: 16.1 s\n",
      "Wall time: 4min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-399:\n",
      "Process ForkPoolWorker-390:\n",
      "Process ForkPoolWorker-343:\n",
      "Process ForkPoolWorker-371:\n",
      "Process ForkPoolWorker-373:\n",
      "Process ForkPoolWorker-366:\n",
      "Process ForkPoolWorker-394:\n",
      "Process ForkPoolWorker-383:\n",
      "Process ForkPoolWorker-398:\n",
      "Process ForkPoolWorker-397:\n",
      "Process ForkPoolWorker-315:\n",
      "Process ForkPoolWorker-374:\n",
      "Process ForkPoolWorker-354:\n",
      "Process ForkPoolWorker-379:\n",
      "Process ForkPoolWorker-340:\n",
      "Process ForkPoolWorker-310:\n",
      "Process ForkPoolWorker-335:\n",
      "Process ForkPoolWorker-360:\n",
      "Process ForkPoolWorker-338:\n",
      "Process ForkPoolWorker-349:\n",
      "Process ForkPoolWorker-388:\n",
      "Process ForkPoolWorker-333:\n",
      "Process ForkPoolWorker-330:\n",
      "Process ForkPoolWorker-384:\n",
      "Process ForkPoolWorker-347:\n",
      "Process ForkPoolWorker-325:\n",
      "Process ForkPoolWorker-329:\n",
      "Process ForkPoolWorker-382:\n",
      "Process ForkPoolWorker-375:\n",
      "Process ForkPoolWorker-348:\n",
      "Process ForkPoolWorker-346:\n",
      "Process ForkPoolWorker-387:\n",
      "Process ForkPoolWorker-332:\n",
      "Process ForkPoolWorker-369:\n",
      "Process ForkPoolWorker-313:\n",
      "Process ForkPoolWorker-396:\n",
      "Process ForkPoolWorker-395:\n",
      "Process ForkPoolWorker-370:\n",
      "Process ForkPoolWorker-393:\n",
      "Process ForkPoolWorker-376:\n",
      "Process ForkPoolWorker-363:\n",
      "Process ForkPoolWorker-357:\n",
      "Process ForkPoolWorker-364:\n",
      "Process ForkPoolWorker-323:\n",
      "Process ForkPoolWorker-312:\n",
      "Process ForkPoolWorker-381:\n",
      "Process ForkPoolWorker-359:\n",
      "Process ForkPoolWorker-380:\n",
      "Process ForkPoolWorker-352:\n",
      "Process ForkPoolWorker-392:\n",
      "Process ForkPoolWorker-331:\n",
      "Process ForkPoolWorker-389:\n",
      "Process ForkPoolWorker-317:\n",
      "Process ForkPoolWorker-386:\n",
      "Process ForkPoolWorker-336:\n",
      "Process ForkPoolWorker-344:\n",
      "Process ForkPoolWorker-400:\n",
      "Process ForkPoolWorker-319:\n",
      "Process ForkPoolWorker-306:\n",
      "Process ForkPoolWorker-337:\n",
      "Process ForkPoolWorker-391:\n",
      "Process ForkPoolWorker-326:\n",
      "Process ForkPoolWorker-342:\n",
      "Process ForkPoolWorker-367:\n",
      "Process ForkPoolWorker-365:\n",
      "Process ForkPoolWorker-307:\n",
      "Process ForkPoolWorker-355:\n",
      "Process ForkPoolWorker-304:\n",
      "Process ForkPoolWorker-341:\n",
      "Process ForkPoolWorker-350:\n",
      "Process ForkPoolWorker-301:\n",
      "Process ForkPoolWorker-318:\n",
      "Process ForkPoolWorker-316:\n",
      "Process ForkPoolWorker-385:\n",
      "Process ForkPoolWorker-320:\n",
      "Process ForkPoolWorker-358:\n",
      "Process ForkPoolWorker-328:\n",
      "Process ForkPoolWorker-322:\n",
      "Process ForkPoolWorker-353:\n",
      "Process ForkPoolWorker-361:\n",
      "Process ForkPoolWorker-303:\n",
      "Process ForkPoolWorker-311:\n",
      "Process ForkPoolWorker-378:\n",
      "Process ForkPoolWorker-334:\n",
      "Process ForkPoolWorker-351:\n",
      "Process ForkPoolWorker-368:\n",
      "Process ForkPoolWorker-362:\n",
      "Process ForkPoolWorker-308:\n",
      "Process ForkPoolWorker-372:\n",
      "Process ForkPoolWorker-356:\n",
      "Process ForkPoolWorker-324:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-321:\n",
      "Process ForkPoolWorker-309:\n",
      "Process ForkPoolWorker-327:\n",
      "Process ForkPoolWorker-339:\n",
      "Process ForkPoolWorker-314:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-305:\n",
      "Process ForkPoolWorker-302:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-345:\n",
      "Process ForkPoolWorker-377:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pool = mp.Pool(processes=100)\n",
    "\n",
    "results_time = pool.map(fit_lasso_time, range(nSegments * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_time = []\n",
    "\n",
    "for i in range(nSegments * 5):\n",
    "    preds_lasso_time.append(results_time[i].predict(X_test_time[i//556]))\n",
    "\n",
    "\n",
    "#preds_lasso_time_s = np.transpose(preds_lasso_time[:-556].reshape(4,556,80), (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 80, 556)\n",
      "(1, 60, 556)\n",
      "(211280,)\n"
     ]
    }
   ],
   "source": [
    "preds_lasso_time_s = np.array(preds_lasso_time[:-556])\n",
    "preds_lasso_time_s = np.transpose(preds_lasso_time_s.reshape(4,556,80), (0, 2, 1))\n",
    "print(preds_lasso_time_s.shape)\n",
    "\n",
    "preds_lasso_time_e = np.array(preds_lasso_time[-556:])\n",
    "preds_lasso_time_e = np.transpose(preds_lasso_time_e.reshape(1,556,60), (0, 2, 1))\n",
    "print(preds_lasso_time_e.shape)\n",
    "\n",
    "preds_flat = np.concatenate((preds_lasso_time_s.flatten(), preds_lasso_time_e.flatten()))\n",
    "print(preds_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211280,)\n"
     ]
    }
   ],
   "source": [
    "y_flat = np.concatenate((np.array(Y_test_time[:-1]).flatten(), np.array(Y_test_time[-1]).flatten()))\n",
    "print(y_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec CV et time, globale\n",
      "MSE: 105.44522582146786\n",
      "MAE: 7.01154682526274\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec CV et time, globale\")\n",
    "print(\"MSE:\", mean_squared_error(preds_flat, y_flat))\n",
    "print(\"MAE:\", mean_absolute_error(preds_flat, y_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "As=[]\n",
    "for i in range(5):\n",
    "    A = [a.coef_ for a in results_time[i*nSegments:(i+1)*nSegments]]\n",
    "    A = np.array(A)\n",
    "    As.append(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "for i in range(19):\n",
    "    A.append(As[i//4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risque_time(A, X, Y):\n",
    "    n = 45\n",
    "    T = 19\n",
    "    r = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for t in range(T):\n",
    "            if t//4 == 4:\n",
    "                r += np.mean((Y[t//4][i*3+t%3] - np.dot(A[t], X[t//4][i*3+t%3]))**2)\n",
    "            else:\n",
    "                r += np.mean((Y[t//4][i*4+t%4] - np.dot(A[t], X[t//4][i*4+t%4]))**2)\n",
    "    r = r/(n*T)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=19\n",
    "T//4, T%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=13\n",
    "j=5\n",
    "k=T//4\n",
    "\n",
    "if t//4 == 4:\n",
    "    Y_train_time[t//4][i*3+t%3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.02917980806032"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risque_time(A, X_train_time, Y_train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risque du modèle spécifique: 85.03**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle sélectif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 Created!\n",
      "n = 65\n",
      "Z3 Centré !\n"
     ]
    }
   ],
   "source": [
    "Z3 = []\n",
    "\n",
    "for i in range(int((speedDF.shape[1])/20)):\n",
    "    Z3.append(speedDF.iloc[:,i*20:(i+1)*20].values)\n",
    "\n",
    "print(\"Z3 Created!\")\n",
    "n3 = len(Z3)\n",
    "print(\"n =\", n3)\n",
    "\n",
    "Z3 = np.array(Z3)\n",
    "\n",
    "Z3_train = Z3[:45]\n",
    "Z3_test = Z3[45:]\n",
    "\n",
    "\n",
    "M3 = (1/45)*Z3_train.sum(axis=0)\n",
    "\n",
    "for i in range(45):\n",
    "    Z3_train[i] = Z3_train[i] - M3\n",
    "for i in range(65-45):\n",
    "    Z3_test[i] = Z3_test[i] - M3\n",
    "    \n",
    "print(\"Z3 Centré !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_Y(Z, T):\n",
    "    \n",
    "    X1 = Z[:, :, :T]\n",
    "    Y1 = Z[:, :, 1:T+1]\n",
    "    X2 = Z[:, :, T:-1]\n",
    "    Y2 = Z[:, :, T+1:]\n",
    "    X1 = np.concatenate(X1, axis=1)\n",
    "    Y1 = np.concatenate(Y1, axis=1)\n",
    "    X2 = np.concatenate(X2, axis=1)\n",
    "    Y2 = np.concatenate(Y2, axis=1)\n",
    "    return X1.T, Y1.T, X2.T, Y2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 556) (405, 556)\n",
      "(200, 556) (180, 556)\n"
     ]
    }
   ],
   "source": [
    "X1_train, Y1_train, X2_train, Y2_train  = X_Y(Z3_train, T)\n",
    "print(X1_train.shape, X2_train.shape)\n",
    "X1_test, Y1_test, X2_test, Y2_test   = X_Y(Z3_test, T)\n",
    "print(X1_test.shape, X2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-817:\n",
      "Process ForkPoolWorker-818:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "A_lasso_parra_1 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments)]\n",
    "A_lasso_parra_2 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-820:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "def fit_lasso_double(i):\n",
    "    A_lasso_parra_1[i].fit(X1_train, Y1_train[:, i])\n",
    "    A_lasso_parra_2[i].fit(X2_train, Y2_train[:, i])\n",
    "    print(i)\n",
    "    return A_lasso_parra_1[i], A_lasso_parra_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "18\n",
      "36\n",
      "14\n",
      "16\n",
      "30\n",
      "114\n",
      "120\n",
      "104\n",
      "148\n",
      "86\n",
      "82\n",
      "70\n",
      "34\n",
      "170\n",
      "126\n",
      "108\n",
      "50\n",
      "19\n",
      "38\n",
      "98\n",
      "164\n",
      "156\n",
      "154\n",
      "56\n",
      "10\n",
      "160\n",
      "52\n",
      "15\n",
      "58\n",
      "4\n",
      "35\n",
      "130\n",
      "74\n",
      "105\n",
      "162\n",
      "112\n",
      "146\n",
      "118\n",
      "22\n",
      "158\n",
      "37\n",
      "178\n",
      "66\n",
      "24\n",
      "68\n",
      "144\n",
      "138\n",
      "2\n",
      "12\n",
      "84\n",
      "80\n",
      "134\n",
      "194\n",
      "136\n",
      "90\n",
      "106\n",
      "116\n",
      "132\n",
      "72\n",
      "61\n",
      "204\n",
      "67\n",
      "110\n",
      "96\n",
      "124\n",
      "23\n",
      "44\n",
      "184\n",
      "8\n",
      "71\n",
      "76\n",
      "54\n",
      "51\n",
      "127\n",
      "62\n",
      "88\n",
      "174\n",
      "46\n",
      "57\n",
      "20\n",
      "168\n",
      "176\n",
      "180\n",
      "186\n",
      "102\n",
      "6\n",
      "137\n",
      "94\n",
      "140\n",
      "155\n",
      "145\n",
      "149\n",
      "26\n",
      "78\n",
      "40\n",
      "192\n",
      "32\n",
      "92\n",
      "172\n",
      "122\n",
      "159\n",
      "83\n",
      "166\n",
      "64\n",
      "206\n",
      "190\n",
      "39\n",
      "161\n",
      "205\n",
      "121\n",
      "42\n",
      "128\n",
      "169\n",
      "3\n",
      "31\n",
      "182\n",
      "181\n",
      "208\n",
      "93\n",
      "73\n",
      "81\n",
      "171\n",
      "0\n",
      "196\n",
      "100\n",
      "53\n",
      "87\n",
      "55\n",
      "69\n",
      "48\n",
      "152\n",
      "202\n",
      "28\n",
      "200\n",
      "123\n",
      "185\n",
      "17\n",
      "157\n",
      "109\n",
      "119\n",
      "150\n",
      "147\n",
      "11\n",
      "75\n",
      "224\n",
      "5\n",
      "99\n",
      "79\n",
      "193\n",
      "242\n",
      "142\n",
      "49\n",
      "258\n",
      "25\n",
      "135\n",
      "228\n",
      "115\n",
      "210\n",
      "220\n",
      "165\n",
      "107\n",
      "13\n",
      "111\n",
      "268\n",
      "244\n",
      "59\n",
      "198\n",
      "195\n",
      "131\n",
      "188\n",
      "177\n",
      "163\n",
      "27\n",
      "250\n",
      "117\n",
      "139\n",
      "276\n",
      "89\n",
      "179\n",
      "212\n",
      "125\n",
      "85\n",
      "191\n",
      "264\n",
      "254\n",
      "113\n",
      "216\n",
      "9\n",
      "133\n",
      "234\n",
      "218\n",
      "65\n",
      "245\n",
      "153\n",
      "260\n",
      "7\n",
      "274\n",
      "226\n",
      "248\n",
      "97\n",
      "209\n",
      "41\n",
      "63\n",
      "95\n",
      "173\n",
      "29\n",
      "101\n",
      "238\n",
      "21\n",
      "298\n",
      "187\n",
      "256\n",
      "167\n",
      "232\n",
      "129\n",
      "230\n",
      "214\n",
      "91\n",
      "201\n",
      "280\n",
      "225\n",
      "308\n",
      "175\n",
      "278\n",
      "286\n",
      "222\n",
      "249\n",
      "300\n",
      "207\n",
      "183\n",
      "277\n",
      "270\n",
      "77\n",
      "45\n",
      "316\n",
      "243\n",
      "314\n",
      "275\n",
      "197\n",
      "282\n",
      "261\n",
      "294\n",
      "370\n",
      "257\n",
      "290\n",
      "288\n",
      "141\n",
      "203\n",
      "103\n",
      "330\n",
      "342\n",
      "33\n",
      "252\n",
      "143\n",
      "269\n",
      "292\n",
      "43\n",
      "47\n",
      "151\n",
      "233\n",
      "284\n",
      "240\n",
      "336\n",
      "358\n",
      "246\n",
      "332\n",
      "380\n",
      "338\n",
      "262\n",
      "376\n",
      "296\n",
      "1\n",
      "266\n",
      "374\n",
      "371\n",
      "272\n",
      "354\n",
      "302\n",
      "265\n",
      "324\n",
      "259\n",
      "227\n",
      "211\n",
      "360\n",
      "318\n",
      "239\n",
      "217\n",
      "229\n",
      "322\n",
      "251\n",
      "199\n",
      "372\n",
      "317\n",
      "221\n",
      "368\n",
      "326\n",
      "213\n",
      "430\n",
      "398\n",
      "299\n",
      "352\n",
      "189\n",
      "235\n",
      "340\n",
      "304\n",
      "312\n",
      "422\n",
      "310\n",
      "366\n",
      "400\n",
      "231\n",
      "301\n",
      "356\n",
      "375\n",
      "306\n",
      "346\n",
      "328\n",
      "320\n",
      "388\n",
      "271\n",
      "344\n",
      "267\n",
      "432\n",
      "255\n",
      "236\n",
      "334\n",
      "412\n",
      "337\n",
      "382\n",
      "378\n",
      "373\n",
      "287\n",
      "440\n",
      "348\n",
      "394\n",
      "431\n",
      "406\n",
      "436\n",
      "339\n",
      "215\n",
      "450\n",
      "309\n",
      "291\n",
      "444\n",
      "392\n",
      "263\n",
      "333\n",
      "315\n",
      "355\n",
      "362\n",
      "295\n",
      "297\n",
      "241\n",
      "219\n",
      "389\n",
      "424\n",
      "468\n",
      "413\n",
      "293\n",
      "416\n",
      "402\n",
      "420\n",
      "279\n",
      "331\n",
      "396\n",
      "289\n",
      "414\n",
      "345\n",
      "283\n",
      "307\n",
      "281\n",
      "390\n",
      "359\n",
      "426\n",
      "437\n",
      "442\n",
      "285\n",
      "223\n",
      "343\n",
      "253\n",
      "350\n",
      "247\n",
      "381\n",
      "408\n",
      "410\n",
      "448\n",
      "466\n",
      "445\n",
      "404\n",
      "462\n",
      "341\n",
      "418\n",
      "313\n",
      "369\n",
      "303\n",
      "273\n",
      "379\n",
      "384\n",
      "386\n",
      "399\n",
      "500\n",
      "446\n",
      "361\n",
      "391\n",
      "454\n",
      "329\n",
      "364\n",
      "502\n",
      "395\n",
      "325\n",
      "494\n",
      "434\n",
      "504\n",
      "428\n",
      "323\n",
      "353\n",
      "349\n",
      "512\n",
      "438\n",
      "319\n",
      "451\n",
      "474\n",
      "476\n",
      "452\n",
      "327\n",
      "506\n",
      "401\n",
      "377\n",
      "456\n",
      "470\n",
      "508\n",
      "367\n",
      "516\n",
      "405\n",
      "524\n",
      "393\n",
      "423\n",
      "480\n",
      "458\n",
      "305\n",
      "443\n",
      "464\n",
      "335\n",
      "429\n",
      "383\n",
      "484\n",
      "514\n",
      "411\n",
      "548\n",
      "433\n",
      "503\n",
      "363\n",
      "507\n",
      "449\n",
      "482\n",
      "544\n",
      "311\n",
      "417\n",
      "520\n",
      "460\n",
      "347\n",
      "407\n",
      "237\n",
      "486\n",
      "435\n",
      "505\n",
      "496\n",
      "490\n",
      "467\n",
      "441\n",
      "469\n",
      "492\n",
      "421\n",
      "427\n",
      "351\n",
      "403\n",
      "546\n",
      "357\n",
      "549\n",
      "518\n",
      "538\n",
      "528\n",
      "510\n",
      "425\n",
      "532\n",
      "515\n",
      "542\n",
      "530\n",
      "536\n",
      "472\n",
      "498\n",
      "534\n",
      "478\n",
      "387\n",
      "501\n",
      "550\n",
      "552\n",
      "475\n",
      "397\n",
      "321\n",
      "385\n",
      "483\n",
      "554\n",
      "415\n",
      "526\n",
      "453\n",
      "481\n",
      "525\n",
      "459\n",
      "540\n",
      "521\n",
      "439\n",
      "365\n",
      "488\n",
      "471\n",
      "477\n",
      "447\n",
      "513\n",
      "457\n",
      "519\n",
      "409\n",
      "455\n",
      "487\n",
      "509\n",
      "522\n",
      "419\n",
      "517\n",
      "485\n",
      "537\n",
      "545\n",
      "465\n",
      "491\n",
      "495\n",
      "543\n",
      "463\n",
      "531\n",
      "497\n",
      "499\n",
      "539\n",
      "551\n",
      "511\n",
      "479\n",
      "541\n",
      "523\n",
      "547\n",
      "529\n",
      "555\n",
      "461\n",
      "553\n",
      "493\n",
      "489\n",
      "473\n",
      "535\n",
      "533\n",
      "527\n",
      "CPU times: user 53.7 s, sys: 2min 38s, total: 3min 32s\n",
      "Wall time: 33min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1004:\n",
      "Process ForkPoolWorker-997:\n",
      "Process ForkPoolWorker-1005:\n",
      "Process ForkPoolWorker-994:\n",
      "Process ForkPoolWorker-1013:\n",
      "Process ForkPoolWorker-993:\n",
      "Process ForkPoolWorker-996:\n",
      "Process ForkPoolWorker-1007:\n",
      "Process ForkPoolWorker-1010:\n",
      "Process ForkPoolWorker-1006:\n",
      "Process ForkPoolWorker-974:\n",
      "Process ForkPoolWorker-991:\n",
      "Process ForkPoolWorker-990:\n",
      "Process ForkPoolWorker-1000:\n",
      "Process ForkPoolWorker-1016:\n",
      "Process ForkPoolWorker-1002:\n",
      "Process ForkPoolWorker-1009:\n",
      "Process ForkPoolWorker-1003:\n",
      "Process ForkPoolWorker-1008:\n",
      "Process ForkPoolWorker-1018:\n",
      "Process ForkPoolWorker-1011:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-983:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-961:\n",
      "Process ForkPoolWorker-957:\n",
      "Process ForkPoolWorker-928:\n",
      "Process ForkPoolWorker-969:\n",
      "Process ForkPoolWorker-943:\n",
      "Process ForkPoolWorker-968:\n",
      "Process ForkPoolWorker-949:\n",
      "Process ForkPoolWorker-988:\n",
      "Process ForkPoolWorker-978:\n",
      "Process ForkPoolWorker-963:\n",
      "Process ForkPoolWorker-922:\n",
      "Process ForkPoolWorker-972:\n",
      "Process ForkPoolWorker-995:\n",
      "Process ForkPoolWorker-935:\n",
      "Process ForkPoolWorker-975:\n",
      "Process ForkPoolWorker-971:\n",
      "Process ForkPoolWorker-986:\n",
      "Process ForkPoolWorker-952:\n",
      "Process ForkPoolWorker-932:\n",
      "Process ForkPoolWorker-944:\n",
      "Process ForkPoolWorker-973:\n",
      "Process ForkPoolWorker-946:\n",
      "Process ForkPoolWorker-933:\n",
      "Process ForkPoolWorker-959:\n",
      "Process ForkPoolWorker-924:\n",
      "Process ForkPoolWorker-1001:\n",
      "Process ForkPoolWorker-979:\n",
      "Process ForkPoolWorker-939:\n",
      "Process ForkPoolWorker-925:\n",
      "Process ForkPoolWorker-945:\n",
      "Process ForkPoolWorker-951:\n",
      "Process ForkPoolWorker-940:\n",
      "Process ForkPoolWorker-941:\n",
      "Process ForkPoolWorker-921:\n",
      "Process ForkPoolWorker-947:\n",
      "Process ForkPoolWorker-950:\n",
      "Process ForkPoolWorker-980:\n",
      "Process ForkPoolWorker-955:\n",
      "Process ForkPoolWorker-956:\n",
      "Process ForkPoolWorker-936:\n",
      "Process ForkPoolWorker-1015:\n",
      "Process ForkPoolWorker-958:\n",
      "Process ForkPoolWorker-967:\n",
      "Process ForkPoolWorker-982:\n",
      "Process ForkPoolWorker-954:\n",
      "Process ForkPoolWorker-1012:\n",
      "Process ForkPoolWorker-960:\n",
      "Process ForkPoolWorker-965:\n",
      "Process ForkPoolWorker-989:\n",
      "Process ForkPoolWorker-919:\n",
      "Process ForkPoolWorker-942:\n",
      "Process ForkPoolWorker-976:\n",
      "Process ForkPoolWorker-998:\n",
      "Process ForkPoolWorker-923:\n",
      "Process ForkPoolWorker-953:\n",
      "Process ForkPoolWorker-966:\n",
      "Process ForkPoolWorker-964:\n",
      "Process ForkPoolWorker-934:\n",
      "Process ForkPoolWorker-962:\n",
      "Process ForkPoolWorker-938:\n",
      "Process ForkPoolWorker-977:\n",
      "Process ForkPoolWorker-992:\n",
      "Process ForkPoolWorker-929:\n",
      "Process ForkPoolWorker-926:\n",
      "Process ForkPoolWorker-916:\n",
      "Process ForkPoolWorker-917:\n",
      "Process ForkPoolWorker-927:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-948:\n",
      "Process ForkPoolWorker-930:\n",
      "Process ForkPoolWorker-937:\n",
      "Process ForkPoolWorker-981:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-920:\n",
      "Process ForkPoolWorker-918:\n",
      "Process ForkPoolWorker-931:\n",
      "Process ForkPoolWorker-984:\n",
      "Process ForkPoolWorker-1014:\n",
      "Process ForkPoolWorker-1017:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-987:\n",
      "Process ForkPoolWorker-999:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-970:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-985:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pool = mp.Pool(processes=100)\n",
    "\n",
    "results_double = pool.map(fit_lasso_double, range(nSegments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_double = []\n",
    "\n",
    "for i in range(nSegments):\n",
    "    pred1 = results_double[i][0].predict(X1_test)\n",
    "    pred2 = results_double[i][1].predict(X2_test)\n",
    "    preds_lasso_double.append(np.concatenate((pred1,pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.46944828052457"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_double[10][1].mse_path_[np.where(results_double[10][1].alphas_ == results_double[10][1].alpha_)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_double = np.array(preds_lasso_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 380)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_lasso_double.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 380)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_concat = np.concatenate((Y1_test, Y2_test)).T\n",
    "Y_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec CV et time, split en T=10\n",
      "MSE: 103.21306633834385\n",
      "MAE: 6.940675328469302\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec CV et time, split en T=10\")\n",
    "print(\"MSE:\", mean_squared_error(preds_lasso_double.flatten(), Y_concat.flatten()))\n",
    "print(\"MAE:\", mean_absolute_error(preds_lasso_double.flatten(), Y_concat.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step(T):\n",
    "    print(\"\\n------ STEP\", T ,\"------\\n\")\n",
    "    print('Splitting data')\n",
    "    X1_train, Y1_train, X2_train, Y2_train  = X_Y(Z3_train, T)\n",
    "    print(\"Train: X1 shape:\", X1_train.shape, \"X2 shape:\", X2_train.shape)\n",
    "    X1_test, Y1_test, X2_test, Y2_test   = X_Y(Z3_test, T)\n",
    "    print(\"Test: X1 shape:\", X1_test.shape, \"X2 shape:\", X2_test.shape)\n",
    "    print()\n",
    "    \n",
    "    A_lasso_parra_1 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=10) for i in range(10)]\n",
    "    A_lasso_parra_2 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=10) for i in range(10)]\n",
    "    print('Models created !')\n",
    "    \n",
    "    def fit_lasso_double(i):\n",
    "        A_lasso_parra_1[i].fit(X1_train, Y1_train[:, i])\n",
    "        A_lasso_parra_2[i].fit(X2_train, Y2_train[:, i])\n",
    "        return A_lasso_parra_1[i], A_lasso_parra_2[i]\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    start = time.time()\n",
    "    pool = mp.Pool(processes=10)\n",
    "    results_double = pool.map(fit_lasso_double, range(10))\n",
    "    end=time.time()\n",
    "    print(\"Training done in \", end - start, \"seconds\")\n",
    "    \n",
    "    mse=0\n",
    "    for i in range(10):\n",
    "        mse += T * np.mean(results_double[i][0].mse_path_[np.where(results_double[i][0].alphas_ == results_double[i][0].alpha_)[0][0]])\n",
    "        mse += (19-T) * np.mean(results_double[i][1].mse_path_[np.where(results_double[i][1].alphas_ == results_double[i][1].alpha_)[0][0]])\n",
    "    mse = mse/(19*10)\n",
    "    \n",
    "    print('MSE:', mse)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport worker\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 Created!\n",
      "n = 65\n",
      "Z Centré !\n"
     ]
    }
   ],
   "source": [
    "W = worker.T_optim(speedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ STEP 1 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (45, 556) X2 shape: (810, 556)\n",
      "Test: X1 shape: (20, 556) X2 shape: (360, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  32.95591616630554 seconds\n",
      "MSE: 88.45780683638188\n",
      "\n",
      "------ STEP 2 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (90, 556) X2 shape: (765, 556)\n",
      "Test: X1 shape: (40, 556) X2 shape: (340, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  35.873591899871826 seconds\n",
      "MSE: 88.69318773014912\n",
      "\n",
      "------ STEP 3 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (135, 556) X2 shape: (720, 556)\n",
      "Test: X1 shape: (60, 556) X2 shape: (320, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  40.24766731262207 seconds\n",
      "MSE: 89.5123232730679\n",
      "\n",
      "------ STEP 4 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (180, 556) X2 shape: (675, 556)\n",
      "Test: X1 shape: (80, 556) X2 shape: (300, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  97.3743577003479 seconds\n",
      "MSE: 89.6260708158256\n",
      "\n",
      "------ STEP 5 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (225, 556) X2 shape: (630, 556)\n",
      "Test: X1 shape: (100, 556) X2 shape: (280, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  95.09438061714172 seconds\n",
      "MSE: 89.77199351795741\n",
      "\n",
      "------ STEP 6 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (270, 556) X2 shape: (585, 556)\n",
      "Test: X1 shape: (120, 556) X2 shape: (260, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  86.63007307052612 seconds\n",
      "MSE: 89.61616929753893\n",
      "\n",
      "------ STEP 7 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (315, 556) X2 shape: (540, 556)\n",
      "Test: X1 shape: (140, 556) X2 shape: (240, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  74.84304523468018 seconds\n",
      "MSE: 89.90367510639949\n",
      "\n",
      "------ STEP 8 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (360, 556) X2 shape: (495, 556)\n",
      "Test: X1 shape: (160, 556) X2 shape: (220, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  71.19341611862183 seconds\n",
      "MSE: 89.36370852275913\n",
      "\n",
      "------ STEP 9 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (405, 556) X2 shape: (450, 556)\n",
      "Test: X1 shape: (180, 556) X2 shape: (200, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  56.17234182357788 seconds\n",
      "MSE: 89.41797089745903\n",
      "\n",
      "------ STEP 10 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (450, 556) X2 shape: (405, 556)\n",
      "Test: X1 shape: (200, 556) X2 shape: (180, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  48.10473561286926 seconds\n",
      "MSE: 89.2351980775071\n",
      "\n",
      "------ STEP 11 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (495, 556) X2 shape: (360, 556)\n",
      "Test: X1 shape: (220, 556) X2 shape: (160, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  48.3069953918457 seconds\n",
      "MSE: 88.96705242028767\n",
      "\n",
      "------ STEP 12 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (540, 556) X2 shape: (315, 556)\n",
      "Test: X1 shape: (240, 556) X2 shape: (140, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  53.272119760513306 seconds\n",
      "MSE: 88.2557710684287\n",
      "\n",
      "------ STEP 13 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (585, 556) X2 shape: (270, 556)\n",
      "Test: X1 shape: (260, 556) X2 shape: (120, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  73.68909025192261 seconds\n",
      "MSE: 87.78814886483164\n",
      "\n",
      "------ STEP 14 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (630, 556) X2 shape: (225, 556)\n",
      "Test: X1 shape: (280, 556) X2 shape: (100, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  78.44259691238403 seconds\n",
      "MSE: 88.04352237480562\n",
      "\n",
      "------ STEP 15 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (675, 556) X2 shape: (180, 556)\n",
      "Test: X1 shape: (300, 556) X2 shape: (80, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  97.12826037406921 seconds\n",
      "MSE: 88.52084115690877\n",
      "\n",
      "------ STEP 16 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (720, 556) X2 shape: (135, 556)\n",
      "Test: X1 shape: (320, 556) X2 shape: (60, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  34.0647189617157 seconds\n",
      "MSE: 88.18107205684025\n",
      "\n",
      "------ STEP 17 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (765, 556) X2 shape: (90, 556)\n",
      "Test: X1 shape: (340, 556) X2 shape: (40, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  38.34453010559082 seconds\n",
      "MSE: 88.18327590131813\n",
      "CPU times: user 2.01 s, sys: 2.74 s, total: 4.75 s\n",
      "Wall time: 17min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6ca43db588>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xdclff5//HXxR6CbFS2C2ccoOKM0SaxiYmJ0cZGjdlp2sz2m3SmadOk9demzWxWUxOzzDBmT5vpAsW9xYAiirIUFGSez+8PDsYBcpAD94FzPR8PHsDNfd/nAvF9bj6f63xuMcaglFLKPXhYXYBSSqn2o6GvlFJuRENfKaXciIa+Ukq5EQ19pZRyIxr6SinlRjT0lVLKjTgU+iJyl4hsEZGtInK3fVuYiCwVkSz7+9Amjp1n3ydLROY5s3illFItI829OEtEBgFvACOBauAz4DbgZqDEGDNfRH4DhBpjfn3asWFAJpAKGGAtkGKMOezsb0QppVTzvBzYpz+QboypABCRb4ErgWnARPs+C4FvgF+fduzFwFJjTIn92KXAFGBRUw8WERFhEhMTHf4GlFJKwdq1a4uMMZHN7edI6G8BHhaRcOA4cAn1V+/Rxph8AGNMvohENXJsDLDvpM/z7NtOISK3ALcAxMfHk5mZ6UBZSimlGojIXkf2a3ZM3xizHfh/wFLqh3Y2ArWO1tHYKRt5jOeNManGmNTIyGafqJRSSp0jhyZyjTH/NcYMN8ZMAEqALOCQiHQHsL8vaOTQPCDupM9jgQOtK1kppdS5crR7J8r+Ph6YTv2Y/AdAQzfOPOD9Rg79HLhIRELt3T0X2bcppZSygCNj+gDv2Mf0a4BfGGMOi8h84C0RuRHIBWYCiEgq8DNjzE3GmBIR+Quwxn6eBxsmdZVSSrW/Zls221tqaqrRiVyllGoZEVlrjEltbj99Ra5SSrkRDX2llHIjGvrK5Xy06QA5ReVWl6FUp6Shr1zK0m2HuP319fzlo21Wl6JUp6Shr1xGwdFKfv3OJjw9hG93FVJQVml1SUp1Ohr6yiUYY7j37U2UV9XyzOzh1NkM767fb3VZSnU6GvrKJSxcuYdvdxXy+0v7c9HAbqQkhLJ4bR6u1lKsVEenoa8st+vQUf766Q4uSI5kbloCADNSYskqOMbGvFKLq1Oqc9HQV5aqqq3jzkXrCfL14u8zhiBSv0bfped1x8/bg8Vr9zVzBqVUS2joK0v947Od7Dh4lL/POI/IIN8T24P9vJkysBsfbDhAZU2dhRUq1blo6CvLLM8q4oXlOcxJi2dy/+gzvj4zNY6yylq+2HbIguqU6pw09JUlDpdX86u3N9ArMpDfXzKg0X1G9wwnJsSfxWvz2rk6pTovDX3V7owx/O7dzZSUV/P4rGH4+3g2up+Hh3DV8BiWZRWSX3q8natUqnPS0Fft7u3MPD7dcpBfXZTMoJiuZ933qpRYjIEl67RnXyln0NB3Y4fKKqmutbXrY+4pKudPH24lrWcYN4/v2ez+CeGBjEwK0559pZxEQ98N1dkMT32VxZj5XzH9mRXkFle0y+PW1Nm4+80NeHkI//rJUDw9GruF8plmpMSSU1TOutzDbVyhUp2fhr6bOXDkOD/9TzqPfLGLCX0iyC2uYOqTy1jaDh0yT361mw37jvDX6YPpEeLv8HGXDu5OgI8nb2fqhK5SraWh70Y+2ZzPlMe+Y8v+Uh6ZOYQF143g4zvHkxAeyM0vZ/K3T7dTW9c2wz2Ze0p46qsspg+PYep5PVp0bKCvFz8e1J2PNuVzvFp79pVqDQ19N1BeVct9izfy89fWkRQRyCd3jmdGSiwiQlxYAG//bDSzR8Xz3LfZXPNChtNXtzxaWcPdb24gJtSfP18+8JzOMTM1lmNVtXy2Nd+ptSnlbjT0O7lNeUeY+uRy3l6bx88n9mLxbWNIjAg8ZR8/b08evnIwj149hM15pVzyxHJWfl/ktBoe+GArB44c57GrhxLk531O5xiZGEZcmPbsK9VaGvqdlM1mePbb75n+9Eoqa+p4/aY07pvSD2/Ppv/JrxwWy/u3j6WrvxdzXsjg31/vxmZrXcfMhxsPsGTdfm6f1IeUhLBzPo+HhzBjeBwrvy8m73D7TDwr1Rlp6HdCB0srmfPfDOZ/uoMLB0Tz6V3jGd0r3KFj+0YH8cHt47j0vB784/Od3PRyJkcqqs+pjgNHjvP7dzczNC6EOyf1PqdznGz68Bjt2VeqlTT0O5nPtx5kyuPfsT73CP/vqsE8PXs4IQE+LTpHoK8XT8wayoPTBrIsq5BLn1jOprwjLTpHnc3wy7c2UGszPHb1ULzO8heGo+LCAhjTK5zFa/Na/ReIUu5KQ7+TOF5dx+/e3cytr6wlNtSfj+4cx9Uj4k8sVdxSIsK1oxN5+2djAJjxzCpeSd/r8Auk/rMsm/TsEv50+cAz5hBaY0ZKLLklFazZU+K0cyrlTjT0O4Et+0uZ+uQyXs/I5dYJPVly21h6RXZxyrmHxoXw0R3jGNM7nPvf28Ldb26gvKq22Xr++cVOfjyoGzNTYp1SR4Mpg7rRxdeLt3VCV6lzoqHfgdlshheWZXPl0ys4WlnLqzeO4reX9MfHy7n/rKGBPiyYN4L/u6gvH248wLR/ryDr0NFG9z1eXcddb6wnLNCHv145+Jz/0mhKgI8Xlw7uzieb85t98lFKnUlDv4MqKKtk3oureejj7UxMjuKzuycwrk9Emz2eh4dw+6Q+vHrjKI5UVHP5Uyt4f8OZE6oPf7KN7wvL+efMoYQGtmwuwVEzU2OpqK7jk83as69US2nod0Bfbj/ElMeXsWZPCQ9dMYjn56YQ1kYBe7oxvSP4+M7xDIoJ5q43NvCH9zZTVVt3oq5X03O5eXxSmz4BpSSEkhQRqD37Sp0DDf0OpLSihj+8t5kbF2YSHezHh7ePY05agtOHUJoTHezH6zenceuEnryansvMZ1exPvcw9y3eRP/uwfzfxclt+vgiwoyUWDJyStptsTilOgsN/Q6gutbGguU5nP/I17yWkcuN45J47xdj6BMdZFlN3p4e/PaS/jw3N4WcwnKufHolx6pqeXzWUHy9Gr8pijNdOSwGEVi8Tq/2lWoJL6sLUE0zxvD51kPM/3Q7e4orGNc7gt9d0p8BPYKtLu2Eiwd2o9+dQdz//lamDelB33Z6IuoR4s+43hG8szaPuyf3wcPBZZqVcnca+i5qU94RHvp4O6tzSugd1YUXrxvBxOTIdh/KcURCeCAv3zCy3R93Rkosd72xgfTsYsb0brs5BKU6k84V+p/+Bg5utrqKVqmqrWNfSQUV5dXc5yHEdQ8gKtgXWSWwyurqXMtlxtDD7zChS3zASa9LUMpS3QbDj+e36UN0rtDvwOqMYf+R4yduAN6jqz89Qvzw8tBpl6Z4iBAe6EPRsSpqwwP0Z6WUAzpX6LfxM2RbqK2z8caafTz2v10UHavmiqE9uHdKP2JacGcpd1aae5ifPL2S+YMHM2tkvNXlKOXyOlfodyDGGL7ZWchfP9lOVsExRiaG8d95/RkSF2J1aR3K0LgQekd1YfHaPA19pRygoW+B7fllPPzxdpbvLiIxPIBn5wzn4oHdXHKS1tU19OzP/3QH2YXH6Klj+0qdlUODoCJyj4hsFZEtIrJIRPxEZJKIrLNvWygijT6BiEidiGywv33g3PI7loKySn69eBOXPLGMzftLuX/qAL6453ymDOqugd8K04fF4CHwjvbsK9WsZq/0RSQGuBMYYIw5LiJvAdcAfwYmG2N2iciDwDzgv42c4rgxZqgzi+5oKqpr+c93OTz33ffU1Nm4YWwSd0zq3eJ17lXjooL9OL9vJO+s3c8vL0zGU3v2lWqSo+0OXoC//Wo+ACgHqowxu+xfXwpc1Qb1dXjVtTamPrGcR/+3i/P7RrL0nvO5f+oADXwnm5kax8GySlbsdt69fZXqjJoNfWPMfuARIBfIB0qBtwBvEUm17zYDiGviFH4ikiki6SJyhRNq7lA25h0hu6ic+dMH88ycFKfeUET9YHL/KEICvHWdfaWa0Wzoi0goMA1IAnoAgcBsYBbwqIisBo4CTS1uHm+MSaV+SOgxEenVyGPcYn9iyCwsLDy378RFpX9fDNQvV6Dajq+XJ9OG9ODzrQcpPV5jdTlKuSxHhnd+BOQYYwqNMTXAEmCMMWaVMWa8MWYk8B2Q1djBxpgD9vfZwDfAsEb2ed4Yk2qMSY2MjDzHb8U1ZeSU0K9bUJutLa9+MCMljupaGx9uPGB1KUq5LEdCPxdIE5EAqW8xmQxsF5EoABHxBX4NPHv6gSISav86IhIBjAW2Oat4V1ddayNzbwlpPcOtLsUtDIoJpl+3IF1nX6mzcGRMPwNYDKwDNtuPeR64V0S2A5uAD40xXwGISKqIvGA/vD+QKSIbga+B+cYYtwn9TXlHqKyxkdYzzOpS3EJDz/6GfUfYXdD47RyVcncOde8YYx4wxvQzxgwyxsw1xlQZY+41xvQ3xiQbYx47ad9MY8xN9o9XGmMGG2OG2N831tLZaWXklAAwMkmv9NvLFcNi8PIQ3s7Uq32lGqMrVLWh9OxikqOD2u1WhgoiuvgyMTmKJev3U1tns7ocpVyOhn4bqamzkbnnsA7tWGBmaiyFR6v4Lsu5nWDHq+swxjj1nEq1N117p41syivleE2dTuJa4ILkKMICfVi8No9J/aLP+TyVNXWs23uYZbuLWLG7iM37SxmREMbz16boi+tUh6Wh30bSs+v780cm6ZV+e/Px8uCKoTG8mr6Xw+XVDrfL2myGbfllLLeH/OqcEqpqbXh5CMPiQ5g3OpHXM+pvBL/whpH00OWvVQekod9GMnJK6BvdhfAuvlaX4pZmpMSyYEUOH2w8wLwxiU3ut6+kguW7i1i+u4iVu4s4XFH/wq6+0V24ZlQ843pHMKpnOF186/+rXDywG7e8nMn0p1ey8IaRJHez7ub0Sp0LDf02UD+eX8JVw2OtLsVtDegRzMAewby9dt8poX+4vJpV2cUnrub3FlcAEB3sy6R+0YzrE87YXhFEBfs1et7RvcJ562ejue7F1cx8diX/uTaVUTqEpzoQDf02sGV/KRXVOp5vtRkpsfz5w228tWYfOcXlLM8qYsuBUoyBLr5epPUM4/oxiYzrE0GvyC4OL2/dv3sw79w2hnkLVjN3wWqemDWUKYO6t/F3o5RzaOi3gfTs+v78Udq5Y6lpQ2P46yfbue+dTXh5CMPjQ7l7cl/G9QnnvNgQvD3PvXktNjSAxT8bw40L13Dba+t4cNog5qYlOLF6pdqGhn4bSM8upndUFyJ0PN9SYYE+vHT9SCpr6k4Zl3eW0EAfXrspjTsWreP+97ZwqLSSX13UV2+Io1ya9uk7Wa19PF/7813D2N4RTO4f7fTAb+Dv48mzc1KYNSKOp77eza/f2aQvClMuTa/0nWzLgTLKdTzfrXh5evC36YOJCvbjiS+zKDpWzVPXDCPAR/97KdejV/pOpv357klE+OWFfXn4ykF8s7OAa/6TQUl5tdVlKXUGDX0ny8gupldkIFFBjbf8qc5t9qgEnpmTwvb8MmY8s5J9JRVWl6TUKTT0nai2zsaaPYe1b9vNXTywG6/eNIqiY1VMf2Yl2w6UWV2SUido6DvRtvwyjlXV6ni+YkRiGItvG4OXh3D1c6tYqTdsVy5CQ9+JGsbz03Q8XwF9o4NY8vMx9AjxZ96Lq/U2jsolaOg7UXp2CT0jApt8Cb9yP927+vPWraMZFhfKHYvWs2B5jtUlKTenoe8kdTbDmpwSHc9XZ+ga4M3LN45kysBuPPjRNv726XZsNl2XX1lDQ99Jth0o42hVrb4oSzXKz9uTf88ezty0BJ77Npv/e3sjNfoiLmUBffWIk2Tk2Mfz9UpfNcHTQ3hw2kCig3155Itd1NoMj88aqss2qHaloe8k6dnFJEUEEq3j+eosRITbJ/VBRPjH5zsZkRjK3NGJVpel3IgO7zhBnc2QkVPCKO3aUQ667fxeTOoXxV8+2s6mvCNWl6PciIa+E2zPL+NopfbnK8d5eAj/nDmEyCBffv7aOkrtd+xSqq1p6DtBQ3++rp+vWiI00IenrhnGobJKfvX2RozRjh7V9jT0nSA9u4SE8AC6d9UbZauWGRYfyu8u6c//th/ihWXaw6/anoZ+K9lshjV7SkhL0qEddW6uG5PIJYO7Mf+zHWTuKbG6HNXJaei30vaDZZQeryGtlw7tqHMjIsy/6jziQv25/fX1FB+rsrok1Ylp6LdSRsP9cPVKX7VCsJ83/549nJKKau5+cwN1+opd1UY09FspPbuY+LAAeoToeL5qnYE9uvLg5QNZllXEv7/ebXU5qpPS0G8Fm82wWu+Hq5zo6hFxTB8Ww6P/28UKXY5ZtQEN/VbYeegoRypqdGhHOY2I8NCVg+gd2YW73ljPobJKq0tSnYyGfitof75qCwE+XjwzZzjlVXXcsWg9tbowm3IiDf1WyMguITbUn9jQAKtLUZ1M76gg/jp9EKtzSvjX0l1Wl6M6EQ39c2SzGTJyinXpBdVmrhwWy09HxvP0N9/z1Y5DVpejOgkN/XO0q+AohytqNPRVm3rgsgEM6B7MPW9uJO9whdXlqE5AQ/8c/dCfr+P5qu34eXvyzJzh2GyG219fT3Wtju+r1tHQP0fp2cXEhPgTF6bj+aptJYQH8o+Z57Fh3xH+9ul2q8tRHZyG/jkwpn79fB3aUe1lyqDu3DA2iRdX7OHTzflWl6M6MIdCX0TuEZGtIrJFRBaJiJ+ITBKRdfZtC0Wk0btwicg8Ecmyv81zbvnWyCo4Rkl5tbZqqnb1mx/3Y1h8CPct3sSeonKry1EdVLOhLyIxwJ1AqjFmEOAJXAMsBGbZt+0Fzgh0EQkDHgBGASOBB0Qk1HnlW6OhP3+0XumrduTj5cFT1wzH01P4+WvrqKyps7ok1QE5OrzjBfjbr+YDgHKgyhjT0EC8FLiqkeMuBpYaY0qMMYft+01pZc2Wy8guoUdXP2JDdb0d1b5iQvx59CdD2ZZfxp8/3GZ1OaoDajb0jTH7gUeAXCAfKAXeArxFJNW+2wwgrpHDY4B9J32eZ9/WYRljSM+u788XEavLUW7ogn5R/HxiLxatzuXd9XlWl6M6GEeGd0KBaUAS0AMIBGYDs4BHRWQ1cBSobezwRradsWasiNwiIpkikllYWNiC8tvf7oJjFJdX6ySustQvL+zLqKQwfrdkC1mHjlpdjupAHBne+RGQY4wpNMbUAEuAMcaYVcaY8caYkcB3QFYjx+Zx6l8AscCB03cyxjxvjEk1xqRGRka2/LtoR+k59v58ncRVFvLy9ODJnw4j0NeT215bR3lVY9dcSp3JkdDPBdJEJEDqxzMmA9tFJApARHyBXwPPNnLs58BFIhJq/4vhIvu2Dis9u5juXf2I1/58ZbGoYD+emDWM7MJj/PMLXZ9HOcaRMf0MYDGwDthsP+Z54F4R2Q5sAj40xnwFICKpIvKC/dgS4C/AGvvbg/ZtHZIxhozsEh3PVy5jTO8ILhrQjU+35GOM3m1LNa/R3vrTGWMeoL718mT32t9O3zcTuOmkzxcAC1pRo8v4vrCcomNVuvSCcikX9Ivks60H2XXoGMndgqwuR7k4fUVuCzT05+skrnIl5/eNAuDrnQUWV6I6Ag39FsjIKSE62JeEcB3PV66jW1c/+nUL4hsNfeUADX0HaX++cmUTk6PI3HOYo5U1VpeiXJyGvoNyisopPFqlQzvKJV2QHEmtzbBid7HVpSgXp6HvoHRdP1+5sOEJoQT5eukQj2qWhr6D0rOLiQryJSki0OpSlDqDt6cH4/pE8M3OQm3dVGeloe+A+vXzdTxfubaJyZEcLKtkpy7LoM5CQ98Be4orOFRWpUsvKJc2MdneurnDtdevUtbS0HeA9uerjiA62I/+3YN1XF+dlYa+AzKyi4kM8qWnjucrFzcxOZK1e7V1UzVNQ78Z9f35JYxKCtPxfOXyJvZtaN0ssroU5aI09JuRW1LBwbJKHdpRHcLwhFCC/Lx0XF81SUO/GT+M5+skrnJ93p4ejO8Twbe7tHVTNU5Dvxnp2SVEdPGhV2QXq0tRyiET+0ZxsKySHQe1dVOdSUP/LOrXzy9mlPbnqw7k/OT6u899s1OHeNSZNPTPYl/JcQ6UVpKmSy+oDiQ62I8B3YN1qWXVKA39s0jP0f581TE1tG6WaeumOo2G/lmkZxcTHuhD7ygdz1cdy8TkKOpshhVZ2rqpTqWhfxYZ2SWM6qn9+arjGR4fQpCfl47rqzNo6DdhX0kF+48c16Ed1SF5eXowoU8k3+wq0NZNdQoN/SY09OePStLQVx3T+cmRHCqrYnu+tm6qH2joNyE9u4SwQB/66Hi+6qAm9rW3bu7SLh71Aw39JmTkFDMqKQwPDx3PVx1TlL118xtdkkGdREO/EQuW55B3+Djn26+UlOqoLugXydrcw5Qe19ZNVU9D/zRfbD3IXz7exsUDo/lJapzV5SjVKidaN3XVTWWnoX+SjfuOcOcb6zkvNoTHrh6mQzuqwxsWF0Kwn94wXf1AQ99uX0kFNy7MJKKLLy9cm4q/j6fVJSnVal6eHozvG6k3TFcnaOgDpcdruOGlNVTX1vHS9SOIDPK1uiSlnGZi30gKjlaxLb/M6lKUC3D70K+utXHbq2vZU1zOs3NT6B0VZHVJSjmVrrqpTubWoW+M4Xfvbmbl98XMn34eY3pFWF2SUk4XFeTHwB7BfKuhr3Dz0H/qq90sXpvH3T/qw1UpsVaXo1SbuSA5Sls3FeDGof/e+v38c+kupg+P4a7JfawuR6k2NTE5kjqbYbmuuun23DL007OLuW/xJtJ6hjF/+nm6iqbq9IZq66ayc7vQ/77wGLe+spa4MH+em5OKj5fb/QiUGzrRuqk3THd7bpV4RcequP7FNXh7Ci9dP5KuAd5Wl6RUu7kgOYrCo1VsPaCtm+7MbUK/sqaOm1/OpOBoJS/MG0FcWIDVJSnVrhrWkvp2l3bxuDO3CH2bzXDPmxvYsO8Ij109jKFxIVaXpFS7iwzyZVBMsI7ruzm3CP35n+3g0y0H+f0l/ZkyqJvV5ShlmYl9o1i79zClFdq66a4cCn0RuUdEtorIFhFZJCJ+IjJZRNaJyAYRWS4ivRs5LlFEjtv32SAizzr/Wzi7V9P38vx32Vw7OoEbxyW198Mr5VIu6BeJzcCy3e47xHOwtJKCskqry7BMs6EvIjHAnUCqMWYQ4AnMAp4BZhtjhgKvA39o4hTfG2OG2t9+5qS6HfL1jgL++P4WJvWL4o9TB2hrpnJ7Q+NC6erv7bZLMthshtkvpDPzuVVU1tRZXY4lHB3e8QL8RcQLCAAOAAYItn+9q32by9h6oJTbX19H/+7BPPnTYXh5usVIllJn5ekhjO8Twbe7CrHZ3K91c9nuIr4vLGdvcQX/+S7b6nIs0WwSGmP2A48AuUA+UGqM+QK4CfhERPKAucD8Jk6RJCLrReRbERnf2A4icouIZIpIZmFh669A8kuPc8NLa+jq782C60YQ6OvV6nMq1VlMtLduuuOqmwtX7iGiiy8XDYjm39/sZl9JhdUltTtHhndCgWlAEtADCBSROcA9wCXGmFjgReBfjRyeD8QbY4YBvwReF5Hg03cyxjxvjEk1xqRGRrbuFoVHK2u4/sU1lFfVseD6EUQH+7XqfEp1Ng2tm+7WxbOnqJyvdxYwe1Q8f7p8IILwl4+2WV1Wu3NkzONHQI4xptAYUwMsAcYCQ4wxGfZ93gTGnH6gMabKGFNs/3gt8D3Q1ymVN6KmzsYvXl9PVsExnp49nH7dznh+UcrtRQb5Mjimq9uN67+8ai+eIsweFU+PEH/umNybL7Yd4ms3e/JzJPRzgTQRCZD6mdDJwDagq4g0BPiFwPbTDxSRSBHxtH/cE+gDtMlAmjGGP76/le92FfLwFYOYoDc1V6pJE5MjWZfrPq2b5VW1vJ25j0sGdyfK/tf/TeN60jMykD9/sJWqWveZ1HVkTD8DWAysAzbbj3keuBl4R0Q2Uj+mfy+AiFwuIg/aD58AbLLvsxj4mTGmxOnfBfB9YTnvrMvjtom9mDUyvi0eQqlOY2Jyfevmd1nucbW/ZP1+jlbVMm9M4oltPl4e/Pnygexxs0ldcbXFl1JTU01mZuY5Hbu74Cg9I7roDc2VakadzZDy0FIm94vmnz8ZYnU5bcoYw4WPfkeAjyfv/2LsGa3bt726lq93FvC/X55PbGjHXZ5FRNYaY1Kb269T9TH2jgrSwFfKAfWtm5Fu0bq5YncxuwuOMW90YqOv1fnD1AFuNanbqUJfKeW4iX0jKTrW+VfdfGnlHsIDfZg6pHujX48J8ef2Sb35fOsht+ho0tBXyk1NcIPWzX0lFXy54xA/HRmPr5dnk/vdND6JnhGB/MkNJnU19JVyU5FBvpwX25VvOvFSy6+k78VDhNlpZ2/u8PXy5E/2Sd0XluW0U3XW0NBXyo1N7BvJ+tzDHKmotroUp6uoruWN1blMGdiN7l39m91/Qt9IfjyoG09+lcX+I8fboUJraOgr5cbOT46yt252vhumv7f+AGWVtVw3NtHhY05M6n7YeSd1NfSVcmND40IICfDudOP6xhgWrtzDgO7BpCaEOnxcw6TuZ1sP8l0nHfbS0FfKjXl6CBP6RPJdJ2vdTM8uYeeho1w3pvE2zbO5aXwSSZ14UldDXyk3NzE5kqJj1Z2qdXPhyj2EBnhz+dAeLT62YVI3u6i8U07qaugr5eYaWjc7y8Jj+48c54ttB7l6RDx+3k23aZ7N+X0jmTKwG099tbvTTepq6Cvl5iK62Fs3O0nov7JqLwBzRye06jz3XzYAg+GhTvZKXQ19pRQTk6PYsO9Ih2/drKyp4401uVw0oBsxIc23aZ5NTIg/d0zqw6dbDrKsEy1Mp6GvlDpp1c2O3br5wYYDHKmoOWU1zdZomNR94P3OM6mroa+UYkhsCKEB3nyzo+MO8RhjeGnlHpKjg0jrGeaUc/p6efLAZQPILirnv8s7x6Suhr5Sqr51s2/HXnUzc+9htuWXMe8c2jTPZmJyFBcPjObJL3dzoBNM6mroK6WA+iGyt/wRAAANNElEQVSe4vJqthwotbqUc/LSyj109ffmimEtb9Nszv1T7ZO6H3f8SV0NfaUUABP6RCICX+/oeJOW+aXH+WzLQa4eEUeAj5fTzx8bGsDtF/Tmk80HWd7B5z009JVSAIR38SUlPpT3NuzvcEM8r6XnYjOGuWmta9M8m5sn9CQxPIA/frCF6lpbmz1OW9PQV0qdMHd0AjlF5XzbgdadqaypY9HqXCb3iyYurO1ud+jr5ckDlw8ku7BjT+pq6CulTrhkcHeig31ZsKLjhNrHm/IpLq/mOie1aZ7NBclRXDQgmie/yiK/tGNO6mroK6VO8Pb04NrRiSzLKmLXoaNWl9OshjbN3lFdGNs7vF0e8/6pA6izGR76eHu7PJ6zaegrpU5Rf2tBD15cscfqUpq1LvcIm/eXOr1N82ziwuondT/elN8hJ3U19JVSpwgL9OHKYTG8uz6Pw+WuvSzDwpV7CPLzYvqwmHZ93Jsn9CQhPIAHOuCkrvN7m5RSHd51YxN5Y80+Fq3J5ecTe1tdTqMKyir5ZHM+145OJNC3faPMz7t++eXrX1zDL15fR0yIPzZjsBlDnQ1sNkOdMdhs9m3Gvs2+3ZiGj3/YbjOG3lFdePjKwW1au4a+UuoM/boFM7Z3OK+s2svN43vi7el6gwKvZeRSZwzXtnI1zXN1QXIUs0fF8976/Xh4CJ4egqcIHh6Ch3DiY08PwUPs2+wfn9jmIXietL09Rqg09JVSjbp+TBI3vZzJZ1sOctkQ57/KtTWqa228lpHLxL6RJEYEWlbHw1cObvMrc2dzvadvpZRLmNQvioTwAF50wfbNTzbnU3SsiuvGJlldSoejoa+UapSHh3DdmETW5R5hw74jVpdzipdW7qFnRCDje0dYXUqHo6GvlGrSzNQ4gny9XOpqf+O++ieha0cn4OHRPm2anYmGvlKqSV18vZiZGsfHm/I5WFppdTlAfZtmoI8nV6XEWl1Kh6Shr5Q6q+vGJFJnDK+m77W6FAqPVvHRpnxmpMQS5OdtdTkdkoa+Uuqs4sMD+FH/aF7L2EtljbW3DFy0OpfqOhvXtsM6O52Vhr5Sqlk3jE3icEUN72/Yb1kNNXU2XsvYy4S+kfSK7GJZHR2dhr5SqllpPcPo1y2IBcv3YIw1a+1/tuUgh8qquG6MNS/G6iw09JVSzRIRbhiXxM5DR1n1fbElNSxcuYeE8AAm9o2y5PE7Cw19pZRDLh/Sg/BAHxZYsPrmlv2lZO49zNw0bdNsLQ19pZRD/Lw9uWZUPF/uOMTe4vJ2fewXlmUT4OPJzNS4dn3czsih0BeRe0Rkq4hsEZFFIuInIpNFZJ2IbBCR5SLS6FJ8IvJbEdktIjtF5GLnlq+Uak9z0hLw8hBeWrmn3R7zvfX7eW/DAa4dnUhXf23TbK1mQ19EYoA7gVRjzCDAE5gFPAPMNsYMBV4H/tDIsQPs+w4EpgBPi4in88pXSrWn6GA/Lh3cnbcz8zhaWdPmj7dlfym/WbKJkUlh/Oqivm3+eO7A0eEdL8BfRLyAAOAAYIBg+9e72redbhrwhjGmyhiTA+wGRrauZKWUlW4Yl8Sxqlrezsxr08cpKa/m1lfWEhrgw7+vGe6Syzt3RM3+FI0x+4FHgFwgHyg1xnwB3AR8IiJ5wFxgfiOHxwD7Tvo8z75NKdVBnRcbQkpCKC+t3EOdrW3aN2vrbNyxaB2Fx6p4dk4KkUG+bfI47siR4Z1Q6q/Yk4AeQKCIzAHuAS4xxsQCLwL/auzwRrad8VsiIreISKaIZBYWFrakfqWUBW4Ym0RuSQVf7Shok/P//fOdrNhdzENXDGJIXEibPIa7cuTvpR8BOcaYQmNMDbAEGAsMMcZk2Pd5ExjTyLF5wMnT7bE0MgxkjHneGJNqjEmNjIxs0TeglGp/Fw+MpkdXPxYsd/7qmx9sPMDz32UzNy2Bn2i3jtM5Evq5QJqIBEj97eYnA9uAriLSMLNyIbC9kWM/AGaJiK+IJAF9gNVOqFspZSEvTw+uHZPIquxitueXOe282w6Ucd/ijaQmhHL/1AFOO6/6gSNj+hnAYmAdsNl+zPPAzcA7IrKR+jH9ewFE5HIRedB+7FbgLeqfJD4DfmGMsXbFJqWUU8waEYeft4fT1to/UlHNra9m0tXfm6fnDMfHSydu24JYtY5GU1JTU01mZqbVZSilHPD7dzfz9to8Vv1mEuFdzn2ytc5muO7F1WRkl/DGrWkMjw91YpXuQUTWGmNSm9tPn0qVUufs+rGJVNfaeD0jt1XneeSLnSzLKuLBaQM18NuYhr5S6pz1jgpiQt9IXknfS3Wt7ZzO8fGmfJ755nuuGRXPrJHxTq5QnU5DXynVKtePTaTgaBWfbM5v8bE7Dx7l3sUbGR4fwgOX6cRte9DQV0q1yvl9IukZEciCFTktWmu/tKKGW17JJNDXi2fmpODrpSu0tAcNfaVUq3h4CNePTWRTXinrcg87dEydzXDXm+s5cOQ4z8weTnSwXxtXqRpo6CulWm368FiC/LwcXmv/sf/t4pudhTxw2UBSE8Patjh1Cg19pVSrBfp68dOR8Xy25SAHjhw/676fbcnnya92c3VqHLNH6cRte9PQV0o5xbWjEzDG8PKqvU3uk3XoKL96ayND4kL487SB1L/IX7UnDX2llFPEhgZw8cBuLFqdy/HqM194X1ZZwy2vrMXfx4vn5qTg560Tt1bQ0FdKOc31Y5MoPV7DkvWnrrVvsxnueWMD+0oqeHr2cLp11Ylbq2joK6WcZkRiKINignlxxZ5T2jcf/zKLL3cU8MfLBjAySSduraShr5RyGhHh+jFJ7C44xrKsIgCWbjvE419mMSMllrlpCRZXqDT0lVJONXVIdyK6+PLiihx2Fxzjnjc3cF5sVx66YpBO3LoAL6sLUEp1Lr5ensxJi+ex/2WRVbAaXy8PntWJW5ehV/pKKaebPSoBH08P8ksreeqa4fQI8be6JGWnV/pKKaeLDPLlb9MHE+jrxehe4VaXo06ioa+UahNXpcRaXYJqhA7vKKWUG9HQV0opN6Khr5RSbkRDXyml3IiGvlJKuRENfaWUciMa+kop5UY09JVSyo1IS+5e3x5EpBBo+tY77SsCKLK6iEZoXS2jdbWM1tUyrlJXgjEmsrmdXC70XYmIZBpjUq2u43RaV8toXS2jdbWMq9bVFB3eUUopN6Khr5RSbkRD/+yet7qAJmhdLaN1tYzW1TKuWlejdExfKaXciF7pK6WUG9HQP42IxInI1yKyXUS2ishdVtd0MhHxFJH1IvKR1bU0EJEQEVksIjvsP7fRVtcEICL32P8Nt4jIIhHxs7CWBSJSICJbTtoWJiJLRSTL/j7URer6h/3fcpOIvCsiIa5Q10lf+z8RMSIS4Sp1icgdIrLT/vv29/auqyU09M9UC/zKGNMfSAN+ISIDLK7pZHcB260u4jSPA58ZY/oBQ3CB+kQkBrgTSDXGDAI8gVkWlvQSMOW0bb8BvjTG9AG+tH/e3l7izLqWAoOMMecBu4DftndRNF4XIhIHXAjktndBdi9xWl0icgEwDTjPGDMQeMSCuhymoX8aY0y+MWad/eOj1AdYjLVV1RORWOBS4AWra2kgIsHABOC/AMaYamPMEWurOsEL8BcRLyAAOGBVIcaY74CS0zZPAxbaP14IXNGuRdF4XcaYL4wxtfZP04F2vwVWEz8vgEeB+wBLJiObqOs2YL4xpsq+T0G7F9YCGvpnISKJwDAgw9pKTniM+l94m9WFnKQnUAi8aB92ekFEAq0uyhizn/orrlwgHyg1xnxhbVVniDbG5EP9xQYQZXE9jbkB+NTqIgBE5HJgvzFmo9W1nKYvMF5EMkTkWxEZYXVBZ6Oh3wQR6QK8A9xtjClzgXqmAgXGmLVW13IaL2A48IwxZhhQjjXDFKewj49PA5KAHkCgiMyxtqqORUR+T/1w52suUEsA8Hvgj1bX0ggvIJT64eB7gbdERKwtqWka+o0QEW/qA/81Y8wSq+uxGwtcLiJ7gDeASSLyqrUlAZAH5BljGv4aWkz9k4DVfgTkGGMKjTE1wBJgjMU1ne6QiHQHsL93mWEBEZkHTAVmG9fo6+5F/RP4Rvv/gVhgnYh0s7SqennAElNvNfV/ibf7JLOjNPRPY3+G/i+w3RjzL6vraWCM+a0xJtYYk0j9hORXxhjLr1yNMQeBfSKSbN80GdhmYUkNcoE0EQmw/5tOxgUmmE/zATDP/vE84H0LazlBRKYAvwYuN8ZUWF0PgDFmszEmyhiTaP8/kAcMt//+We09YBKAiPQFfHCNBdgapaF/prHAXOqvpDfY3y6xuigXdwfwmohsAoYCf7W4Hux/eSwG1gGbqf9dt+yVkyKyCFgFJItInojcCMwHLhSRLOo7Uua7SF1PAUHAUvvv/7MuUpflmqhrAdDT3sb5BjDPRf46apS+IlcppdyIXukrpZQb0dBXSik3oqGvlFJuRENfKaXciIa+Ukq5EQ19pZRyIxr6SinlRjT0lVLKjfx/8Xxm7Sk2dZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6be926bdd8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,18), W.Ts)\n",
    "plt.plot(range(1,18), [89.59]*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker v0.2\n",
      "Z3 Created!\n",
      "n = 65\n",
      "Z Centré !\n"
     ]
    }
   ],
   "source": [
    "W2 = worker.T_optim(speedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "------ STEP 1 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (45, 556) X2 shape: (810, 556)\n",
      "Test: X1 shape: (20, 556) X2 shape: (360, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  388.6070713996887 seconds\n",
      "MSE: 100.32089699966409\n",
      "\n",
      "--------------------\n",
      "------ STEP 2 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (90, 556) X2 shape: (765, 556)\n",
      "Test: X1 shape: (40, 556) X2 shape: (340, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  428.9380078315735 seconds\n",
      "MSE: 100.82066943669241\n",
      "\n",
      "--------------------\n",
      "------ STEP 3 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (135, 556) X2 shape: (720, 556)\n",
      "Test: X1 shape: (60, 556) X2 shape: (320, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  471.4565269947052 seconds\n",
      "MSE: 101.05199147381843\n",
      "\n",
      "--------------------\n",
      "------ STEP 4 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (180, 556) X2 shape: (675, 556)\n",
      "Test: X1 shape: (80, 556) X2 shape: (300, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  641.0438439846039 seconds\n",
      "MSE: 101.25406812604716\n",
      "\n",
      "--------------------\n",
      "------ STEP 5 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (225, 556) X2 shape: (630, 556)\n",
      "Test: X1 shape: (100, 556) X2 shape: (280, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  579.2586665153503 seconds\n",
      "MSE: 101.23306444428914\n",
      "\n",
      "--------------------\n",
      "------ STEP 6 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (270, 556) X2 shape: (585, 556)\n",
      "Test: X1 shape: (120, 556) X2 shape: (260, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  455.8152551651001 seconds\n",
      "MSE: 101.15883647782329\n",
      "\n",
      "--------------------\n",
      "------ STEP 7 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (315, 556) X2 shape: (540, 556)\n",
      "Test: X1 shape: (140, 556) X2 shape: (240, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  372.35116267204285 seconds\n",
      "MSE: 101.20461658848455\n",
      "\n",
      "--------------------\n",
      "------ STEP 8 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (360, 556) X2 shape: (495, 556)\n",
      "Test: X1 shape: (160, 556) X2 shape: (220, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  290.0502245426178 seconds\n",
      "MSE: 101.09104760194461\n",
      "\n",
      "--------------------\n",
      "------ STEP 9 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (405, 556) X2 shape: (450, 556)\n",
      "Test: X1 shape: (180, 556) X2 shape: (200, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  244.89900159835815 seconds\n",
      "MSE: 100.90205675387031\n",
      "\n",
      "--------------------\n",
      "------ STEP 10 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (450, 556) X2 shape: (405, 556)\n",
      "Test: X1 shape: (200, 556) X2 shape: (180, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  216.86948204040527 seconds\n",
      "MSE: 100.81888286342877\n",
      "\n",
      "--------------------\n",
      "------ STEP 11 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (495, 556) X2 shape: (360, 556)\n",
      "Test: X1 shape: (220, 556) X2 shape: (160, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  227.0064446926117 seconds\n",
      "MSE: 100.80448068158483\n",
      "\n",
      "--------------------\n",
      "------ STEP 12 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (540, 556) X2 shape: (315, 556)\n",
      "Test: X1 shape: (240, 556) X2 shape: (140, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  263.143541097641 seconds\n",
      "MSE: 100.93378478738838\n",
      "\n",
      "--------------------\n",
      "------ STEP 13 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (585, 556) X2 shape: (270, 556)\n",
      "Test: X1 shape: (260, 556) X2 shape: (120, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  335.03546237945557 seconds\n",
      "MSE: 100.74984946419683\n",
      "\n",
      "--------------------\n",
      "------ STEP 14 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (630, 556) X2 shape: (225, 556)\n",
      "Test: X1 shape: (280, 556) X2 shape: (100, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  444.068710565567 seconds\n",
      "MSE: 100.73184378317795\n",
      "\n",
      "--------------------\n",
      "------ STEP 15 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (675, 556) X2 shape: (180, 556)\n",
      "Test: X1 shape: (300, 556) X2 shape: (80, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  532.4327018260956 seconds\n",
      "MSE: 100.9070990670666\n",
      "\n",
      "--------------------\n",
      "------ STEP 16 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (720, 556) X2 shape: (135, 556)\n",
      "Test: X1 shape: (320, 556) X2 shape: (60, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  414.14392828941345 seconds\n",
      "MSE: 100.79962888595428\n",
      "\n",
      "--------------------\n",
      "------ STEP 17 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (765, 556) X2 shape: (90, 556)\n",
      "Test: X1 shape: (340, 556) X2 shape: (40, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  399.4573087692261 seconds\n",
      "MSE: 100.59669428862325\n",
      "CPU times: user 1min 25s, sys: 3min 52s, total: 5min 17s\n",
      "Wall time: 1h 51min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.32089699966409,\n",
       " 100.82066943669241,\n",
       " 101.05199147381843,\n",
       " 101.25406812604716,\n",
       " 101.23306444428914,\n",
       " 101.15883647782329,\n",
       " 101.20461658848455,\n",
       " 101.09104760194461,\n",
       " 100.90205675387031,\n",
       " 100.81888286342877,\n",
       " 100.80448068158483,\n",
       " 100.93378478738838,\n",
       " 100.74984946419683,\n",
       " 100.73184378317795,\n",
       " 100.9070990670666,\n",
       " 100.79962888595428,\n",
       " 100.59669428862325]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f759c864550>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f759ca01d68>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(W2.Ts)\n",
    "plt.plot(range(1,18), [99.58]*17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-12-03 05:00:00', '2018-12-03 05:15:00',\n",
       "               '2018-12-03 05:30:00', '2018-12-03 05:45:00',\n",
       "               '2018-12-03 06:00:00', '2018-12-03 06:15:00',\n",
       "               '2018-12-03 06:30:00', '2018-12-03 06:45:00',\n",
       "               '2018-12-03 07:00:00', '2018-12-03 07:15:00',\n",
       "               ...\n",
       "               '2019-03-13 16:30:00', '2019-03-13 16:45:00',\n",
       "               '2019-03-13 17:00:00', '2019-03-13 17:15:00',\n",
       "               '2019-03-13 17:30:00', '2019-03-13 17:45:00',\n",
       "               '2019-03-13 18:00:00', '2019-03-13 18:15:00',\n",
       "               '2019-03-13 18:30:00', '2019-03-13 18:45:00'],\n",
       "              dtype='datetime64[ns]', name='time', length=3416, freq=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3416/56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_full_day = [98.31380401, 98.04428575, 98.46852718, 98.90482791, 98.90185752, 98.90097691, 98.90550257, 98.87668661, 98.90091228, 98.97369572, 98.95700435, 98.80853677, 98.77431778, 98.70931348]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7220b556a0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7220bf19b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53], T_full_day)\n",
    "plt.plot(range(1,55), [98.4397163818663]*54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_day = [98.27780502, 98.18063096, 98.07973628, 98.00645776, 97.99512048, 98.10686783, 98.17337253, 98.32593225, 98.41427167, 98.45310563, 98.47314408, 98.68532916, 98.84161414, 98.8417469,  98.83832682, 98.84556246, 98.81420862, 98.8365484, 98.91583903, 98.89547896, 98.75771296, 98.71828197, 98.70702846, 98.66267219, 98.57173955]\n",
    "times = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 52, 53, 54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72203a9f60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(times, T_day, label=\"Modèle avec coupure\")\n",
    "plt.plot(range(1,55), [98.4397163818663]*54, label=\"Modèle général\")\n",
    "plt.title(\"Score en fonction de la coupure\")\n",
    "plt.xlabel(\"Quart d'heure de coupure\")\n",
    "plt.ylabel(\"MSE score\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('cut_full_day.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
