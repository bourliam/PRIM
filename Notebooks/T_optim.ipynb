{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the right T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal : find T such as [A1,...,A1,A2,...,A2] is the optimal split.\n",
    "                                T\n",
    "                                \n",
    "Definition: risque: $R(A)=\\frac{1}{n}\\sum_{i}^{n}\\sum_{t}^{T} || Y_{i,t}-A_{t}X_{i,t}||²$\n",
    "\n",
    "Trois modèles:\n",
    "- Général : A = (A,A,...,A)\n",
    "- Spécifique : A = (A1,A1,...,A5,A5)\n",
    "- Selectif: A = (A1,...,A1,A2,...,A2) avec split en T^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\" \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt        \n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "sys.path.append('../scripts/')\n",
    "from models import BaseModels, DataCleaner, ModelPlots, DataModel\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeResults=pd.read_pickle(\"../data/mergeResults.pckl\")\n",
    "segmentsMeta=pd.read_pickle(\"../data/segmentsMeta.pckl\")\n",
    "speeds = pd.read_pickle(\"../data/monthsSpeed__0.pckl\")\n",
    "counts = pd.read_pickle('../data/monthsCount__0.pckl')\n",
    "data_cleaner = DataCleaner(speeds, segmentsMeta, mergeResults, counts)\n",
    "speedDF = data_cleaner.data\n",
    "\n",
    "nSegments = len(speedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de rique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risque(A, X, Y):\n",
    "    n = 45\n",
    "    T = 19\n",
    "    r = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for t in range(T):\n",
    "            r += np.mean((Y[i*t] - np.dot(A[t], X[i*t]))**2)\n",
    "    r = r/(n*T)\n",
    "    \n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des risques en fonction de T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Général"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Created!\n",
      "n = 65\n",
      "Z Centré !\n",
      "(855, 556) (855, 556)\n",
      "(380, 556) (380, 556)\n"
     ]
    }
   ],
   "source": [
    "Z = []\n",
    "\n",
    "for i in range(int((speedDF.shape[1])/20)):\n",
    "    Z.append(speedDF.iloc[:,i*20:(i+1)*20].values)\n",
    "\n",
    "print(\"Z Created!\")\n",
    "n = len(Z)\n",
    "print(\"n =\", n)\n",
    "\n",
    "Z = np.array(Z)\n",
    "\n",
    "Z_train = Z[:45]\n",
    "Z_test = Z[45:]\n",
    "\n",
    "M = (1/45)*Z_train.sum(axis=0)\n",
    "\n",
    "for i in range(45):\n",
    "    Z_train[i] = Z_train[i] - M\n",
    "for i in range(65-45):\n",
    "    Z_test[i] = Z_test[i] - M\n",
    "    \n",
    "print(\"Z Centré !\")\n",
    "\n",
    "\n",
    "def X_Y(Z):\n",
    "    new_X = Z[:,:,:-1]\n",
    "    new_Y = Z[:,:,1:]\n",
    "    new_X = np.concatenate(new_X, axis=1)\n",
    "    new_Y = np.concatenate(new_Y, axis=1)\n",
    "    return new_X.T, new_Y.T\n",
    "\n",
    "new_X_train, new_Y_train  = X_Y(Z_train)\n",
    "print(new_X_train.shape, new_Y_train.shape)\n",
    "new_X_test, new_Y_test = X_Y(Z_test)\n",
    "print(new_X_test.shape, new_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lasso_parra = [linear_model.LassoCV(n_jobs=4, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lasso(i):\n",
    "    A_lasso_parra[i].fit(new_X_train, new_Y_train[:, i])\n",
    "    print(i,\"alpha:\",A_lasso_parra[i].alpha_,\"\\nalphas\", len(A_lasso_parra[i].alphas_), \"\\nnb iter:\", A_lasso_parra[i].n_iter_)\n",
    "    return A_lasso_parra[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 alpha: 5.492640533537323 \n",
      "alphas 100 \n",
      "nb iter: 70\n",
      "120 alpha: 7.342444934958369 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "36 alpha: 15.15035268851419 \n",
      "alphas 100 \n",
      "nb iter: 64\n",
      "108 alpha: 7.7090578412284625 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "72 alpha: 2.737651881657627 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "24 alpha: 8.521574229500153 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "84 alpha: 8.545676359583654 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "132 alpha: 8.458312464588507 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "37 alpha: 2.746168687491727 \n",
      "alphas 100 \n",
      "nb iter: 56\n",
      "61 alpha: 2.8656663789331382 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "73 alpha: 2.0497975934421153 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "12 alpha: 7.466387050317008 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "96 alpha: 6.771781306939158 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "48 alpha: 4.124023339233715 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "121 alpha: 12.11469567236471 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "0 alpha: 19.442736717517935 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "49 alpha: 8.851589363177052 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "38 alpha: 7.13887308085358 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "62 alpha: 11.77095707815801 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "50 alpha: 23.077468322951997 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "74 alpha: 3.6273526782039873 \n",
      "alphas 100 \n",
      "nb iter: 69\n",
      "85 alpha: 11.594508791757367 \n",
      "alphas 100 \n",
      "nb iter: 52\n",
      "109 alpha: 18.747266854658893 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "25 alpha: 9.473238886680997 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "133 alpha: 24.803075243431145 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "51 alpha: 13.414592793532226 \n",
      "alphas 100 \n",
      "nb iter: 56\n",
      "86 alpha: 14.173232739120785 \n",
      "alphas 100 \n",
      "nb iter: 62\n",
      "122 alpha: 10.08845795058123 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "39 alpha: 5.135011229618442 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "97 alpha: 9.49793728820485 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "123 alpha: 14.825384181736553 \n",
      "alphas 100 \n",
      "nb iter: 74\n",
      "13 alpha: 20.114268792365365 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "52 alpha: 7.990519872941052 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "75 alpha: 11.353492571684411 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "26 alpha: 3.6548752702109755 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "110 alpha: 9.321991697177495 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "63 alpha: 5.911903347874118 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "134 alpha: 17.648224178837076 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "14 alpha: 8.55388553981069 \n",
      "alphas 100 \n",
      "nb iter: 74\n",
      "98 alpha: 14.516395464515252 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "1 alpha: 19.271843854788866 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "27 alpha: 2.6187562487559672 \n",
      "alphas 100 \n",
      "nb iter: 80\n",
      "15 alpha: 13.933695228361024 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "53 alpha: 10.035337865956553 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "40 alpha: 8.830930935035871 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "16 alpha: 5.470705894285358 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "87 alpha: 13.646476978628634 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "135 alpha: 2.7498234333057887 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "64 alpha: 10.016822292113506 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "124 alpha: 13.314034598754374 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "76 alpha: 49.42287859521947 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "99 alpha: 4.290065473856172 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "136 alpha: 9.39364571645087 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "111 alpha: 9.942214813780904 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "2 alpha: 7.383170672374222 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "137 alpha: 10.122749536200372 \n",
      "alphas 100 \n",
      "nb iter: 135\n",
      "28 alpha: 14.274617674669017 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "3 alpha: 15.546240930870713 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "54 alpha: 1.779238412596217 \n",
      "alphas 100 \n",
      "nb iter: 78\n",
      "17 alpha: 9.046684998983753 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "88 alpha: 9.728451357740672 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "65 alpha: 5.188243891881098 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "125 alpha: 4.738516684992457 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "41 alpha: 13.028793605616672 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "112 alpha: 3.5582631490394383 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "100 alpha: 7.480542221502036 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "77 alpha: 27.609656113102535 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "18 alpha: 8.152941481835109 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "138 alpha: 22.20966601166992 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "55 alpha: 3.697243618428756 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "126 alpha: 5.673778719949118 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "29 alpha: 2.1677096607183763 \n",
      "alphas 100 \n",
      "nb iter: 93\n",
      "4 alpha: 2.9051138910610512 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "19 alpha: 11.97392184364784 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "66 alpha: 6.969676874107781 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "67 alpha: 16.342185797123385 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "30 alpha: 11.734865730238328 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "101 alpha: 10.679190624863761 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "42 alpha: 8.51460471609849 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "127 alpha: 12.68621117192148 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "56 alpha: 5.130198962928958 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "139 alpha: 12.851704439361177 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "78 alpha: 15.746745450031714 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "5 alpha: 1.4594050543053672 \n",
      "alphas 100 \n",
      "nb iter: 155\n",
      "68 alpha: 5.241036136529558 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "113 alpha: 8.460549109403283 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "20 alpha: 3.464414928211515 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "57 alpha: 2.9926759641057292 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "79 alpha: 12.448161686098397 \n",
      "alphas 100 \n",
      "nb iter: 61\n",
      "114 alpha: 5.8768536519017545 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "128 alpha: 8.605005548791343 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "102 alpha: 8.662452002025352 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "89 alpha: 18.261701487327993 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "31 alpha: 11.360576510353999 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "43 alpha: 6.959628566260045 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "69 alpha: 3.8716702844172017 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "140 alpha: 17.43146050365029 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "70 alpha: 8.897520700793423 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "6 alpha: 11.062610816844307 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "58 alpha: 2.5159420949982803 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "80 alpha: 6.788119489185043 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "32 alpha: 15.58042585197876 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "129 alpha: 5.28289572968734 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "21 alpha: 4.917667413119083 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "71 alpha: 3.5640175391143587 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "115 alpha: 32.77398088076099 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "81 alpha: 5.802108122982963 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "103 alpha: 7.959225782246563 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "82 alpha: 13.261271935061876 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "59 alpha: 6.152779268969222 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "44 alpha: 11.51373929286533 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "90 alpha: 29.21887271232481 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "104 alpha: 8.957307658751496 \n",
      "alphas 100 \n",
      "nb iter: 68\n",
      "144 alpha: 5.721649828272977 \n",
      "alphas 100 \n",
      "nb iter: 53\n",
      "141 alpha: 14.760117095834962 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "105 alpha: 6.476171834119363 \n",
      "alphas 100 \n",
      "nb iter: 74\n",
      "145 alpha: 11.804233226293425 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "33 alpha: 16.64485968659289 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "116 alpha: 16.316813244315785 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "130 alpha: 5.977039491589222 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "7 alpha: 14.831639816820253 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "22 alpha: 3.981976162446291 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "34 alpha: 15.529201792161935 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "23 alpha: 3.6079540480577905 \n",
      "alphas 100 \n",
      "nb iter: 93\n",
      "83 alpha: 7.084372823199539 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "156 alpha: 4.068397005391943 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "35 alpha: 13.71626207365999 \n",
      "alphas 100 \n",
      "nb iter: 73\n",
      "146 alpha: 4.128118120132287 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "45 alpha: 5.054245082185148 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "106 alpha: 8.067231673688738 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "131 alpha: 8.985950442887392 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "142 alpha: 6.725269710932901 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "91 alpha: 7.144894916201935 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "117 alpha: 17.992368057039393 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "204 alpha: 12.170745223972204 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "8 alpha: 12.01760807479928 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "147 alpha: 5.182482125827445 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "143 alpha: 4.312368498493799 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "205 alpha: 14.270161106816397 \n",
      "alphas 100 \n",
      "nb iter: 54\n",
      "46 alpha: 3.9372672185088438 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "148 alpha: 9.574257559718736 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "192 alpha: 14.822498611570525 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "180 alpha: 18.219901669597952 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "107 alpha: 14.90739082976379 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "157 alpha: 2.896097071918141 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "206 alpha: 16.99786537923713 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "118 alpha: 9.66668044802801 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "193 alpha: 7.350289894461984 \n",
      "alphas 100 \n",
      "nb iter: 60\n",
      "181 alpha: 9.343444795164071 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "168 alpha: 8.796495564770614 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "216 alpha: 6.606164424239032 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "92 alpha: 16.416305275746556 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "9 alpha: 10.068723194346985 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "158 alpha: 22.529582706796276 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "47 alpha: 3.901809344993889 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "169 alpha: 8.03712053157621 \n",
      "alphas 100 \n",
      "nb iter: 71\n",
      "93 alpha: 12.566408710525085 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "149 alpha: 7.4730827190397875 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "228 alpha: 10.25214844342913 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "170 alpha: 22.455232259686472 \n",
      "alphas 100 \n",
      "nb iter: 48\n",
      "207 alpha: 15.032384332907812 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "119 alpha: 6.830030731633386 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "10 alpha: 3.0481884065419425 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "159 alpha: 4.3572409024834675 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "194 alpha: 7.3222887223596285 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "182 alpha: 9.28005984885173 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "217 alpha: 7.9764551547651985 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "240 alpha: 5.543369780472592 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "160 alpha: 9.02151613255463 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "208 alpha: 1.3583533285726954 \n",
      "alphas 100 \n",
      "nb iter: 124\n",
      "150 alpha: 12.983302495195352 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "229 alpha: 19.84385860214535 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "94 alpha: 5.327825375184585 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "252 alpha: 13.111417808484665 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "11 alpha: 3.355434276639946 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "183 alpha: 16.70171061960275 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "171 alpha: 5.738673282542467 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "195 alpha: 5.849191511934824 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "241 alpha: 13.75523713625344 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "209 alpha: 3.6603557829314273 \n",
      "alphas 100 \n",
      "nb iter: 63\n",
      "264 alpha: 3.738515660116266 \n",
      "alphas 100 \n",
      "nb iter: 68\n",
      "242 alpha: 8.401012120226886 \n",
      "alphas 100 \n",
      "nb iter: 48\n",
      "218 alpha: 15.408113315925382 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "161 alpha: 6.457309112683645 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "230 alpha: 8.970839369536185 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "151 alpha: 8.722461956257566 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "184 alpha: 12.65623035748543 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "265 alpha: 4.122264855922235 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "253 alpha: 10.458925694618038 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "95 alpha: 3.014525838537863 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "210 alpha: 12.242799851923479 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "162 alpha: 5.425736214547942 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "243 alpha: 11.070188805407474 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "196 alpha: 10.057193763423426 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "172 alpha: 6.73593591757705 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "276 alpha: 3.445830803515794 \n",
      "alphas 100 \n",
      "nb iter: 48\n",
      "185 alpha: 6.771550528530847 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "231 alpha: 5.73915369909404 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "244 alpha: 9.997610015771878 \n",
      "alphas 100 \n",
      "nb iter: 76\n",
      "254 alpha: 2.3771580893645874 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "219 alpha: 3.7204383446235894 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "245 alpha: 13.771134310372148 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "211 alpha: 14.922601204358942 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "163 alpha: 7.999247049172044 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "197 alpha: 7.958925732854873 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "152 alpha: 9.294103591654556 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "277 alpha: 2.7751970298602386 \n",
      "alphas 100 \n",
      "nb iter: 74\n",
      "266 alpha: 27.1267883004185 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "232 alpha: 6.345360342456718 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "220 alpha: 11.552791518385632 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "186 alpha: 13.124933553586112 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "164 alpha: 16.981559295675073 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "233 alpha: 3.074197091354179 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "267 alpha: 2.574988759565555 \n",
      "alphas 100 \n",
      "nb iter: 111\n",
      "153 alpha: 7.0958342385621105 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "255 alpha: 40.494873096926696 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "246 alpha: 8.843282415310837 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "278 alpha: 5.788474397168904 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "173 alpha: 13.79282033838841 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "212 alpha: 7.919758886821993 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "268 alpha: 2.0791019227115126 \n",
      "alphas 100 \n",
      "nb iter: 68\n",
      "234 alpha: 11.373202233611494 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "198 alpha: 11.781996464384422 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "154 alpha: 7.175317478958286 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "247 alpha: 10.118749127883751 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "256 alpha: 11.151375397172238 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "165 alpha: 9.080601911106134 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "187 alpha: 18.878283751378607 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "221 alpha: 16.89815700038032 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "269 alpha: 13.25932852628241 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "155 alpha: 4.902637746391471 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "257 alpha: 7.000449031311203 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "258 alpha: 16.992749763853972 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "199 alpha: 5.8299194829185135 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "213 alpha: 8.21003500447086 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "248 alpha: 10.885144490931918 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "235 alpha: 7.164777984365053 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "174 alpha: 8.961241266222565 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "279 alpha: 10.594539454071786 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "249 alpha: 11.864498129698603 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "250 alpha: 27.85948700560521 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "270 alpha: 6.451295208237566 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "222 alpha: 23.255382684889657 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "288 alpha: 12.944732636119085 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "200 alpha: 5.845576333325844 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "188 alpha: 18.550020702378742 \n",
      "alphas 100 \n",
      "nb iter: 3\n",
      "214 alpha: 2.5077200491730784 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "259 alpha: 24.95986382814908 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "166 alpha: 7.535359705566598 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "271 alpha: 6.007861815398749 \n",
      "alphas 100 \n",
      "nb iter: 39\n",
      "280 alpha: 9.525961629605407 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "236 alpha: 8.559618897268576 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "175 alpha: 16.083425798630525 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "251 alpha: 12.213223997655883 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "260 alpha: 4.612548158648774 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "201 alpha: 22.75282298305238 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "289 alpha: 12.825155846686629 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "223 alpha: 9.35183602382967 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "167 alpha: 5.334167674021483 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "215 alpha: 5.74558763317744 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "189 alpha: 12.137391491278793 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "261 alpha: 7.3091623962507075 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "224 alpha: 7.31879781282824 \n",
      "alphas 100 \n",
      "nb iter: 85\n",
      "281 alpha: 10.429684229583982 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "300 alpha: 24.52590922063579 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "272 alpha: 17.736681568621893 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "202 alpha: 8.762870835204057 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "237 alpha: 11.02312700977448 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "324 alpha: 8.544929925021565 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "225 alpha: 15.223771940969892 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "312 alpha: 9.53268787002734 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "190 alpha: 18.219499865812715 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "176 alpha: 10.161328393037966 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "301 alpha: 8.65947396247763 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "290 alpha: 13.521678703754143 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "282 alpha: 15.445008040052631 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "238 alpha: 15.910057570747455 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "262 alpha: 12.388323138366083 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "203 alpha: 12.67932459548376 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "325 alpha: 24.347980116590854 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "191 alpha: 12.304753424925671 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "336 alpha: 7.518566827968374 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "239 alpha: 12.882038211021227 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "302 alpha: 3.307179755269717 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "273 alpha: 6.408652874045438 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "226 alpha: 12.087497925492595 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "360 alpha: 1.4435993610089584 \n",
      "alphas 100 \n",
      "nb iter: 113\n",
      "263 alpha: 18.66571816759029 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "313 alpha: 9.949590167685603 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "291 alpha: 13.692781571602325 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "337 alpha: 3.9316833610712565 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "177 alpha: 10.466885432941663 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "326 alpha: 14.168712867831172 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "283 alpha: 14.366172459750668 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "274 alpha: 2.9409912544671943 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "303 alpha: 11.856246938753786 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "227 alpha: 5.008586138332639 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "348 alpha: 15.1092976896178 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "314 alpha: 4.545210560386145 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "372 alpha: 8.130077882823763 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "275 alpha: 4.219795750442136 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "338 alpha: 1.8437534956960928 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "373 alpha: 9.252362398436786 \n",
      "alphas 100 \n",
      "nb iter: 76\n",
      "292 alpha: 10.149071178402874 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "361 alpha: 13.958072613923568 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "178 alpha: 8.645253693648593 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "327 alpha: 5.746728253626925 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "339 alpha: 4.17153351328315 \n",
      "alphas 100 \n",
      "nb iter: 58\n",
      "374 alpha: 12.104860838340942 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "349 alpha: 6.932735172833722 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "315 alpha: 5.981295559104659 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "375 alpha: 10.886227711212921 \n",
      "alphas 100 \n",
      "nb iter: 59\n",
      "293 alpha: 13.143174270497454 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "284 alpha: 16.13359409885184 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "396 alpha: 29.079809034692474 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "304 alpha: 24.847541438179313 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "384 alpha: 14.541474896194291 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "340 alpha: 13.37857777007867 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "328 alpha: 7.5627223263030805 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "376 alpha: 11.441768748847766 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "362 alpha: 9.87689824159616 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "350 alpha: 8.933407044860786 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "179 alpha: 14.253026050547678 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "316 alpha: 12.2180413085257 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "285 alpha: 7.946260881114114 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "329 alpha: 1.5534324761811593 \n",
      "alphas 100 \n",
      "nb iter: 97\n",
      "385 alpha: 4.380856406743932 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "294 alpha: 12.742210324188584 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "397 alpha: 24.41590128067139 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "341 alpha: 5.7100073743639905 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "305 alpha: 18.130756158886093 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "330 alpha: 5.939315336663901 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "317 alpha: 8.885194355997026 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "363 alpha: 4.157122929495427 \n",
      "alphas 100 \n",
      "nb iter: 37\n",
      "342 alpha: 6.234285518761885 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "351 alpha: 7.9241537593575755 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "398 alpha: 1.887271094664231 \n",
      "alphas 100 \n",
      "nb iter: 82\n",
      "377 alpha: 10.616421144107948 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "408 alpha: 16.45443724744821 \n",
      "alphas 100 \n",
      "nb iter: 3\n",
      "295 alpha: 4.3237152434472055 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "331 alpha: 30.816360298997395 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "286 alpha: 19.375324558917374 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "386 alpha: 18.074312231719166 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "306 alpha: 15.95747493475948 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "352 alpha: 5.746808854476286 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "318 alpha: 6.259449981615193 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "343 alpha: 12.515240490008107 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "364 alpha: 9.573876391478276 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "399 alpha: 4.627923666624808 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "332 alpha: 2.052274179156612 \n",
      "alphas 100 \n",
      "nb iter: 66\n",
      "307 alpha: 3.96513841965021 \n",
      "alphas 100 \n",
      "nb iter: 67\n",
      "296 alpha: 11.226604535013225 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "378 alpha: 5.375865052353938 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "387 alpha: 13.514662378833123 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "287 alpha: 8.2923446477955 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "400 alpha: 3.5829416980212465 \n",
      "alphas 100 \n",
      "nb iter: 48\n",
      "344 alpha: 26.980926389791655 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "319 alpha: 9.571923077475947 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "308 alpha: 8.24146379242646 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "409 alpha: 12.930076994302295 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "333 alpha: 2.6129985234395203 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "379 alpha: 7.576886143808963 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "353 alpha: 7.211056861251408 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "297 alpha: 3.677663059564179 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "345 alpha: 18.678972562357114 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "388 alpha: 2.6910247569836856 \n",
      "alphas 100 \n",
      "nb iter: 52\n",
      "380 alpha: 11.370351617373345 \n",
      "alphas 100 \n",
      "nb iter: 75\n",
      "365 alpha: 14.478686298537868 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "354 alpha: 8.97030601089475 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "298 alpha: 6.2288337962408615 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "389 alpha: 3.3180015577954096 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "420 alpha: 10.609654299161768 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "401 alpha: 16.591987299891283 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "309 alpha: 10.712273054925408 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "320 alpha: 7.10296783189186 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "334 alpha: 5.080918671269334 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "346 alpha: 4.604851153761588 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "355 alpha: 5.02881212913694 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "366 alpha: 13.647863033669063 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "410 alpha: 7.728079980610383 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "381 alpha: 9.942017472878957 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "299 alpha: 7.879889771803394 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "432 alpha: 10.132692043868325 \n",
      "alphas 100 \n",
      "nb iter: 71\n",
      "402 alpha: 5.5103109046713925 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "421 alpha: 12.042927882278876 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "411 alpha: 3.9323772612642234 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "390 alpha: 6.114491757443691 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "310 alpha: 16.79965168939431 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "321 alpha: 11.252135756825412 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "356 alpha: 13.629112224968404 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "391 alpha: 6.316972636903855 \n",
      "alphas 100 \n",
      "nb iter: 63\n",
      "347 alpha: 25.80195352238227 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "382 alpha: 4.9506494715796086 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "335 alpha: 16.43091323033647 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "422 alpha: 6.296835336341179 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "367 alpha: 18.577037257652897 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "444 alpha: 6.351392384057345 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "412 alpha: 5.589631384553141 \n",
      "alphas 100 \n",
      "nb iter: 34\n",
      "403 alpha: 15.594431121162765 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "433 alpha: 21.941194175751004 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "445 alpha: 3.5669268843001687 \n",
      "alphas 100 \n",
      "nb iter:311 alpha: 14.815460674269655 \n",
      "alphas 54\n",
      " 100 \n",
      "nb iter: 8\n",
      "413 alpha: 11.229119481960025 \n",
      "alphas 100 \n",
      "nb iter: 46\n",
      "383 alpha: 3.555147960424262 \n",
      "alphas 100 \n",
      "nb iter: 87\n",
      "392 alpha: 7.727128844440286 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "468 alpha: 8.352192277463743 \n",
      "alphas 100 \n",
      "nb iter: 72\n",
      "368 alpha: 5.326310726568022 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "357 alpha: 19.779766884742546 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "456 alpha: 16.588184541125692 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "434 alpha: 6.904467354703169 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "423 alpha: 10.722171338181322 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "393 alpha: 7.559046987887608 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "480 alpha: 6.266006617288485 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "322 alpha: 23.055337783248337 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "404 alpha: 13.772513852677768 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "358 alpha: 11.612658509140907 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "446 alpha: 10.683560201217798 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "405 alpha: 11.479231424550779 \n",
      "alphas 100 \n",
      "nb iter: 70\n",
      "369 alpha: 4.556189902220949 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "435 alpha: 5.032332537170765 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "469 alpha: 23.644329264381643 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "394 alpha: 6.82226891336465 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "370 alpha: 17.05303873771517 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "481 alpha: 10.384322190989911 \n",
      "alphas 100 \n",
      "nb iter: 15\n",
      "414 alpha: 7.987444342246405 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "406 alpha: 15.544425576381178 \n",
      "alphas 100 \n",
      "nb iter: 48\n",
      "424 alpha: 12.151786628492246 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "359 alpha: 24.534603291645197 \n",
      "alphas 100 \n",
      "nb iter: 14\n",
      "457 alpha: 14.009406358171864 \n",
      "alphas 100 \n",
      "nb iter: 7\n",
      "371 alpha: 13.982139093239997 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "436 alpha: 2.603538828839858 \n",
      "alphas 100 \n",
      "nb iter: 68\n",
      "395 alpha: 6.964215255475753 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "323 alpha: 23.0860485169127 \n",
      "alphas 100 \n",
      "nb iter: 9\n",
      "437 alpha: 8.630046371652421 \n",
      "alphas 100 \n",
      "nb iter: 60\n",
      "504 alpha: 7.198356422554824 \n",
      "alphas 100 \n",
      "nb iter: 90\n",
      "470 alpha: 4.920905067979739 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "447 alpha: 4.044966014141817 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "516 alpha: 6.080439743415152 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "505 alpha: 8.984610214312745 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "492 alpha: 16.246006263481856 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "425 alpha: 10.750286209226978 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "407 alpha: 8.58031810231865 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "528 alpha: 8.146603254260366 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "471 alpha: 11.55353097181237 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "415 alpha: 24.52287081453371 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "482 alpha: 8.526123678771299 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "438 alpha: 5.428447655738372 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "506 alpha: 15.201887737471605 \n",
      "alphas 100 \n",
      "nb iter: 51\n",
      "448 alpha: 6.934621520183391 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "458 alpha: 14.401929938593533 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "507 alpha: 9.826641835953778 \n",
      "alphas 100 \n",
      "nb iter: 88\n",
      "517 alpha: 9.790079418352125 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "483 alpha: 7.827284364832706 \n",
      "alphas 100 \n",
      "nb iter: 49\n",
      "416 alpha: 7.7752515272041505 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "508 alpha: 6.423111665815841 \n",
      "alphas 100 \n",
      "nb iter: 62\n",
      "449 alpha: 9.800314575266933 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "540 alpha: 15.485212993075717 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "459 alpha: 12.878935456471035 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "472 alpha: 18.065004639874417 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "439 alpha: 29.212073892988695 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "493 alpha: 5.793936822070323 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "529 alpha: 8.038534173571941 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "450 alpha: 8.997271725897187 \n",
      "alphas 100 \n",
      "nb iter: 68\n",
      "426 alpha: 11.619701617364932 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "440 alpha: 7.468660823808657 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "494 alpha: 8.306208279531196 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "451 alpha: 4.0513551124544565 \n",
      "alphas 100 \n",
      "nb iter: 45\n",
      "417 alpha: 6.08911470496111 \n",
      "alphas 100 \n",
      "nb iter: 65\n",
      "541 alpha: 10.607171431686332 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "484 alpha: 4.80867021672201 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "518 alpha: 16.78075994464341 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "460 alpha: 8.854288974366865 \n",
      "alphas 100 \n",
      "nb iter: 23\n",
      "509 alpha: 9.304166841951728 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "427 alpha: 23.976881805249313 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "473 alpha: 5.286884050527072 \n",
      "alphas 100 \n",
      "nb iter: 12\n",
      "519 alpha: 5.4246534899128855 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "530 alpha: 21.7755176904711 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "441 alpha: 23.356541338153626 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "452 alpha: 8.936599070275362 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "485 alpha: 9.697494355135479 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "461 alpha: 22.905052570159356 \n",
      "alphas 100 \n",
      "nb iter: 8\n",
      "542 alpha: 4.916022862755556 \n",
      "alphas 100 \n",
      "nb iter: 36\n",
      "418 alpha: 7.174204969423266 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "495 alpha: 29.61845326553063 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "510 alpha: 2.8503691560060633 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "486 alpha: 9.242905284187124 \n",
      "alphas 100 \n",
      "nb iter: 57\n",
      "474 alpha: 5.248272467286698 \n",
      "alphas 100 \n",
      "nb iter: 27\n",
      "520 alpha: 4.492181186584238 \n",
      "alphas 100 \n",
      "nb iter: 33\n",
      "462 alpha: 7.014275487465671 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "442 alpha: 3.740357101120782 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "453 alpha: 11.212119134954628 \n",
      "alphas 100 \n",
      "nb iter: 17\n",
      "531 alpha: 11.745284033842744 \n",
      "alphas 100 \n",
      "nb iter: 18\n",
      "543 alpha: 5.727385889320397 \n",
      "alphas 100 \n",
      "nb iter: 29\n",
      "443 alpha: 13.41062654171757 \n",
      "alphas 100 \n",
      "nb iter: 40\n",
      "428 alpha: 12.810498071584636 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "521 alpha: 12.63375511077632 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "544 alpha: 4.534983665923596 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "487 alpha: 6.46280863927661 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "454 alpha: 9.912231550863732 \n",
      "alphas 100 \n",
      "nb iter: 31\n",
      "511 alpha: 13.870228162312381 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "532 alpha: 4.310885866528782 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "419 alpha: 13.027579342711972 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "429 alpha: 20.26485263785144 \n",
      "alphas 100 \n",
      "nb iter: 47\n",
      "496 alpha: 14.06080885107424 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "475 alpha: 10.469359269422 \n",
      "alphas 100 \n",
      "nb iter: 5\n",
      "430 alpha: 14.039812969058637 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "463 alpha: 22.843159823947182 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "512 alpha: 2.0182424794321094 \n",
      "alphas 100 \n",
      "nb iter: 63\n",
      "431 alpha: 6.434588509788461 \n",
      "alphas 100 \n",
      "nb iter: 88\n",
      "552 alpha: 12.20376174593774 \n",
      "alphas 100 \n",
      "nb iter: 22\n",
      "522 alpha: 10.706463043030757 \n",
      "alphas 100 \n",
      "nb iter: 11\n",
      "476 alpha: 6.798416569087134 \n",
      "alphas 100 \n",
      "nb iter: 26\n",
      "455 alpha: 5.4535361923181345 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "513 alpha: 5.027627356586642 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "464 alpha: 3.756468802451327 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "533 alpha: 19.77883970613941 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "523 alpha: 6.191062248029567 \n",
      "alphas 100 \n",
      "nb iter: 81\n",
      "488 alpha: 13.782879714046626 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "545 alpha: 25.984993658283244 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "497 alpha: 13.241549345078164 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "553 alpha: 17.66105959775788 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "477 alpha: 21.429842258922 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "514 alpha: 6.251679761787326 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "524 alpha: 2.758466562632116 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "546 alpha: 5.840579265481496 \n",
      "alphas 100 \n",
      "nb iter: 44\n",
      "465 alpha: 8.757148512041194 \n",
      "alphas 100 \n",
      "nb iter: 21\n",
      "515 alpha: 10.103825862856143 \n",
      "alphas 100 \n",
      "nb iter: 35\n",
      "554 alpha: 25.27639015497073 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "466 alpha: 12.757375797734111 \n",
      "alphas 100 \n",
      "nb iter: 25\n",
      "489 alpha: 12.479126628000575 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "534 alpha: 11.57997752711342 \n",
      "alphas 100 \n",
      "nb iter: 10\n",
      "525 alpha: 10.67919868167299 \n",
      "alphas 100 \n",
      "nb iter: 24\n",
      "478 alpha: 5.819726087902807 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "498 alpha: 14.517867258204447 \n",
      "alphas 100 \n",
      "nb iter: 1\n",
      "547 alpha: 4.300787662974748 \n",
      "alphas 100 \n",
      "nb iter: 16\n",
      "467 alpha: 6.513463985270197 \n",
      "alphas 100 \n",
      "nb iter: 30\n",
      "490 alpha: 8.146519586368782 \n",
      "alphas 100 \n",
      "nb iter: 28\n",
      "555 alpha: 15.23844325401519 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "548 alpha: 10.870330103477757 \n",
      "alphas 100 \n",
      "nb iter: 43\n",
      "479 alpha: 2.7353325776006665 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "526 alpha: 11.444103609929646 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "535 alpha: 14.820818332295026 \n",
      "alphas 100 \n",
      "nb iter: 4\n",
      "549 alpha: 8.834464030433564 \n",
      "alphas 100 \n",
      "nb iter: 50\n",
      "499 alpha: 10.541367090491686 \n",
      "alphas 100 \n",
      "nb iter: 6\n",
      "500 alpha: 7.794024406525308 \n",
      "alphas 100 \n",
      "nb iter: 55\n",
      "491 alpha: 12.600191999498662 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "536 alpha: 13.61522855581978 \n",
      "alphas 100 \n",
      "nb iter: 32\n",
      "550 alpha: 5.182651787602775 \n",
      "alphas 100 \n",
      "nb iter: 19\n",
      "527 alpha: 13.519247782850412 \n",
      "alphas 100 \n",
      "nb iter: 2\n",
      "501 alpha: 16.426315015586997 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "537 alpha: 5.056579487473483 \n",
      "alphas 100 \n",
      "nb iter: 41\n",
      "502 alpha: 5.321391290534269 \n",
      "alphas 100 \n",
      "nb iter: 64\n",
      "503 alpha: 5.988310704017923 \n",
      "alphas 100 \n",
      "nb iter: 38\n",
      "551 alpha: 8.380651291887007 \n",
      "alphas 100 \n",
      "nb iter: 20\n",
      "538 alpha: 9.628106726518237 \n",
      "alphas 100 \n",
      "nb iter: 13\n",
      "539 alpha: 3.1652652382917514 \n",
      "alphas 100 \n",
      "nb iter: 42\n",
      "CPU times: user 2.27 s, sys: 1.29 s, total: 3.56 s\n",
      "Wall time: 22min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pool = mp.Pool(processes=12)\n",
    "\n",
    "results = pool.map(fit_lasso, range(nSegments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 99.58364336189145\n"
     ]
    }
   ],
   "source": [
    "mse=0\n",
    "for i in range(len(results)):\n",
    "    mse += np.mean(results[i].mse_path_[np.where(results[i].alphas_ == results[i].alpha_)[0][0]])\n",
    "mse = mse/len(results)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_para = []\n",
    "\n",
    "for i in range(nSegments):\n",
    "    preds_lasso_para.append(results[i].predict(new_X_test))\n",
    "\n",
    "preds_lasso_para = np.array(preds_lasso_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec CV\n",
      "MSE: 102.27059546136078\n",
      "MAE: 6.935341225207588\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec CV\")\n",
    "print(\"MSE:\", mean_squared_error(preds_lasso_para.T.flatten(), new_Y_test.flatten()))\n",
    "print(\"MAE:\", mean_absolute_error(preds_lasso_para.T.flatten(), new_Y_test.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [a.coef_ for a in results]\n",
    "A = [A]*19\n",
    "A = np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.59049561290934"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risque(A, new_X_train, new_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risque du modèle général: 89.59**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Created!\n",
      "n = 65\n",
      "Z2_train shape: (45, 556, 20)\n",
      "Z2_train shape: (45, 556, 21)\n",
      "Zt_train shape: (5, 45, 556, 5)\n",
      "Zt_test shape: (5, 20, 556, 5)\n",
      "Z Centré !\n",
      "9.671276125623585e-16\n"
     ]
    }
   ],
   "source": [
    "Z2 = []\n",
    "\n",
    "for i in range(int((speedDF.shape[1])/20)):\n",
    "    Z2.append(speedDF.iloc[:,i*20:(i+1)*20].values)\n",
    "\n",
    "print(\"Z Created!\")\n",
    "n = len(Z2)\n",
    "print(\"n =\", n)\n",
    "\n",
    "Z2 = np.array(Z2)\n",
    "\n",
    "Z2_train = Z[:45]\n",
    "Z2_test = Z[45:]\n",
    "\n",
    "\n",
    "print(\"Z2_train shape:\", Z2_train.shape)\n",
    "Z2_train = np.append(Z2_train, np.zeros((45,556,1)), axis=2)\n",
    "print(\"Z2_train shape:\", Z2_train.shape)\n",
    "\n",
    "Z2_test = np.append(Z2_test, np.zeros((20,556,1)), axis=2)\n",
    "\n",
    "\n",
    "Zt_train = []\n",
    "for i in range(5):\n",
    "    Zt_train.append(Z2_train[:,:,i*4:(i+1)*4+1])\n",
    "Zt_train = np.array(Zt_train)\n",
    "print(\"Zt_train shape:\", Zt_train.shape)\n",
    "\n",
    "\n",
    "Zt_test = []\n",
    "for i in range(5):\n",
    "    Zt_test.append(Z2_test[:,:,i*4:(i+1)*4+1])\n",
    "Zt_test = np.array(Zt_test)\n",
    "print(\"Zt_test shape:\", Zt_test.shape)\n",
    "\n",
    "\n",
    "for j in range(5):\n",
    "    M = (1/45)*Zt_train[j].sum(axis=0)\n",
    "\n",
    "    for i in range(45):\n",
    "        Zt_train[j][i] = Zt_train[j][i] - M\n",
    "    for i in range(65-45):\n",
    "        Zt_test[j][i] = Zt_test[j][i] - M\n",
    "    \n",
    "print(\"Z Centré !\")\n",
    "print(Zt_train[1,:,1,3].mean())\n",
    "\n",
    "X_train_time = [X_Y(Zt_train[i])[0] for i in range(4)]\n",
    "X_train_time.append(X_Y(Zt_train[-1][:,:,:-1])[0])\n",
    "Y_train_time = [X_Y(Zt_train[i])[1] for i in range(4)]\n",
    "Y_train_time.append(X_Y(Zt_train[-1][:,:,:-1])[1])\n",
    "\n",
    "X_test_time = [X_Y(Zt_test[i])[0] for i in range(4)]\n",
    "X_test_time.append(X_Y(Zt_test[-1][:,:,:-1])[0])\n",
    "Y_test_time = [X_Y(Zt_test[i])[1] for i in range(4)]\n",
    "Y_test_time.append(X_Y(Zt_test[-1][:,:,:-1])[1])\n",
    "#X_train_time, Y_train_time  = np.array([X_Y(Zt_train[i]) for i in range(5)])[:,0], np.array([X_Y(Zt_train[i]) for i in range(5)])[:,1]\n",
    "#print(X_train_time.shape, Y_train_time.shape)\n",
    "#X_test_time, Y_test_time = np.array([X_Y(Zt_test[i]) for i in range(5)])[:,0], np.array([X_Y(Zt_test[i]) for i in range(5)])[:,1]\n",
    "#print(X_test_time.shape, Y_test_time.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention X_train_time et cie listes de taille 5 avec les 4 premiers de shape 180,556 et le dernier de shape 135, 556**\n",
    "\n",
    "**Pour test_time c'est 80,556 et 60,556**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lasso_time = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments*5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lasso_time(i):\n",
    "    j = i % 556\n",
    "    k = i // 556\n",
    "    A_lasso_time[i].fit(X_train_time[k], Y_train_time[k][:, j])\n",
    "    print(\"timeframe:\", k, \"section:\", j, \"alpha:\", A_lasso_time[i].alpha_)\n",
    "    return A_lasso_time[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeframe: 0 section: 14 alpha: 9.158871517226588\n",
      "timeframe: 0 section: 308 alpha: 24.836508203648474\n",
      "timeframe: 1 section: 137 alpha: 30.13337522216871\n",
      "timeframe: 0 section: 105 alpha: 11.20191709682916\n",
      "timeframe: 0 section: 511 alpha: 10.054632219650879\n",
      "timeframe: 1 section: 18 alpha: 23.302316946114285\n",
      "timeframe: 0 section: 49 alpha: 9.031644436332076\n",
      "timeframe: 1 section: 67 alpha: 6.230083515277103\n",
      "timeframe: 0 section: 273 alpha: 18.960492308063678\n",
      "timeframe: 0 section: 504 alpha: 9.109787529005859\n",
      "timeframe: 0 section: 35 alpha: 7.4862650145321625\n",
      "timeframe: 0 section: 315 alpha: 86.63014077704382\n",
      "timeframe: 1 section: 123 alpha: 34.990680567941226\n",
      "timeframe: 1 section: 60 alpha: 18.53658055619706\n",
      "timeframe: 0 section: 77 alpha: 23.695614023762943\n",
      "timeframe: 0 section: 448 alpha: 8.792979834362272\n",
      "timeframe: 0 section: 364 alpha: 25.135349386754502\n",
      "timeframe: 0 section: 462 alpha: 95.47259606565194\n",
      "timeframe: 0 section: 126 alpha: 15.512514094954684\n",
      "timeframe: 0 section: 427 alpha: 49.051898010079\n",
      "timeframe: 0 section: 217 alpha: 28.964931102313738\n",
      "timeframe: 0 section: 168 alpha: 24.35117283677002\n",
      "timeframe: 0 section: 294 alpha: 40.61818043495898\n",
      "timeframe: 0 section: 455 alpha: 12.15787134325916\n",
      "timeframe: 0 section: 385 alpha: 8.381382289606014\n",
      "timeframe: 0 section: 63 alpha: 25.895694977806997\n",
      "timeframe: 0 section: 546 alpha: 25.31034410082712\n",
      "timeframe: 0 section: 483 alpha: 30.666727553683742\n",
      "timeframe: 0 section: 413 alpha: 16.479478463351693\n",
      "timeframe: 0 section: 553 alpha: 30.72078418620627\n",
      "timeframe: 0 section: 420 alpha: 38.49855942269639\n",
      "timeframe: 0 section: 56 alpha: 15.875465897111857\n",
      "timeframe: 0 section: 336 alpha: 14.76241020221101\n",
      "timeframe: 0 section: 154 alpha: 31.47028808774156\n",
      "timeframe: 0 section: 203 alpha: 21.817526763137586\n",
      "timeframe: 0 section: 518 alpha: 15.59985945694936\n",
      "timeframe: 0 section: 532 alpha: 19.357386300566443\n",
      "timeframe: 0 section: 252 alpha: 33.00011969446421\n",
      "timeframe: 0 section: 539 alpha: 20.00935986219533\n",
      "timeframe: 0 section: 441 alpha: 30.420548760076965\n",
      "timeframe: 0 section: 343 alpha: 23.317749814947902\n",
      "timeframe: 0 section: 406 alpha: 24.401749022519635\n",
      "timeframe: 0 section: 357 alpha: 40.06566547072606\n",
      "timeframe: 0 section: 84 alpha: 40.10821278309014\n",
      "timeframe: 0 section: 434 alpha: 28.85704074009336\n",
      "timeframe: 0 section: 28 alpha: 24.781444556095614\n",
      "timeframe: 0 section: 287 alpha: 14.360243596526594\n",
      "timeframe: 0 section: 189 alpha: 35.3676626441784\n",
      "timeframe: 0 section: 42 alpha: 8.27282666094049\n",
      "timeframe: 0 section: 497 alpha: 35.188371503957846\n",
      "timeframe: 0 section: 266 alpha: 18.220963319033977\n",
      "timeframe: 0 section: 70 alpha: 9.397468523086212\n",
      "timeframe: 0 section: 196 alpha: 44.76797158890647\n",
      "timeframe: 0 section: 175 alpha: 16.36318022653274\n",
      "timeframe: 0 section: 350 alpha: 15.67366218860942\n",
      "timeframe: 0 section: 392 alpha: 19.966759563703217\n",
      "timeframe: 0 section: 98 alpha: 44.59817162167\n",
      "timeframe: 0 section: 161 alpha: 36.70444559137205\n",
      "timeframe: 0 section: 147 alpha: 14.56740133269027\n",
      "timeframe: 0 section: 91 alpha: 20.267523341117332\n",
      "timeframe: 0 section: 21 alpha: 7.004073901688471\n",
      "timeframe: 0 section: 469 alpha: 31.96677649798148\n",
      "timeframe: 1 section: 116 alpha: 27.314891300467234\n",
      "timeframe: 0 section: 280 alpha: 13.718746366938753\n",
      "timeframe: 0 section: 210 alpha: 29.82713937338252\n",
      "timeframe: 0 section: 371 alpha: 1.604342871406509\n",
      "timeframe: 0 section: 238 alpha: 30.114727624474632\n",
      "timeframe: 0 section: 133 alpha: 41.8881063139285\n",
      "timeframe: 0 section: 322 alpha: 41.66863282050503\n",
      "timeframe: 1 section: 39 alpha: 21.52618622796296\n",
      "timeframe: 0 section: 399 alpha: 15.877646840134522\n",
      "timeframe: 0 section: 119 alpha: 19.05883763214897\n",
      "timeframe: 1 section: 25 alpha: 29.862113626567638\n",
      "timeframe: 0 section: 301 alpha: 11.438230090033908\n",
      "timeframe: 0 section: 182 alpha: 27.914849411163335\n",
      "timeframe: 1 section: 53 alpha: 18.23619118891072\n",
      "timeframe: 0 section: 7 alpha: 15.156751178802585\n",
      "timeframe: 1 section: 102 alpha: 29.78252233632866\n",
      "timeframe: 0 section: 231 alpha: 26.026387695847767\n",
      "timeframe: 0 section: 378 alpha: 9.620199083733233\n",
      "timeframe: 1 section: 95 alpha: 11.466903673095912\n",
      "timeframe: 1 section: 81 alpha: 4.113475423524585\n",
      "timeframe: 0 section: 140 alpha: 59.059078670809335\n",
      "timeframe: 0 section: 329 alpha: 7.667232543584663\n",
      "timeframe: 1 section: 88 alpha: 29.47693188432084\n",
      "timeframe: 0 section: 490 alpha: 30.79034821868498\n",
      "timeframe: 0 section: 224 alpha: 29.05083977425613\n",
      "timeframe: 0 section: 112 alpha: 15.088044319833617\n",
      "timeframe: 0 section: 476 alpha: 39.36956490711738\n",
      "timeframe: 0 section: 525 alpha: 39.604707424637105\n",
      "timeframe: 0 section: 0 alpha: 22.943930153447113\n",
      "timeframe: 0 section: 15 alpha: 38.34340940596447\n",
      "timeframe: 0 section: 259 alpha: 44.79649356091141\n",
      "timeframe: 1 section: 32 alpha: 64.47326260971143\n",
      "timeframe: 0 section: 245 alpha: 5.956289043983178\n",
      "timeframe: 1 section: 46 alpha: 17.926097691392016\n",
      "timeframe: 0 section: 36 alpha: 5.623924664728957\n",
      "timeframe: 1 section: 4 alpha: 14.02864569752742\n",
      "timeframe: 0 section: 57 alpha: 16.92232923431794\n",
      "timeframe: 1 section: 11 alpha: 22.67535427348642\n",
      "timeframe: 1 section: 109 alpha: 17.08589289364362\n",
      "timeframe: 1 section: 74 alpha: 5.254865786927431\n",
      "timeframe: 0 section: 50 alpha: 55.295368087267235\n",
      "timeframe: 0 section: 71 alpha: 122.74152609796735\n",
      "timeframe: 0 section: 43 alpha: 13.10629448837723\n",
      "timeframe: 0 section: 78 alpha: 27.37261046371649\n",
      "timeframe: 1 section: 130 alpha: 28.23910034567773\n",
      "timeframe: 0 section: 1 alpha: 22.079713791276028\n",
      "timeframe: 0 section: 29 alpha: 17.475320755325008\n",
      "timeframe: 0 section: 64 alpha: 21.354698546110235\n",
      "timeframe: 0 section: 8 alpha: 27.17365659235975\n",
      "timeframe: 0 section: 22 alpha: 13.310473308761356\n",
      "timeframe: 0 section: 225 alpha: 28.76960514841055\n",
      "timeframe: 0 section: 183 alpha: 22.54216099337072\n",
      "timeframe: 0 section: 176 alpha: 20.73868002598715\n",
      "timeframe: 0 section: 211 alpha: 34.45948565877267\n",
      "timeframe: 0 section: 323 alpha: 24.0984086768311\n",
      "timeframe: 0 section: 309 alpha: 14.553224799565715\n",
      "timeframe: 1 section: 5 alpha: 10.621699746518738\n",
      "timeframe: 0 section: 449 alpha: 57.84890813452603\n",
      "timeframe: 0 section: 477 alpha: 33.714283953584676\n",
      "timeframe: 0 section: 372 alpha: 74.48092694420771\n",
      "timeframe: 0 section: 232 alpha: 10.263700512520408\n",
      "timeframe: 0 section: 134 alpha: 20.519672868719656\n",
      "timeframe: 0 section: 519 alpha: 29.35165016898342\n",
      "timeframe: 0 section: 456 alpha: 32.47684133166833\n",
      "timeframe: 0 section: 393 alpha: 16.357896981840973\n",
      "timeframe: 0 section: 330 alpha: 6.7387165813464796\n",
      "timeframe: 0 section: 463 alpha: 51.35493139380583\n",
      "timeframe: 0 section: 435 alpha: 8.283631390031221\n",
      "timeframe: 0 section: 344 alpha: 12.225527223610394\n",
      "timeframe: 0 section: 470 alpha: 13.134909851397104\n",
      "timeframe: 0 section: 120 alpha: 11.059055939130715\n",
      "timeframe: 0 section: 386 alpha: 23.408481218419105\n",
      "timeframe: 0 section: 547 alpha: 15.348945966682663\n",
      "timeframe: 1 section: 12 alpha: 39.60433858681448\n",
      "timeframe: 0 section: 316 alpha: 29.7498311902283\n",
      "timeframe: 1 section: 131 alpha: 20.213491106121392\n",
      "timeframe: 0 section: 162 alpha: 13.333227330086297\n",
      "timeframe: 1 section: 124 alpha: 23.58919565841936\n",
      "timeframe: 1 section: 117 alpha: 22.313457898018985\n",
      "timeframe: 0 section: 92 alpha: 27.684270442017645\n",
      "timeframe: 1 section: 19 alpha: 23.779354525880223\n",
      "timeframe: 0 section: 274 alpha: 11.359216903455305\n",
      "timeframe: 0 section: 533 alpha: 19.63231749788409\n",
      "timeframe: 0 section: 505 alpha: 8.72622503206388\n",
      "timeframe: 0 section: 442 alpha: 8.558310727035892\n",
      "timeframe: 0 section: 85 alpha: 29.77333403045389\n",
      "timeframe: 0 section: 23 alpha: 14.110257963801057\n",
      "timeframe: 0 section: 218 alpha: 23.77502919760389\n",
      "timeframe: 0 section: 204 alpha: 15.086561711825157\n",
      "timeframe: 1 section: 33 alpha: 53.7790570732634\n",
      "timeframe: 0 section: 79 alpha: 26.943190202586283\n",
      "timeframe: 0 section: 16 alpha: 8.75256515951086\n",
      "timeframe: 0 section: 295 alpha: 13.346042110474256\n",
      "timeframe: 0 section: 155 alpha: 26.29764796802295\n",
      "timeframe: 0 section: 414 alpha: 26.037186463492876\n",
      "timeframe: 0 section: 197 alpha: 28.90426271708546\n",
      "timeframe: 0 section: 30 alpha: 16.5275373428668\n",
      "timeframe: 0 section: 428 alpha: 25.924423299676654\n",
      "timeframe: 0 section: 400 alpha: 21.257910486559982\n",
      "timeframe: 1 section: 61 alpha: 18.109458167145807\n",
      "timeframe: 0 section: 58 alpha: 59.04895088174379\n",
      "timeframe: 0 section: 421 alpha: 29.956541440115377\n",
      "timeframe: 0 section: 358 alpha: 15.577342621660668\n",
      "timeframe: 0 section: 302 alpha: 15.89062711688227\n",
      "timeframe: 0 section: 106 alpha: 19.99772090779075\n",
      "timeframe: 0 section: 99 alpha: 28.238002097427945\n",
      "timeframe: 0 section: 9 alpha: 8.550551807916873\n",
      "timeframe: 0 section: 484 alpha: 8.223003405763567\n",
      "timeframe: 0 section: 127 alpha: 23.449436058499092\n",
      "timeframe: 1 section: 68 alpha: 6.810349056631543\n",
      "timeframe: 0 section: 169 alpha: 3.508074823491784\n",
      "timeframe: 0 section: 554 alpha: 58.217829307117725\n",
      "timeframe: 0 section: 337 alpha: 12.080477441267954\n",
      "timeframe: 0 section: 113 alpha: 29.120599158132794\n",
      "timeframe: 0 section: 288 alpha: 19.275226408990083\n",
      "timeframe: 0 section: 491 alpha: 36.82391425723486\n",
      "timeframe: 0 section: 351 alpha: 16.108696617812313\n",
      "timeframe: 0 section: 190 alpha: 25.182589985580833\n",
      "timeframe: 0 section: 2 alpha: 24.217410007403203\n",
      "timeframe: 1 section: 110 alpha: 23.82677997399992\n",
      "timeframe: 1 section: 82 alpha: 25.707437716170496\n",
      "timeframe: 0 section: 246 alpha: 29.1003440863672\n",
      "timeframe: 0 section: 260 alpha: 20.09691022908788\n",
      "timeframe: 0 section: 498 alpha: 26.30134991477245\n",
      "timeframe: 1 section: 40 alpha: 15.49632176186505\n",
      "timeframe: 1 section: 138 alpha: 67.1385056754561\n",
      "timeframe: 0 section: 37 alpha: 11.156103835253735\n",
      "timeframe: 0 section: 526 alpha: 24.02360244751626\n",
      "timeframe: 0 section: 379 alpha: 16.267454670380964\n",
      "timeframe: 0 section: 253 alpha: 17.714660074758378\n",
      "timeframe: 0 section: 540 alpha: 20.973842729168265\n",
      "timeframe: 0 section: 512 alpha: 16.722531721956223\n",
      "timeframe: 0 section: 51 alpha: 12.304418374541179\n",
      "timeframe: 0 section: 141 alpha: 46.79268596347055\n",
      "timeframe: 1 section: 26 alpha: 12.301505741184604\n",
      "timeframe: 0 section: 239 alpha: 25.409099839253635\n",
      "timeframe: 0 section: 148 alpha: 13.265886005643067\n",
      "timeframe: 1 section: 47 alpha: 5.626759593921438\n",
      "timeframe: 1 section: 75 alpha: 30.85845783557586\n",
      "timeframe: 0 section: 267 alpha: 59.05525315426707\n",
      "timeframe: 0 section: 450 alpha: 13.314295639610158\n",
      "timeframe: 0 section: 226 alpha: 20.6927305154695\n",
      "timeframe: 0 section: 44 alpha: 19.63949487444136\n",
      "timeframe: 0 section: 72 alpha: 10.140228361387864\n",
      "timeframe: 1 section: 96 alpha: 17.94879359873126\n",
      "timeframe: 1 section: 54 alpha: 11.465664888604923\n",
      "timeframe: 0 section: 365 alpha: 22.69154498615258\n",
      "timeframe: 1 section: 89 alpha: 33.75763746422529\n",
      "timeframe: 0 section: 233 alpha: 8.999124707499982\n",
      "timeframe: 0 section: 373 alpha: 5.3077427022161485\n",
      "timeframe: 0 section: 310 alpha: 43.21153227186119\n",
      "timeframe: 1 section: 103 alpha: 39.2463836502861\n",
      "timeframe: 0 section: 548 alpha: 13.81120332552261\n",
      "timeframe: 0 section: 65 alpha: 27.72675348738669\n",
      "timeframe: 0 section: 184 alpha: 26.157595900781416\n",
      "timeframe: 0 section: 324 alpha: 52.13916572211123\n",
      "timeframe: 0 section: 436 alpha: 80.38165208187422\n",
      "timeframe: 0 section: 407 alpha: 25.448208882748354\n",
      "timeframe: 0 section: 135 alpha: 11.846905104703298\n",
      "timeframe: 0 section: 177 alpha: 23.682370401630738\n",
      "timeframe: 0 section: 275 alpha: 6.50230760266381\n",
      "timeframe: 0 section: 93 alpha: 8.906004904289397\n",
      "timeframe: 0 section: 317 alpha: 14.472604612850024\n",
      "timeframe: 0 section: 212 alpha: 27.664983871623427\n",
      "timeframe: 0 section: 464 alpha: 15.134099818195127\n",
      "timeframe: 0 section: 457 alpha: 19.966510928112317\n",
      "timeframe: 0 section: 471 alpha: 25.79022940673524\n",
      "timeframe: 0 section: 163 alpha: 4.122836085468986\n",
      "timeframe: 0 section: 478 alpha: 16.386838338346717\n",
      "timeframe: 0 section: 520 alpha: 17.80641181028696\n",
      "timeframe: 0 section: 394 alpha: 28.05952599351658\n",
      "timeframe: 0 section: 281 alpha: 26.61913415521561\n",
      "timeframe: 0 section: 331 alpha: 10.69393703975937\n",
      "timeframe: 0 section: 506 alpha: 17.587388503550862\n",
      "timeframe: 0 section: 10 alpha: 75.00999015876808\n",
      "timeframe: 0 section: 86 alpha: 15.754731380881644\n",
      "timeframe: 0 section: 443 alpha: 31.456448198855494\n",
      "timeframe: 0 section: 345 alpha: 29.974267220450745\n",
      "timeframe: 1 section: 6 alpha: 19.911276711494132\n",
      "timeframe: 0 section: 121 alpha: 40.91467183333673\n",
      "timeframe: 0 section: 198 alpha: 8.988125197907099\n",
      "timeframe: 0 section: 17 alpha: 29.316997530717046\n",
      "timeframe: 0 section: 205 alpha: 41.66578215263697\n",
      "timeframe: 0 section: 387 alpha: 25.22265193518089\n",
      "timeframe: 0 section: 114 alpha: 10.581308882648928\n",
      "timeframe: 0 section: 534 alpha: 23.854469878803087\n",
      "timeframe: 0 section: 80 alpha: 22.292901974489094\n",
      "timeframe: 0 section: 401 alpha: 29.94760461427225\n",
      "timeframe: 0 section: 52 alpha: 2.5491821821038485\n",
      "timeframe: 0 section: 296 alpha: 22.822404962133827\n",
      "timeframe: 0 section: 415 alpha: 38.46734611613544\n",
      "timeframe: 0 section: 24 alpha: 4.6311176875927345\n",
      "timeframe: 1 section: 20 alpha: 15.457394655919215\n",
      "timeframe: 0 section: 100 alpha: 16.297568196070813\n",
      "timeframe: 0 section: 492 alpha: 14.648471352811818\n",
      "timeframe: 0 section: 359 alpha: 12.008319394409298\n",
      "timeframe: 0 section: 107 alpha: 30.449150228880487\n",
      "timeframe: 0 section: 170 alpha: 37.07137992243559\n",
      "timeframe: 1 section: 132 alpha: 15.644385459281107\n",
      "timeframe: 0 section: 261 alpha: 12.29063404944488\n",
      "timeframe: 0 section: 191 alpha: 27.07271093119248\n",
      "timeframe: 0 section: 3 alpha: 45.63852985048973\n",
      "timeframe: 0 section: 513 alpha: 14.154797825670341\n",
      "timeframe: 0 section: 338 alpha: 13.317123021097034\n",
      "timeframe: 1 section: 13 alpha: 32.130273261145966\n",
      "timeframe: 0 section: 31 alpha: 24.171480566403012\n",
      "timeframe: 1 section: 34 alpha: 9.241136902175448\n",
      "timeframe: 0 section: 380 alpha: 41.45923028375866\n",
      "timeframe: 0 section: 422 alpha: 11.915157261361566\n",
      "timeframe: 0 section: 429 alpha: 58.257769332522294\n",
      "timeframe: 0 section: 128 alpha: 24.994454421653256\n",
      "timeframe: 0 section: 374 alpha: 17.854886515887554\n",
      "timeframe: 0 section: 555 alpha: 29.083917131644686\n",
      "timeframe: 0 section: 303 alpha: 34.18384312367895\n",
      "timeframe: 0 section: 38 alpha: 73.16749630775952\n",
      "timeframe: 0 section: 247 alpha: 20.227131034642127\n",
      "timeframe: 0 section: 254 alpha: 28.009961307842737\n",
      "timeframe: 0 section: 240 alpha: 15.919571364775567\n",
      "timeframe: 0 section: 45 alpha: 27.761572733273386\n",
      "timeframe: 0 section: 541 alpha: 27.52889599630964\n",
      "timeframe: 0 section: 59 alpha: 18.42898554119147\n",
      "timeframe: 0 section: 73 alpha: 16.652273856230128\n",
      "timeframe: 0 section: 499 alpha: 16.247833368382313\n",
      "timeframe: 0 section: 219 alpha: 9.06639567965265\n",
      "timeframe: 0 section: 527 alpha: 10.197701111800066\n",
      "timeframe: 0 section: 485 alpha: 15.542369513430257\n",
      "timeframe: 0 section: 149 alpha: 19.818390932778307\n",
      "timeframe: 1 section: 125 alpha: 22.291789527612536\n",
      "timeframe: 1 section: 55 alpha: 18.916294745617304\n",
      "timeframe: 0 section: 289 alpha: 19.77311008708123\n",
      "timeframe: 0 section: 185 alpha: 18.788063980215902\n",
      "timeframe: 0 section: 268 alpha: 9.357044397321923\n",
      "timeframe: 0 section: 227 alpha: 15.087601893882612\n",
      "timeframe: 0 section: 451 alpha: 9.432042878129934\n",
      "timeframe: 1 section: 83 alpha: 19.164517202053965\n",
      "timeframe: 1 section: 118 alpha: 26.378304418341312\n",
      "timeframe: 1 section: 139 alpha: 32.607749936715514\n",
      "timeframe: 1 section: 76 alpha: 79.05759487495897\n",
      "timeframe: 0 section: 549 alpha: 2.1821508769560327\n",
      "timeframe: 0 section: 352 alpha: 19.992369147477923\n",
      "timeframe: 0 section: 142 alpha: 18.2751723447653\n",
      "timeframe: 0 section: 156 alpha: 26.93666510595105\n",
      "timeframe: 0 section: 318 alpha: 15.622491963920872\n",
      "timeframe: 0 section: 66 alpha: 14.473678461013426\n",
      "timeframe: 1 section: 111 alpha: 19.1117776759859\n",
      "timeframe: 1 section: 41 alpha: 35.017684524936975\n",
      "timeframe: 0 section: 366 alpha: 36.39202782511218\n",
      "timeframe: 0 section: 164 alpha: 12.297781269774962\n",
      "timeframe: 1 section: 62 alpha: 18.797030081684976\n",
      "timeframe: 0 section: 213 alpha: 17.697339366825787\n",
      "timeframe: 0 section: 311 alpha: 40.81803298734798\n",
      "timeframe: 0 section: 408 alpha: 39.77331073667344\n",
      "timeframe: 0 section: 507 alpha: 88.64328998640032\n",
      "timeframe: 0 section: 234 alpha: 40.07663765927286\n",
      "timeframe: 0 section: 94 alpha: 21.795617909282335\n",
      "timeframe: 1 section: 27 alpha: 18.80160335360486\n",
      "timeframe: 0 section: 122 alpha: 22.297137104743577\n",
      "timeframe: 0 section: 276 alpha: 14.784297375441975\n",
      "timeframe: 1 section: 104 alpha: 23.34571393793821\n",
      "timeframe: 1 section: 48 alpha: 12.618598159246046\n",
      "timeframe: 1 section: 69 alpha: 11.192040446440512\n",
      "timeframe: 0 section: 332 alpha: 15.995368829775291\n",
      "timeframe: 0 section: 465 alpha: 40.17202709864032\n",
      "timeframe: 0 section: 458 alpha: 32.97192976612135\n",
      "timeframe: 0 section: 178 alpha: 33.01993940683001\n",
      "timeframe: 0 section: 325 alpha: 34.47501391178016\n",
      "timeframe: 0 section: 479 alpha: 12.297820470610217\n",
      "timeframe: 0 section: 437 alpha: 20.791263585891798\n",
      "timeframe: 1 section: 90 alpha: 38.158634611924555\n",
      "timeframe: 0 section: 521 alpha: 44.175433814935936\n",
      "timeframe: 0 section: 282 alpha: 36.06755778477166\n",
      "timeframe: 0 section: 108 alpha: 15.69049171474496\n",
      "timeframe: 0 section: 388 alpha: 12.730093246437686\n",
      "timeframe: 0 section: 87 alpha: 47.788657376930566\n",
      "timeframe: 0 section: 18 alpha: 5.333857113449612\n",
      "timeframe: 0 section: 444 alpha: 16.699969251808998\n",
      "timeframe: 0 section: 199 alpha: 13.193533217675032\n",
      "timeframe: 1 section: 35 alpha: 30.531133586893464\n",
      "timeframe: 0 section: 472 alpha: 37.89983941340852\n",
      "timeframe: 0 section: 136 alpha: 20.601022636277577\n",
      "timeframe: 1 section: 97 alpha: 22.2318726096383\n",
      "timeframe: 0 section: 206 alpha: 22.23871260271625\n",
      "timeframe: 0 section: 402 alpha: 23.039522043207867\n",
      "timeframe: 0 section: 430 alpha: 4.362116102641049\n",
      "timeframe: 0 section: 60 alpha: 3.4874140904304594\n",
      "timeframe: 0 section: 81 alpha: 9.781111926171796\n",
      "timeframe: 0 section: 4 alpha: 0.8521235866326837\n",
      "timeframe: 0 section: 395 alpha: 29.510890732152927\n",
      "timeframe: 0 section: 53 alpha: 29.621952177591957\n",
      "timeframe: 0 section: 339 alpha: 9.977241017663962\n",
      "timeframe: 0 section: 115 alpha: 74.7703822054687\n",
      "timeframe: 0 section: 39 alpha: 12.031588595372716\n",
      "timeframe: 0 section: 192 alpha: 15.974558149112411\n",
      "timeframe: 1 section: 14 alpha: 17.058596065057866\n",
      "timeframe: 0 section: 514 alpha: 19.67920231589246\n",
      "timeframe: 0 section: 535 alpha: 26.783791897705374\n",
      "timeframe: 0 section: 297 alpha: 11.505398348987239\n",
      "timeframe: 0 section: 493 alpha: 37.18610409313447\n",
      "timeframe: 1 section: 56 alpha: 14.839924043756211\n",
      "timeframe: 0 section: 346 alpha: 20.71330303585436\n",
      "timeframe: 0 section: 360 alpha: 8.077384839017691\n",
      "timeframe: 0 section: 269 alpha: 66.98823927076197\n",
      "timeframe: 0 section: 129 alpha: 30.824812667886906\n",
      "timeframe: 0 section: 423 alpha: 25.048559171950718\n",
      "timeframe: 0 section: 416 alpha: 28.102045915049345\n",
      "timeframe: 0 section: 101 alpha: 29.65951122496461\n",
      "timeframe: 0 section: 542 alpha: 25.556875987432427\n",
      "timeframe: 1 section: 133 alpha: 48.50826833160386\n",
      "timeframe: 0 section: 25 alpha: 34.94624806739945\n",
      "timeframe: 0 section: 500 alpha: 11.280245496751549\n",
      "timeframe: 0 section: 486 alpha: 13.180445325764229\n",
      "timeframe: 0 section: 262 alpha: 33.096812113302555\n",
      "timeframe: 0 section: 74 alpha: 14.252889823690689\n",
      "timeframe: 0 section: 248 alpha: 13.93443047481191\n",
      "timeframe: 0 section: 11 alpha: 17.335455558122117\n",
      "timeframe: 0 section: 32 alpha: 59.389558145323726\n",
      "timeframe: 0 section: 67 alpha: 2.9181537436306346\n",
      "timeframe: 0 section: 381 alpha: 19.588233791165976\n",
      "timeframe: 0 section: 319 alpha: 26.259642780542688\n",
      "timeframe: 0 section: 46 alpha: 14.305882842093116\n",
      "timeframe: 0 section: 150 alpha: 27.167390035442587\n",
      "timeframe: 1 section: 21 alpha: 24.416764016253893\n",
      "timeframe: 0 section: 143 alpha: 17.569760189845454\n",
      "timeframe: 0 section: 304 alpha: 70.25733988309656\n",
      "timeframe: 0 section: 528 alpha: 26.885216448665282\n",
      "timeframe: 0 section: 290 alpha: 19.236484675028446\n",
      "timeframe: 0 section: 171 alpha: 23.70611333614323\n",
      "timeframe: 1 section: 7 alpha: 35.32328424503377\n",
      "timeframe: 0 section: 220 alpha: 22.880924392927994\n",
      "timeframe: 0 section: 375 alpha: 13.472860149160427\n",
      "timeframe: 0 section: 353 alpha: 20.768984804300803\n",
      "timeframe: 1 section: 49 alpha: 13.69203789556921\n",
      "timeframe: 0 section: 241 alpha: 26.967255170966503\n",
      "timeframe: 0 section: 186 alpha: 25.78138685218782\n",
      "timeframe: 0 section: 228 alpha: 37.75090335453348\n",
      "timeframe: 0 section: 157 alpha: 17.387450731591553\n",
      "timeframe: 1 section: 126 alpha: 10.77244172307615\n",
      "timeframe: 0 section: 123 alpha: 55.47865001072553\n",
      "timeframe: 0 section: 550 alpha: 29.65638538891922\n",
      "timeframe: 0 section: 452 alpha: 37.87984534846002\n",
      "timeframe: 1 section: 105 alpha: 15.1660614431096\n",
      "timeframe: 0 section: 367 alpha: 24.962721067434273\n",
      "timeframe: 1 section: 77 alpha: 26.928059515716374\n",
      "timeframe: 0 section: 255 alpha: 92.62678336139977\n",
      "timeframe: 0 section: 277 alpha: 64.37807089419051\n",
      "timeframe: 0 section: 522 alpha: 12.48452883362626\n",
      "timeframe: 0 section: 480 alpha: 8.137920129755669\n",
      "timeframe: 0 section: 409 alpha: 25.68921561520709\n",
      "timeframe: 0 section: 459 alpha: 60.009281702311135\n",
      "timeframe: 0 section: 389 alpha: 4.138461975957951\n",
      "timeframe: 0 section: 19 alpha: 9.616290303303197\n",
      "timeframe: 0 section: 95 alpha: 10.725264690777745\n",
      "timeframe: 0 section: 137 alpha: 0.8610270731158133\n",
      "timeframe: 0 section: 431 alpha: 7.146127336676015\n",
      "timeframe: 1 section: 0 alpha: 25.09782652553778\n",
      "timeframe: 1 section: 42 alpha: 10.96036202104601\n",
      "timeframe: 0 section: 445 alpha: 6.423621548602475\n",
      "timeframe: 0 section: 508 alpha: 12.368546643304995\n",
      "timeframe: 0 section: 214 alpha: 17.473863217263546\n",
      "timeframe: 0 section: 438 alpha: 23.473023089093243\n",
      "timeframe: 1 section: 36 alpha: 43.889382374478515\n",
      "timeframe: 0 section: 333 alpha: 14.813063678288644\n",
      "timeframe: 1 section: 84 alpha: 40.42353331683037\n",
      "timeframe: 0 section: 312 alpha: 25.146662239087632\n",
      "timeframe: 0 section: 283 alpha: 50.30391065491235\n",
      "timeframe: 0 section: 235 alpha: 26.86304149934419\n",
      "timeframe: 0 section: 179 alpha: 13.57037887590443\n",
      "timeframe: 1 section: 119 alpha: 12.141523391168473\n",
      "timeframe: 0 section: 473 alpha: 9.665291139719905\n",
      "timeframe: 1 section: 140 alpha: 31.435762849892686\n",
      "timeframe: 0 section: 61 alpha: 21.487940769421744\n",
      "timeframe: 1 section: 63 alpha: 25.013003490862168\n",
      "timeframe: 0 section: 396 alpha: 56.33831298826988\n",
      "timeframe: 0 section: 200 alpha: 21.85495608504827\n",
      "timeframe: 0 section: 165 alpha: 40.83479922120751\n",
      "timeframe: 0 section: 466 alpha: 40.86747995114278\n",
      "timeframe: 0 section: 88 alpha: 28.752806002492136\n",
      "timeframe: 1 section: 28 alpha: 25.055780439252793\n",
      "timeframe: 0 section: 82 alpha: 6.401721963602635\n",
      "timeframe: 0 section: 193 alpha: 8.155572673365565\n",
      "timeframe: 0 section: 249 alpha: 0.1954745577339185\n",
      "timeframe: 0 section: 340 alpha: 35.82787265349992\n",
      "timeframe: 0 section: 536 alpha: 91.60669402432343\n",
      "timeframe: 0 section: 270 alpha: 6.924190783023239\n",
      "timeframe: 0 section: 403 alpha: 20.324298806621854\n",
      "timeframe: 0 section: 130 alpha: 48.714246230795396\n",
      "timeframe: 0 section: 116 alpha: 37.03476924347884\n",
      "timeframe: 1 section: 112 alpha: 14.342782531054414\n",
      "timeframe: 0 section: 326 alpha: 24.634381097845267\n",
      "timeframe: 0 section: 298 alpha: 8.679284487395268\n",
      "timeframe: 1 section: 91 alpha: 28.665922747632784\n",
      "timeframe: 0 section: 424 alpha: 19.079456619122052\n",
      "timeframe: 0 section: 102 alpha: 20.380881161636392\n",
      "timeframe: 0 section: 417 alpha: 8.193266049574614\n",
      "timeframe: 0 section: 5 alpha: 19.46907812412813\n",
      "timeframe: 1 section: 15 alpha: 42.908909412422545\n",
      "timeframe: 0 section: 207 alpha: 30.03009678846125\n",
      "timeframe: 0 section: 494 alpha: 20.773236556327852\n",
      "timeframe: 0 section: 109 alpha: 18.893018236178488\n",
      "timeframe: 0 section: 543 alpha: 25.37616529167296\n",
      "timeframe: 0 section: 347 alpha: 9.799675840453173\n",
      "timeframe: 0 section: 361 alpha: 40.344091730633565\n",
      "timeframe: 1 section: 70 alpha: 20.198978129679098\n",
      "timeframe: 0 section: 151 alpha: 19.46661961467611\n",
      "timeframe: 0 section: 487 alpha: 19.336456179110666\n",
      "timeframe: 0 section: 54 alpha: 15.500050722220255\n",
      "timeframe: 0 section: 501 alpha: 79.18686431845617\n",
      "timeframe: 0 section: 40 alpha: 30.58619474849357\n",
      "timeframe: 0 section: 47 alpha: 15.681298285399913\n",
      "timeframe: 0 section: 515 alpha: 26.92655814988586\n",
      "timeframe: 0 section: 529 alpha: 15.984476782724668\n",
      "timeframe: 0 section: 26 alpha: 19.5315527879777\n",
      "timeframe: 0 section: 75 alpha: 19.74183852453506\n",
      "timeframe: 0 section: 263 alpha: 33.94807656075707\n",
      "timeframe: 0 section: 305 alpha: 42.18464286193106\n",
      "timeframe: 1 section: 98 alpha: 37.808969081998484\n",
      "timeframe: 0 section: 158 alpha: 22.573943732811795\n",
      "timeframe: 0 section: 242 alpha: 4.012310928701355\n",
      "timeframe: 0 section: 68 alpha: 14.271813072995455\n",
      "timeframe: 1 section: 50 alpha: 25.26308780259527\n",
      "timeframe: 0 section: 376 alpha: 22.55366364903583\n",
      "timeframe: 0 section: 382 alpha: 22.953950437427554\n",
      "timeframe: 0 section: 291 alpha: 27.803004929335017\n",
      "timeframe: 0 section: 172 alpha: 23.678578889362857\n",
      "timeframe: 0 section: 221 alpha: 28.285580500283533\n",
      "timeframe: 0 section: 33 alpha: 31.845371929030833\n",
      "timeframe: 0 section: 144 alpha: 17.875817099415016\n",
      "timeframe: 1 section: 57 alpha: 14.434219696351052\n",
      "timeframe: 0 section: 523 alpha: 24.021552301231885\n",
      "timeframe: 0 section: 354 alpha: 14.16390903193974\n",
      "timeframe: 0 section: 229 alpha: 22.527364758828465\n",
      "timeframe: 0 section: 187 alpha: 33.34525270619039\n",
      "timeframe: 0 section: 320 alpha: 16.048026577851033\n",
      "timeframe: 0 section: 20 alpha: 26.038648247282893\n",
      "timeframe: 0 section: 124 alpha: 35.576908347132246\n",
      "timeframe: 0 section: 12 alpha: 34.99185798143643\n",
      "timeframe: 1 section: 134 alpha: 39.46522174686381\n",
      "timeframe: 0 section: 432 alpha: 12.884803534402101\n",
      "timeframe: 0 section: 439 alpha: 25.833232440358973\n",
      "timeframe: 0 section: 278 alpha: 19.4049478799567\n",
      "timeframe: 1 section: 22 alpha: 14.000620064890459\n",
      "timeframe: 0 section: 138 alpha: 17.60545457328073\n",
      "timeframe: 0 section: 446 alpha: 20.994331653964394\n",
      "timeframe: 0 section: 368 alpha: 40.100155027260826\n",
      "timeframe: 0 section: 509 alpha: 11.865442465892077\n",
      "timeframe: 0 section: 62 alpha: 25.775211886945595\n",
      "timeframe: 0 section: 215 alpha: 22.364680027380615\n",
      "timeframe: 0 section: 256 alpha: 52.38976569785\n",
      "timeframe: 0 section: 83 alpha: 15.427534968867965\n",
      "timeframe: 0 section: 551 alpha: 16.200237896859473\n",
      "timeframe: 0 section: 96 alpha: 18.386165464480378\n",
      "timeframe: 0 section: 474 alpha: 30.231553195096584\n",
      "timeframe: 1 section: 127 alpha: 8.738840558651274\n",
      "timeframe: 0 section: 284 alpha: 20.891310715835186\n",
      "timeframe: 0 section: 410 alpha: 8.081523502880763\n",
      "timeframe: 0 section: 460 alpha: 13.265576807487403\n",
      "timeframe: 1 section: 120 alpha: 27.905306837149272\n",
      "timeframe: 0 section: 481 alpha: 27.37300061507442\n",
      "timeframe: 1 section: 16 alpha: 16.148961963192015\n",
      "timeframe: 0 section: 313 alpha: 31.683185475050173\n",
      "timeframe: 0 section: 341 alpha: 6.318006655482067\n",
      "timeframe: 0 section: 166 alpha: 26.980115484615517\n",
      "timeframe: 0 section: 397 alpha: 32.87893388481517\n",
      "timeframe: 0 section: 180 alpha: 20.214214143370892\n",
      "timeframe: 1 section: 106 alpha: 27.20399754058622\n",
      "timeframe: 1 section: 43 alpha: 18.28832011550916\n",
      "timeframe: 0 section: 334 alpha: 32.719422773224245\n",
      "timeframe: 0 section: 467 alpha: 18.678990772339723\n",
      "timeframe: 0 section: 271 alpha: 22.418868673931968\n",
      "timeframe: 0 section: 453 alpha: 27.137075422317633\n",
      "timeframe: 0 section: 390 alpha: 28.278866060141414\n",
      "timeframe: 0 section: 6 alpha: 18.935886810659575\n",
      "timeframe: 1 section: 64 alpha: 27.212020555638965\n",
      "timeframe: 0 section: 250 alpha: 64.32383026719067\n",
      "timeframe: 0 section: 131 alpha: 19.72972112931785\n",
      "timeframe: 0 section: 502 alpha: 18.168910557918053\n",
      "timeframe: 0 section: 208 alpha: 1.6923644575731287\n",
      "timeframe: 0 section: 362 alpha: 28.46872787914899\n",
      "timeframe: 0 section: 194 alpha: 10.135269488014105\n",
      "timeframe: 0 section: 110 alpha: 19.957997183283876\n",
      "timeframe: 0 section: 236 alpha: 21.661995557220035\n",
      "timeframe: 0 section: 537 alpha: 14.8443413921493\n",
      "timeframe: 0 section: 327 alpha: 16.58096064204818\n",
      "timeframe: 0 section: 117 alpha: 22.050037364363686\n",
      "timeframe: 0 section: 103 alpha: 24.21219963272812\n",
      "timeframe: 1 section: 8 alpha: 7.211955034284505\n",
      "timeframe: 0 section: 152 alpha: 21.841604473762104\n",
      "timeframe: 1 section: 141 alpha: 37.14868013211017\n",
      "timeframe: 1 section: 85 alpha: 29.16289327175018\n",
      "timeframe: 0 section: 201 alpha: 26.466697791972358\n",
      "timeframe: 0 section: 425 alpha: 27.920529763975242\n",
      "timeframe: 0 section: 34 alpha: 55.69182143316209\n",
      "timeframe: 0 section: 243 alpha: 22.67706299412238\n",
      "timeframe: 0 section: 264 alpha: 35.095378205626986\n",
      "timeframe: 1 section: 29 alpha: 17.1726205148558\n",
      "timeframe: 0 section: 159 alpha: 13.474916393182257\n",
      "timeframe: 1 section: 1 alpha: 19.373227740930815\n",
      "timeframe: 0 section: 55 alpha: 87.47755814914147\n",
      "timeframe: 1 section: 37 alpha: 8.168785122795782\n",
      "timeframe: 1 section: 78 alpha: 32.38372425464863\n",
      "timeframe: 0 section: 418 alpha: 26.80449172589117\n",
      "timeframe: 0 section: 89 alpha: 45.31326484266015\n",
      "timeframe: 0 section: 544 alpha: 16.726845957125306\n",
      "timeframe: 0 section: 495 alpha: 49.76223527139441\n",
      "timeframe: 0 section: 488 alpha: 31.22568129683449\n",
      "timeframe: 0 section: 299 alpha: 20.7447252169363\n",
      "timeframe: 0 section: 306 alpha: 16.777442239874368\n",
      "timeframe: 1 section: 51 alpha: 13.836438885807826\n",
      "timeframe: 0 section: 348 alpha: 27.39947485409257\n",
      "timeframe: 1 section: 92 alpha: 22.75764364156772\n",
      "timeframe: 0 section: 173 alpha: 15.00600669288422\n",
      "timeframe: 0 section: 377 alpha: 35.642822096958156\n",
      "timeframe: 0 section: 440 alpha: 41.62784253802792\n",
      "timeframe: 0 section: 41 alpha: 33.445866585873816\n",
      "timeframe: 0 section: 292 alpha: 29.574927918045304\n",
      "timeframe: 0 section: 48 alpha: 10.091756603458617\n",
      "timeframe: 0 section: 69 alpha: 13.734443194038247\n",
      "timeframe: 1 section: 113 alpha: 16.85374768460191\n",
      "timeframe: 0 section: 383 alpha: 11.553000475230311\n",
      "timeframe: 0 section: 404 alpha: 19.398760554340047\n",
      "timeframe: 0 section: 321 alpha: 37.25102845019099\n",
      "timeframe: 0 section: 125 alpha: 20.539690577475827\n",
      "timeframe: 0 section: 530 alpha: 45.76871684188496\n",
      "timeframe: 0 section: 230 alpha: 13.44698832556615\n",
      "timeframe: 0 section: 342 alpha: 24.764131806941915\n",
      "timeframe: 0 section: 524 alpha: 16.19414897424433\n",
      "timeframe: 0 section: 145 alpha: 15.385775190816833\n",
      "timeframe: 0 section: 222 alpha: 30.389008512622777\n",
      "timeframe: 0 section: 355 alpha: 16.622950625839046\n",
      "timeframe: 0 section: 76 alpha: 31.75453123029986\n",
      "timeframe: 0 section: 433 alpha: 29.476700752931013\n",
      "timeframe: 1 section: 71 alpha: 49.01808535562791\n",
      "timeframe: 0 section: 257 alpha: 18.90126431319667\n",
      "timeframe: 1 section: 23 alpha: 36.03334766623373\n",
      "timeframe: 0 section: 181 alpha: 23.649356293221853\n",
      "timeframe: 0 section: 391 alpha: 0.8911118937307172\n",
      "timeframe: 0 section: 285 alpha: 25.551548661786562\n",
      "timeframe: 0 section: 216 alpha: 31.065454900860228\n",
      "timeframe: 0 section: 97 alpha: 27.152957684616137\n",
      "timeframe: 0 section: 279 alpha: 21.72199270578258\n",
      "timeframe: 0 section: 447 alpha: 15.02146012100537\n",
      "timeframe: 0 section: 188 alpha: 16.75281562731036\n",
      "timeframe: 1 section: 144 alpha: 16.92320502081457\n",
      "timeframe: 0 section: 139 alpha: 12.59974639162361\n",
      "timeframe: 0 section: 369 alpha: 13.684979044993879\n",
      "timeframe: 0 section: 468 alpha: 25.572620628510812\n",
      "timeframe: 0 section: 461 alpha: 39.19950910971355\n",
      "timeframe: 0 section: 552 alpha: 36.59191054119697\n",
      "timeframe: 1 section: 128 alpha: 19.25148483931938\n",
      "timeframe: 1 section: 99 alpha: 6.555002565140548\n",
      "timeframe: 0 section: 516 alpha: 20.108147676667997\n",
      "timeframe: 0 section: 314 alpha: 8.88596254568124\n",
      "timeframe: 1 section: 151 alpha: 30.506861254390945\n",
      "timeframe: 0 section: 209 alpha: 13.119538696051263\n",
      "timeframe: 0 section: 27 alpha: 13.863322890024671\n",
      "timeframe: 0 section: 398 alpha: 15.261556820687382\n",
      "timeframe: 0 section: 104 alpha: 12.099464228689687\n",
      "timeframe: 0 section: 13 alpha: 35.13995965933177\n",
      "timeframe: 0 section: 475 alpha: 11.452935110086667\n",
      "timeframe: 0 section: 482 alpha: 16.4380497306168\n",
      "timeframe: 0 section: 167 alpha: 10.522444597356264\n",
      "timeframe: 0 section: 510 alpha: 10.6087240725613\n",
      "timeframe: 1 section: 121 alpha: 43.49558751258135\n",
      "timeframe: 1 section: 158 alpha: 39.22275645364219\n",
      "timeframe: 1 section: 135 alpha: 20.86052939847719\n",
      "timeframe: 0 section: 363 alpha: 23.469063109795563\n",
      "timeframe: 0 section: 195 alpha: 16.597360524340264\n",
      "timeframe: 0 section: 153 alpha: 16.556832984695927\n",
      "timeframe: 0 section: 411 alpha: 8.610732260826511\n",
      "timeframe: 1 section: 58 alpha: 13.262649019482682\n",
      "timeframe: 0 section: 272 alpha: 31.05790411178807\n",
      "timeframe: 1 section: 107 alpha: 31.543505881736856\n",
      "timeframe: 0 section: 454 alpha: 21.350843900424934\n",
      "timeframe: 1 section: 93 alpha: 20.349427465592264\n",
      "timeframe: 0 section: 328 alpha: 23.87838861841318\n",
      "timeframe: 0 section: 419 alpha: 18.447917784422994\n",
      "timeframe: 0 section: 349 alpha: 5.619612693781422\n",
      "timeframe: 1 section: 9 alpha: 12.563437359901789\n",
      "timeframe: 1 section: 142 alpha: 10.988630754797887\n",
      "timeframe: 0 section: 503 alpha: 20.522921019265375\n",
      "timeframe: 1 section: 17 alpha: 25.595639559437334\n",
      "timeframe: 0 section: 545 alpha: 45.08568265363842\n",
      "timeframe: 0 section: 293 alpha: 36.79810116418487\n",
      "timeframe: 1 section: 114 alpha: 20.869784372876875\n",
      "timeframe: 0 section: 426 alpha: 23.39236386448617\n",
      "timeframe: 1 section: 249 alpha: 11.387678382619882\n",
      "timeframe: 0 section: 237 alpha: 41.643810669136464\n",
      "timeframe: 0 section: 244 alpha: 19.72325561092547\n",
      "timeframe: 0 section: 111 alpha: 21.7094081129875\n",
      "timeframe: 1 section: 65 alpha: 39.77884847588231\n",
      "timeframe: 0 section: 265 alpha: 15.64782626566218\n",
      "timeframe: 0 section: 174 alpha: 29.705176003306338\n",
      "timeframe: 0 section: 160 alpha: 43.43574716589579\n",
      "timeframe: 1 section: 30 alpha: 27.945416979323205\n",
      "timeframe: 1 section: 165 alpha: 31.816482197842564\n",
      "timeframe: 0 section: 118 alpha: 13.855224113325349\n",
      "timeframe: 0 section: 300 alpha: 51.46278131339344\n",
      "timeframe: 0 section: 335 alpha: 40.754332319537376\n",
      "timeframe: 1 section: 86 alpha: 22.14124560836582\n",
      "timeframe: 1 section: 193 alpha: 22.4297709147441\n",
      "timeframe: 1 section: 44 alpha: 25.640829979406302\n",
      "timeframe: 0 section: 202 alpha: 32.09028189814775\n",
      "timeframe: 0 section: 251 alpha: 38.56112568726233\n",
      "timeframe: 1 section: 38 alpha: 20.257125127839654\n",
      "timeframe: 0 section: 307 alpha: 20.552627856581196\n",
      "timeframe: 0 section: 90 alpha: 41.91844692934602\n",
      "timeframe: 0 section: 132 alpha: 30.880656000645303\n",
      "timeframe: 0 section: 531 alpha: 28.21353970686085\n",
      "timeframe: 1 section: 79 alpha: 18.80453607109749\n",
      "timeframe: 0 section: 223 alpha: 10.004141529070287\n",
      "timeframe: 0 section: 496 alpha: 33.75503480022528\n",
      "timeframe: 0 section: 538 alpha: 17.127185000865126\n",
      "timeframe: 0 section: 370 alpha: 11.889184633109226\n",
      "timeframe: 0 section: 489 alpha: 29.48816201014133\n",
      "timeframe: 0 section: 286 alpha: 21.352689785062797\n",
      "timeframe: 1 section: 145 alpha: 13.540598822040717\n",
      "timeframe: 0 section: 356 alpha: 22.587797695461152\n",
      "timeframe: 0 section: 405 alpha: 24.013665271071122\n",
      "timeframe: 1 section: 242 alpha: 15.07556426495751\n",
      "timeframe: 1 section: 179 alpha: 24.137672016960135\n",
      "timeframe: 0 section: 146 alpha: 15.104100774933361\n",
      "timeframe: 1 section: 389 alpha: 3.9833061053574386\n",
      "timeframe: 1 section: 52 alpha: 74.00428406648139\n",
      "timeframe: 1 section: 263 alpha: 22.608742287644198\n",
      "timeframe: 1 section: 207 alpha: 49.52145077560852\n",
      "timeframe: 0 section: 258 alpha: 27.135142075211075\n",
      "timeframe: 1 section: 375 alpha: 19.33413588281447\n",
      "timeframe: 0 section: 384 alpha: 32.098589077848445\n",
      "timeframe: 1 section: 186 alpha: 23.67378731317843\n",
      "timeframe: 1 section: 24 alpha: 15.97926775885603\n",
      "timeframe: 1 section: 228 alpha: 17.81902572934988\n",
      "timeframe: 1 section: 235 alpha: 15.830759887234422\n",
      "timeframe: 1 section: 221 alpha: 22.44555872633176\n",
      "timeframe: 1 section: 431 alpha: 13.967558442295292\n",
      "timeframe: 1 section: 333 alpha: 23.201170440253517\n",
      "timeframe: 1 section: 277 alpha: 11.958521012388921\n",
      "timeframe: 1 section: 319 alpha: 28.468928366780922\n",
      "timeframe: 1 section: 214 alpha: 14.396039088827424\n",
      "timeframe: 1 section: 256 alpha: 36.33244290721126\n",
      "timeframe: 1 section: 340 alpha: 36.68659007381494\n",
      "timeframe: 1 section: 10 alpha: 17.15063896572458\n",
      "timeframe: 1 section: 298 alpha: 5.896377196185812\n",
      "timeframe: 1 section: 326 alpha: 8.439509938358846\n",
      "timeframe: 0 section: 517 alpha: 14.960620335635403\n",
      "timeframe: 1 section: 2 alpha: 27.361871787431316\n",
      "timeframe: 1 section: 312 alpha: 21.037012450859866\n",
      "timeframe: 1 section: 200 alpha: 22.486722947263296\n",
      "timeframe: 1 section: 305 alpha: 41.507233849266036\n",
      "timeframe: 1 section: 270 alpha: 16.775094602154546\n",
      "timeframe: 1 section: 172 alpha: 20.551737036585592\n",
      "timeframe: 1 section: 424 alpha: 30.120651647503095\n",
      "timeframe: 1 section: 250 alpha: 43.78733036297901\n",
      "timeframe: 1 section: 445 alpha: 19.87142773780565\n",
      "timeframe: 0 section: 412 alpha: 11.039004403867827\n",
      "timeframe: 1 section: 159 alpha: 10.056558574446662\n",
      "timeframe: 1 section: 347 alpha: 22.01483718487715\n",
      "timeframe: 1 section: 508 alpha: 14.549716035747176\n",
      "timeframe: 1 section: 459 alpha: 36.33529881508791\n",
      "timeframe: 1 section: 438 alpha: 38.12585402525519\n",
      "timeframe: 1 section: 466 alpha: 31.51829046060011\n",
      "timeframe: 1 section: 108 alpha: 14.429249341200922\n",
      "timeframe: 1 section: 417 alpha: 19.891017442749277\n",
      "timeframe: 1 section: 368 alpha: 20.65936489067903\n",
      "timeframe: 1 section: 122 alpha: 16.951475080371125\n",
      "timeframe: 1 section: 354 alpha: 15.174406407087652\n",
      "timeframe: 1 section: 284 alpha: 24.979346696364367\n",
      "timeframe: 1 section: 487 alpha: 24.05236665674178\n",
      "timeframe: 1 section: 59 alpha: 14.85692686170478\n",
      "timeframe: 1 section: 494 alpha: 46.148065453739456\n",
      "timeframe: 1 section: 403 alpha: 51.0920091657469\n",
      "timeframe: 1 section: 129 alpha: 37.85474921299264\n",
      "timeframe: 2 section: 15 alpha: 53.089146540349724\n",
      "timeframe: 1 section: 143 alpha: 13.314436805884322\n",
      "timeframe: 1 section: 72 alpha: 10.938399604099002\n",
      "timeframe: 1 section: 522 alpha: 32.51248657663508\n",
      "timeframe: 1 section: 194 alpha: 18.580842244484398\n",
      "timeframe: 1 section: 452 alpha: 32.30164821335314\n",
      "timeframe: 2 section: 50 alpha: 33.37385657185193\n",
      "timeframe: 1 section: 480 alpha: 33.37248437127777\n",
      "timeframe: 1 section: 382 alpha: 20.062811967570727\n",
      "timeframe: 1 section: 152 alpha: 26.0348093876808\n",
      "timeframe: 1 section: 410 alpha: 16.892722774453826\n",
      "timeframe: 1 section: 361 alpha: 31.461412211249737\n",
      "timeframe: 1 section: 94 alpha: 25.31539834507249\n",
      "timeframe: 1 section: 264 alpha: 10.008458790546696\n",
      "timeframe: 1 section: 136 alpha: 14.89843962645163\n",
      "timeframe: 1 section: 396 alpha: 34.74664998164273\n",
      "timeframe: 1 section: 291 alpha: 22.198267882560955\n",
      "timeframe: 1 section: 501 alpha: 35.460603294510406\n",
      "timeframe: 1 section: 100 alpha: 10.315171005418367\n",
      "timeframe: 1 section: 45 alpha: 11.917950629976193\n",
      "timeframe: 1 section: 390 alpha: 29.64606879436351\n",
      "timeframe: 1 section: 550 alpha: 21.490683796414018\n",
      "timeframe: 1 section: 80 alpha: 13.71061176008325\n",
      "timeframe: 1 section: 31 alpha: 42.460890302315576\n",
      "timeframe: 1 section: 115 alpha: 58.82818969878794\n",
      "timeframe: 1 section: 432 alpha: 39.51531538330543\n",
      "timeframe: 1 section: 166 alpha: 23.296277332165207\n",
      "timeframe: 1 section: 543 alpha: 28.546188545473488\n",
      "timeframe: 2 section: 36 alpha: 25.46624766857692\n",
      "timeframe: 2 section: 148 alpha: 28.500313101884558\n",
      "timeframe: 1 section: 87 alpha: 44.44728485743864\n",
      "timeframe: 1 section: 529 alpha: 22.63069599708301\n",
      "timeframe: 1 section: 473 alpha: 15.098461193356234\n",
      "timeframe: 1 section: 515 alpha: 59.99416595487786\n",
      "timeframe: 2 section: 120 alpha: 37.735426072552634\n",
      "timeframe: 1 section: 257 alpha: 10.361675037398893\n",
      "timeframe: 1 section: 146 alpha: 11.307814015620224\n",
      "timeframe: 1 section: 180 alpha: 27.07097425580682\n",
      "timeframe: 2 section: 127 alpha: 32.176976529077905\n",
      "timeframe: 2 section: 22 alpha: 11.617103711272716\n",
      "timeframe: 1 section: 66 alpha: 19.39176460557516\n",
      "timeframe: 2 section: 57 alpha: 15.376055186493204\n",
      "timeframe: 2 section: 78 alpha: 8.91833997766649\n",
      "timeframe: 1 section: 187 alpha: 48.711593315634026\n",
      "timeframe: 2 section: 85 alpha: 19.72348349789999\n",
      "timeframe: 1 section: 376 alpha: 27.919760957338468\n",
      "timeframe: 1 section: 536 alpha: 40.82924089187664\n",
      "timeframe: 1 section: 243 alpha: 17.26941524925068\n",
      "timeframe: 2 section: 71 alpha: 64.7921211850008\n",
      "timeframe: 2 section: 43 alpha: 20.136458927853674\n",
      "timeframe: 1 section: 229 alpha: 20.48985154715419\n",
      "timeframe: 2 section: 29 alpha: 11.329763037208998\n",
      "timeframe: 1 section: 3 alpha: 33.794494205675264\n",
      "timeframe: 1 section: 313 alpha: 24.93730238027299\n",
      "timeframe: 2 section: 106 alpha: 28.138611441906413\n",
      "timeframe: 1 section: 334 alpha: 25.58447176356574\n",
      "timeframe: 1 section: 509 alpha: 23.479507063261444\n",
      "timeframe: 2 section: 169 alpha: 32.68760003104248\n",
      "timeframe: 1 section: 251 alpha: 25.570336444908925\n",
      "timeframe: 1 section: 271 alpha: 25.02851191883562\n",
      "timeframe: 2 section: 204 alpha: 26.459562871517036\n",
      "timeframe: 1 section: 236 alpha: 28.56387935413278\n",
      "timeframe: 1 section: 460 alpha: 37.366532968593795\n",
      "timeframe: 2 section: 8 alpha: 42.497245792203856\n",
      "timeframe: 2 section: 64 alpha: 23.053638030894387\n",
      "timeframe: 1 section: 502 alpha: 7.094944579883225\n",
      "timeframe: 2 section: 155 alpha: 8.79312199359504\n",
      "timeframe: 1 section: 425 alpha: 11.392859618305668\n",
      "timeframe: 1 section: 327 alpha: 11.466001958553186\n",
      "timeframe: 1 section: 306 alpha: 30.433579255617502\n",
      "timeframe: 1 section: 369 alpha: 20.378182770349877\n",
      "timeframe: 2 section: 1 alpha: 72.95117853372078\n",
      "timeframe: 2 section: 141 alpha: 41.99147690111843\n",
      "timeframe: 1 section: 222 alpha: 41.292111708045674\n",
      "timeframe: 2 section: 92 alpha: 6.023895145415591\n",
      "timeframe: 1 section: 160 alpha: 33.16503658077746\n",
      "timeframe: 1 section: 467 alpha: 26.215442105455804\n",
      "timeframe: 1 section: 391 alpha: 12.880802752072432\n",
      "timeframe: 2 section: 16 alpha: 10.85640698207691\n",
      "timeframe: 1 section: 215 alpha: 19.66576570850203\n",
      "timeframe: 1 section: 173 alpha: 20.99718977658713\n",
      "timeframe: 1 section: 348 alpha: 33.39738212259655\n",
      "timeframe: 1 section: 383 alpha: 21.514579415961364\n",
      "timeframe: 2 section: 99 alpha: 18.71312262635136\n",
      "timeframe: 1 section: 320 alpha: 14.067339556873055\n",
      "timeframe: 2 section: 162 alpha: 14.380835057717299\n",
      "timeframe: 1 section: 201 alpha: 37.42116111178327\n",
      "timeframe: 1 section: 341 alpha: 14.089333586507394\n",
      "timeframe: 1 section: 523 alpha: 48.927495401881764\n",
      "timeframe: 1 section: 446 alpha: 20.02971766088982\n",
      "timeframe: 1 section: 404 alpha: 21.670883911647568\n",
      "timeframe: 1 section: 101 alpha: 22.804478005091383\n",
      "timeframe: 1 section: 418 alpha: 30.932346014950983\n",
      "timeframe: 1 section: 299 alpha: 20.211926050627014\n",
      "timeframe: 2 section: 51 alpha: 21.078481023320375\n",
      "timeframe: 1 section: 208 alpha: 18.986431999250023\n",
      "timeframe: 1 section: 278 alpha: 36.03508708584137\n",
      "timeframe: 1 section: 195 alpha: 22.427902860116443\n",
      "timeframe: 1 section: 439 alpha: 13.817375070242841\n",
      "timeframe: 1 section: 481 alpha: 43.15633860122796\n",
      "timeframe: 1 section: 495 alpha: 41.122716674492615\n",
      "timeframe: 2 section: 134 alpha: 29.590094593035673\n",
      "timeframe: 2 section: 113 alpha: 45.85761808404276\n",
      "timeframe: 1 section: 453 alpha: 26.641001760515607\n",
      "timeframe: 1 section: 544 alpha: 14.596383229596917\n",
      "timeframe: 1 section: 411 alpha: 12.931457822295481\n",
      "timeframe: 1 section: 285 alpha: 26.23499708069829\n",
      "timeframe: 1 section: 153 alpha: 7.475929034190987\n",
      "timeframe: 1 section: 258 alpha: 18.532221283202006\n",
      "timeframe: 1 section: 551 alpha: 26.09784163931689\n",
      "timeframe: 1 section: 292 alpha: 20.205648575214216\n",
      "timeframe: 1 section: 362 alpha: 28.669553873401068\n",
      "timeframe: 1 section: 488 alpha: 18.685070108286666\n",
      "timeframe: 2 section: 23 alpha: 12.787286553869174\n",
      "timeframe: 2 section: 37 alpha: 10.578986233950594\n",
      "timeframe: 2 section: 239 alpha: 7.630736368169255\n",
      "timeframe: 2 section: 79 alpha: 35.4846280716058\n",
      "timeframe: 1 section: 530 alpha: 30.888933765738248\n",
      "timeframe: 1 section: 516 alpha: 12.811097503569322\n",
      "timeframe: 2 section: 190 alpha: 12.238361176347995\n",
      "timeframe: 2 section: 30 alpha: 30.507120254878778\n",
      "timeframe: 2 section: 197 alpha: 21.160534816607907\n",
      "timeframe: 1 section: 167 alpha: 4.924921022167001\n",
      "timeframe: 2 section: 183 alpha: 49.502167814090214\n",
      "timeframe: 2 section: 149 alpha: 10.659812769296956\n",
      "timeframe: 2 section: 170 alpha: 24.784180999623423\n",
      "timeframe: 2 section: 232 alpha: 14.145825383742896\n",
      "timeframe: 1 section: 73 alpha: 8.812252452472505\n",
      "timeframe: 1 section: 433 alpha: 20.634362838825535\n",
      "timeframe: 1 section: 397 alpha: 40.34290942589053\n",
      "timeframe: 1 section: 537 alpha: 17.241701095953296\n",
      "timeframe: 1 section: 244 alpha: 9.643573299675488\n",
      "timeframe: 1 section: 474 alpha: 21.229045917665484\n",
      "timeframe: 1 section: 503 alpha: 42.170974403552144\n",
      "timeframe: 1 section: 188 alpha: 49.64250833967857\n",
      "timeframe: 2 section: 253 alpha: 18.427190875279052\n",
      "timeframe: 1 section: 370 alpha: 9.095530214778801\n",
      "timeframe: 1 section: 314 alpha: 9.114142196119655\n",
      "timeframe: 2 section: 218 alpha: 30.079238003607866\n",
      "timeframe: 2 section: 225 alpha: 30.28798421145836\n",
      "timeframe: 2 section: 86 alpha: 45.88051533986312\n",
      "timeframe: 1 section: 342 alpha: 4.815454609305599\n",
      "timeframe: 1 section: 328 alpha: 24.205399547999825\n",
      "timeframe: 2 section: 58 alpha: 27.149166841815696\n",
      "timeframe: 1 section: 147 alpha: 15.885764912874434\n",
      "timeframe: 1 section: 230 alpha: 20.170464514801367\n",
      "timeframe: 1 section: 524 alpha: 8.993282059508909\n",
      "timeframe: 1 section: 161 alpha: 4.371415450118129\n",
      "timeframe: 1 section: 355 alpha: 8.27769852451976\n",
      "timeframe: 1 section: 252 alpha: 26.01284938014353\n",
      "timeframe: 2 section: 267 alpha: 30.65494114885566\n",
      "timeframe: 1 section: 349 alpha: 20.22071891068231\n",
      "timeframe: 1 section: 335 alpha: 37.32915463960092\n",
      "timeframe: 1 section: 265 alpha: 4.07830105404423\n",
      "timeframe: 2 section: 9 alpha: 8.832757613866422\n",
      "timeframe: 2 section: 211 alpha: 45.87584770565356\n",
      "timeframe: 1 section: 468 alpha: 10.732157314996954\n",
      "timeframe: 2 section: 176 alpha: 16.74192863746355\n",
      "timeframe: 1 section: 426 alpha: 23.352058884580913\n",
      "timeframe: 1 section: 510 alpha: 13.613127908839047\n",
      "timeframe: 2 section: 121 alpha: 31.43481732134005\n",
      "timeframe: 1 section: 216 alpha: 23.333360446269804\n",
      "timeframe: 1 section: 405 alpha: 34.569251005910694\n",
      "timeframe: 1 section: 181 alpha: 23.601574452509233\n",
      "timeframe: 2 section: 205 alpha: 53.77529783509302\n",
      "timeframe: 1 section: 209 alpha: 3.942785851465657\n",
      "timeframe: 1 section: 237 alpha: 19.8997023872077\n",
      "timeframe: 1 section: 307 alpha: 13.368760587410641\n",
      "timeframe: 1 section: 440 alpha: 6.324850285081416\n",
      "timeframe: 2 section: 2 alpha: 25.35647139873494\n",
      "timeframe: 1 section: 174 alpha: 32.38900266945552\n",
      "timeframe: 1 section: 454 alpha: 24.17823170845762\n",
      "timeframe: 1 section: 272 alpha: 27.29583939068226\n",
      "timeframe: 1 section: 392 alpha: 16.4028082400964\n",
      "timeframe: 2 section: 246 alpha: 32.093665524171456\n",
      "timeframe: 1 section: 482 alpha: 13.729870030193897\n",
      "timeframe: 1 section: 377 alpha: 30.311575157149814\n",
      "timeframe: 1 section: 223 alpha: 37.710512147058374\n",
      "timeframe: 1 section: 321 alpha: 38.235602760775755\n",
      "timeframe: 2 section: 93 alpha: 15.995400085436199\n",
      "timeframe: 1 section: 202 alpha: 50.69527979478725\n",
      "timeframe: 2 section: 72 alpha: 8.88708828112943\n",
      "timeframe: 2 section: 156 alpha: 10.340543419947483\n",
      "timeframe: 1 section: 300 alpha: 45.235294322617946\n",
      "timeframe: 1 section: 196 alpha: 22.288006945161502\n",
      "timeframe: 2 section: 260 alpha: 10.938712278728737\n",
      "timeframe: 1 section: 447 alpha: 22.7910948289553\n",
      "timeframe: 1 section: 461 alpha: 19.89863776485899\n",
      "timeframe: 2 section: 44 alpha: 21.38954117407071\n",
      "timeframe: 1 section: 286 alpha: 44.16525638888582\n",
      "timeframe: 2 section: 100 alpha: 12.81573582444796\n",
      "timeframe: 1 section: 363 alpha: 20.78419339954445\n",
      "timeframe: 2 section: 38 alpha: 2.3470642324243425\n",
      "timeframe: 1 section: 419 alpha: 20.283387237881474\n",
      "timeframe: 1 section: 293 alpha: 41.67002513072371\n",
      "timeframe: 1 section: 154 alpha: 8.503118780292468\n",
      "timeframe: 2 section: 17 alpha: 14.301800261310925\n",
      "timeframe: 1 section: 148 alpha: 8.501501873042697\n",
      "timeframe: 1 section: 552 alpha: 20.852124361532727\n",
      "timeframe: 1 section: 279 alpha: 17.08579505236288\n",
      "timeframe: 2 section: 233 alpha: 11.672170579274908\n",
      "timeframe: 2 section: 52 alpha: 10.603928310301383\n",
      "timeframe: 2 section: 128 alpha: 27.87867899703414\n",
      "timeframe: 1 section: 315 alpha: 19.96695755741762\n",
      "timeframe: 1 section: 545 alpha: 55.755822496952405\n",
      "timeframe: 1 section: 412 alpha: 40.92656754335809\n",
      "timeframe: 1 section: 489 alpha: 20.110309761006885\n",
      "timeframe: 1 section: 371 alpha: 32.19182107258514\n",
      "timeframe: 1 section: 434 alpha: 22.276053523498234\n",
      "timeframe: 1 section: 384 alpha: 33.320128993933345\n",
      "timeframe: 2 section: 274 alpha: 4.912397290538469\n",
      "timeframe: 1 section: 259 alpha: 48.12115440739715\n",
      "timeframe: 1 section: 496 alpha: 48.82397778863603\n",
      "timeframe: 1 section: 538 alpha: 38.73466504400192\n",
      "timeframe: 1 section: 504 alpha: 10.146350939011567\n",
      "timeframe: 2 section: 24 alpha: 14.725259037727293\n",
      "timeframe: 1 section: 517 alpha: 38.13668147360264\n",
      "timeframe: 2 section: 184 alpha: 24.54564793336815\n",
      "timeframe: 1 section: 531 alpha: 57.246732492921744\n",
      "timeframe: 1 section: 398 alpha: 4.029438310157201\n",
      "timeframe: 1 section: 168 alpha: 16.41350792481189\n",
      "timeframe: 2 section: 114 alpha: 7.4572889524953405\n",
      "timeframe: 1 section: 189 alpha: 31.714358449188154\n",
      "timeframe: 2 section: 135 alpha: 5.897215945583959\n",
      "timeframe: 2 section: 107 alpha: 37.441317825638876\n",
      "timeframe: 1 section: 253 alpha: 10.276611174226508\n",
      "timeframe: 2 section: 142 alpha: 18.045348739536312\n",
      "timeframe: 1 section: 336 alpha: 37.17517187626529\n",
      "timeframe: 1 section: 245 alpha: 61.00782542928356\n",
      "timeframe: 2 section: 171 alpha: 26.939793123557774\n",
      "timeframe: 1 section: 356 alpha: 30.146086807417277\n",
      "timeframe: 1 section: 475 alpha: 15.998511757030412\n",
      "timeframe: 2 section: 191 alpha: 46.85639718342539\n",
      "timeframe: 2 section: 268 alpha: 9.690341110935655\n",
      "timeframe: 1 section: 217 alpha: 24.694424080554697\n",
      "timeframe: 1 section: 343 alpha: 21.24686003023584\n",
      "timeframe: 2 section: 10 alpha: 2.053581021521457\n",
      "timeframe: 1 section: 525 alpha: 60.67255040292375\n",
      "timeframe: 2 section: 3 alpha: 23.75939152073207\n",
      "timeframe: 1 section: 231 alpha: 16.297356798751824\n",
      "timeframe: 2 section: 240 alpha: 19.759370326362873\n",
      "timeframe: 2 section: 80 alpha: 18.2249725544339\n",
      "timeframe: 1 section: 210 alpha: 13.303861502742288\n",
      "timeframe: 1 section: 441 alpha: 30.21570682798321\n",
      "timeframe: 2 section: 65 alpha: 34.09262081521984\n",
      "timeframe: 1 section: 469 alpha: 36.168782893323744\n",
      "timeframe: 1 section: 162 alpha: 13.676149011052775\n",
      "timeframe: 2 section: 18 alpha: 41.74004414190007\n",
      "timeframe: 1 section: 393 alpha: 18.049562067204842\n",
      "timeframe: 2 section: 261 alpha: 12.509575696021717\n",
      "timeframe: 2 section: 254 alpha: 8.089487943443991\n",
      "timeframe: 1 section: 294 alpha: 19.993598631950956\n",
      "timeframe: 1 section: 301 alpha: 13.10244450328055\n",
      "timeframe: 1 section: 266 alpha: 19.921094788164343\n",
      "timeframe: 1 section: 483 alpha: 30.81939851654023\n",
      "timeframe: 2 section: 59 alpha: 13.215557409704385\n",
      "timeframe: 1 section: 511 alpha: 25.372243760519346\n",
      "timeframe: 1 section: 203 alpha: 22.071112468334313\n",
      "timeframe: 1 section: 329 alpha: 15.568352593536558\n",
      "timeframe: 1 section: 182 alpha: 25.152427433985544\n",
      "timeframe: 1 section: 273 alpha: 18.251514350231176\n",
      "timeframe: 1 section: 175 alpha: 21.186108210491817\n",
      "timeframe: 2 section: 206 alpha: 71.43026683598298\n",
      "timeframe: 1 section: 224 alpha: 25.839503046491206\n",
      "timeframe: 1 section: 406 alpha: 50.412096612171695\n",
      "timeframe: 2 section: 94 alpha: 17.2218539128019\n",
      "timeframe: 1 section: 155 alpha: 16.120322312350673\n",
      "timeframe: 1 section: 378 alpha: 5.040835672366839\n",
      "timeframe: 2 section: 281 alpha: 80.98781092276951\n",
      "timeframe: 2 section: 163 alpha: 24.016356693180285\n",
      "timeframe: 1 section: 413 alpha: 17.077876396199304\n",
      "timeframe: 2 section: 150 alpha: 36.84643048608933\n",
      "timeframe: 1 section: 287 alpha: 25.509094282314678\n",
      "timeframe: 1 section: 427 alpha: 62.110601473197214\n",
      "timeframe: 1 section: 350 alpha: 23.146104612557416\n",
      "timeframe: 1 section: 197 alpha: 21.568346491657753\n",
      "timeframe: 1 section: 455 alpha: 23.271839498160983\n",
      "timeframe: 2 section: 157 alpha: 13.37371398294266\n",
      "timeframe: 1 section: 238 alpha: 26.14836451731281\n",
      "timeframe: 1 section: 420 alpha: 12.86813260166316\n",
      "timeframe: 2 section: 31 alpha: 14.933459546798778\n",
      "timeframe: 2 section: 212 alpha: 45.883949772807114\n",
      "timeframe: 2 section: 87 alpha: 37.5140133308953\n",
      "timeframe: 2 section: 226 alpha: 43.06662308098646\n",
      "timeframe: 1 section: 553 alpha: 34.28257436116043\n",
      "timeframe: 1 section: 462 alpha: 11.554171035588366\n",
      "timeframe: 2 section: 247 alpha: 58.95416315066123\n",
      "timeframe: 1 section: 435 alpha: 10.614257395706383\n",
      "timeframe: 1 section: 322 alpha: 48.145983619415894\n",
      "timeframe: 1 section: 149 alpha: 12.128498184395921\n",
      "timeframe: 2 section: 219 alpha: 14.79500498620871\n",
      "timeframe: 2 section: 129 alpha: 27.76612538868911\n",
      "timeframe: 2 section: 198 alpha: 23.487056417942195\n",
      "timeframe: 1 section: 280 alpha: 28.775001976873035\n",
      "timeframe: 1 section: 372 alpha: 34.613426044068945\n",
      "timeframe: 1 section: 546 alpha: 18.628163072878905\n",
      "timeframe: 1 section: 490 alpha: 20.27709650989079\n",
      "timeframe: 1 section: 169 alpha: 27.182881552376372\n",
      "timeframe: 1 section: 316 alpha: 30.920265753817002\n",
      "timeframe: 1 section: 497 alpha: 30.456144554576852\n",
      "timeframe: 1 section: 448 alpha: 28.07976123890499\n",
      "timeframe: 1 section: 254 alpha: 15.294178593756506\n",
      "timeframe: 2 section: 39 alpha: 8.761482321789762\n",
      "timeframe: 2 section: 275 alpha: 10.355434506857224\n",
      "timeframe: 1 section: 385 alpha: 24.438180605399015\n",
      "timeframe: 1 section: 308 alpha: 23.77330191349095\n",
      "timeframe: 2 section: 53 alpha: 43.192524491673886\n",
      "timeframe: 2 section: 122 alpha: 20.717099107866368\n",
      "timeframe: 2 section: 177 alpha: 21.3526086949127\n",
      "timeframe: 2 section: 101 alpha: 15.902987995671147\n",
      "timeframe: 2 section: 185 alpha: 13.3116045357814\n",
      "timeframe: 2 section: 73 alpha: 0.07153162068555032\n",
      "timeframe: 1 section: 539 alpha: 9.192087416030922\n",
      "timeframe: 1 section: 337 alpha: 17.247269092343096\n",
      "timeframe: 1 section: 364 alpha: 24.430784746920953\n",
      "timeframe: 1 section: 505 alpha: 11.861622923301795\n",
      "timeframe: 1 section: 204 alpha: 30.624218533667307\n",
      "timeframe: 1 section: 532 alpha: 13.343525784721\n",
      "timeframe: 2 section: 60 alpha: 14.065476541851893\n",
      "timeframe: 2 section: 108 alpha: 15.735145998651415\n",
      "timeframe: 1 section: 512 alpha: 120.86890208097309\n",
      "timeframe: 1 section: 357 alpha: 24.988130337551702\n",
      "timeframe: 1 section: 518 alpha: 22.507641915161535\n",
      "timeframe: 2 section: 19 alpha: 52.676132198355255\n",
      "timeframe: 1 section: 476 alpha: 22.967401501239806\n",
      "timeframe: 1 section: 163 alpha: 25.557444064162958\n",
      "timeframe: 1 section: 156 alpha: 44.51081320497248\n",
      "timeframe: 1 section: 267 alpha: 142.56447040241727\n",
      "timeframe: 1 section: 232 alpha: 22.77829595034465\n",
      "timeframe: 1 section: 260 alpha: 17.037490600372255\n",
      "timeframe: 2 section: 241 alpha: 42.856216387701984\n",
      "timeframe: 1 section: 344 alpha: 14.93122629275026\n",
      "timeframe: 1 section: 399 alpha: 16.37714143318872\n",
      "timeframe: 1 section: 190 alpha: 23.854375103205342\n",
      "timeframe: 2 section: 269 alpha: 28.33989378458569\n",
      "timeframe: 1 section: 225 alpha: 23.14623905926651\n",
      "timeframe: 1 section: 526 alpha: 18.256024858318597\n",
      "timeframe: 2 section: 25 alpha: 16.440276242456633\n",
      "timeframe: 2 section: 45 alpha: 18.156538152487656\n",
      "timeframe: 1 section: 211 alpha: 27.874594270262666\n",
      "timeframe: 1 section: 246 alpha: 26.040817301285966\n",
      "timeframe: 1 section: 183 alpha: 46.4418391078833\n",
      "timeframe: 1 section: 330 alpha: 7.029213196946473\n",
      "timeframe: 2 section: 81 alpha: 13.071430971853808\n",
      "timeframe: 2 section: 66 alpha: 37.81780217199218\n",
      "timeframe: 2 section: 136 alpha: 18.37032148344595\n",
      "timeframe: 1 section: 274 alpha: 5.732065047226923\n",
      "timeframe: 1 section: 484 alpha: 30.692904151702198\n",
      "timeframe: 1 section: 414 alpha: 14.801080596445885\n",
      "timeframe: 1 section: 436 alpha: 36.740305269383406\n",
      "timeframe: 2 section: 4 alpha: 23.67583512133441\n",
      "timeframe: 1 section: 239 alpha: 23.66183664134373\n",
      "timeframe: 1 section: 407 alpha: 50.316680049677124\n",
      "timeframe: 1 section: 176 alpha: 45.72780052038666\n",
      "timeframe: 1 section: 302 alpha: 13.645826650953941\n",
      "timeframe: 1 section: 442 alpha: 13.981681948575973\n",
      "timeframe: 1 section: 456 alpha: 27.314162030387674\n",
      "timeframe: 1 section: 317 alpha: 14.433130212878922\n",
      "timeframe: 1 section: 470 alpha: 24.300985083270092\n",
      "timeframe: 1 section: 351 alpha: 32.043564393968715\n",
      "timeframe: 1 section: 295 alpha: 11.496155539094605\n",
      "timeframe: 1 section: 170 alpha: 35.94393407109937\n",
      "timeframe: 2 section: 255 alpha: 96.5499908189353\n",
      "timeframe: 2 section: 123 alpha: 31.993516440238526\n",
      "timeframe: 1 section: 218 alpha: 20.113991622729113\n",
      "timeframe: 1 section: 394 alpha: 9.146120389715412\n",
      "timeframe: 1 section: 198 alpha: 18.376252838820623\n",
      "timeframe: 2 section: 248 alpha: 34.18605440004701\n",
      "timeframe: 2 section: 95 alpha: 13.22902410045708\n",
      "timeframe: 1 section: 373 alpha: 6.8770415019107745\n",
      "timeframe: 2 section: 234 alpha: 10.594942784238949\n",
      "timeframe: 1 section: 463 alpha: 46.02515954846311\n",
      "timeframe: 1 section: 379 alpha: 7.621104495595128\n",
      "timeframe: 1 section: 554 alpha: 19.039550554985595\n",
      "timeframe: 1 section: 547 alpha: 10.976289090712488\n",
      "timeframe: 2 section: 276 alpha: 21.4855116497053\n",
      "timeframe: 1 section: 281 alpha: 29.969736645257225\n",
      "timeframe: 2 section: 32 alpha: 41.31193452152078\n",
      "timeframe: 2 section: 172 alpha: 31.344286257084775\n",
      "timeframe: 1 section: 428 alpha: 34.05827888424823\n",
      "timeframe: 1 section: 205 alpha: 28.828582651772606\n",
      "timeframe: 2 section: 192 alpha: 18.94575772079014\n",
      "timeframe: 2 section: 143 alpha: 39.70878756000179\n",
      "timeframe: 1 section: 498 alpha: 31.14895548459849\n",
      "timeframe: 1 section: 386 alpha: 26.971661162074025\n",
      "timeframe: 2 section: 74 alpha: 15.641715866624576\n",
      "timeframe: 1 section: 323 alpha: 41.94542081417378\n",
      "timeframe: 1 section: 491 alpha: 34.218230789596475\n",
      "timeframe: 1 section: 421 alpha: 20.155079845497205\n",
      "timeframe: 2 section: 151 alpha: 35.672310897676674\n",
      "timeframe: 1 section: 268 alpha: 13.41988716881941\n",
      "timeframe: 1 section: 506 alpha: 41.78069433494101\n",
      "timeframe: 2 section: 11 alpha: 7.759588768193784\n",
      "timeframe: 1 section: 255 alpha: 16.79390040518987\n",
      "timeframe: 1 section: 261 alpha: 9.28064050060248\n",
      "timeframe: 2 section: 158 alpha: 64.83802345221433\n",
      "timeframe: 2 section: 54 alpha: 21.222872434375347\n",
      "timeframe: 1 section: 513 alpha: 18.105655566977564\n",
      "timeframe: 1 section: 150 alpha: 14.401577152821044\n",
      "timeframe: 2 section: 213 alpha: 25.22386400897521\n",
      "timeframe: 1 section: 358 alpha: 7.0733007222032365\n",
      "timeframe: 1 section: 275 alpha: 0.6230566540000955\n",
      "timeframe: 1 section: 233 alpha: 3.3740516504514533\n",
      "timeframe: 2 section: 207 alpha: 27.803467777556143\n",
      "timeframe: 2 section: 164 alpha: 64.26748286517808\n",
      "timeframe: 1 section: 288 alpha: 24.089440111786576\n",
      "timeframe: 2 section: 178 alpha: 26.721670628970475\n",
      "timeframe: 2 section: 227 alpha: 19.244643965926173\n",
      "timeframe: 2 section: 242 alpha: 19.640225077544414\n",
      "timeframe: 2 section: 82 alpha: 31.872611084979972\n",
      "timeframe: 1 section: 345 alpha: 33.26009899969295\n",
      "timeframe: 1 section: 437 alpha: 19.83976225900481\n",
      "timeframe: 2 section: 262 alpha: 25.87428931966713\n",
      "timeframe: 1 section: 338 alpha: 18.80157326059433\n",
      "timeframe: 2 section: 67 alpha: 35.13432717470852\n",
      "timeframe: 1 section: 191 alpha: 27.03720720149982\n",
      "timeframe: 2 section: 130 alpha: 13.301037525042986\n",
      "timeframe: 2 section: 220 alpha: 18.726754749648926\n",
      "timeframe: 2 section: 137 alpha: 35.49480525252873\n",
      "timeframe: 1 section: 533 alpha: 24.438526027765484\n",
      "timeframe: 1 section: 365 alpha: 41.36274798167893\n",
      "timeframe: 1 section: 449 alpha: 18.045295213371617\n",
      "timeframe: 1 section: 226 alpha: 23.63085130939712\n",
      "timeframe: 2 section: 186 alpha: 44.13779558501139\n",
      "timeframe: 1 section: 485 alpha: 21.362032585289707\n",
      "timeframe: 1 section: 164 alpha: 13.090269044770753\n",
      "timeframe: 1 section: 477 alpha: 45.94546061937789\n",
      "timeframe: 1 section: 400 alpha: 3.5082662430620317\n",
      "timeframe: 1 section: 540 alpha: 25.40465717904508\n",
      "timeframe: 2 section: 61 alpha: 6.3108801601206075\n",
      "timeframe: 1 section: 519 alpha: 10.520719574759397\n",
      "timeframe: 1 section: 157 alpha: 16.79386365808232\n",
      "timeframe: 2 section: 249 alpha: 22.539482953980638\n",
      "timeframe: 1 section: 296 alpha: 15.467271387914371\n",
      "timeframe: 1 section: 247 alpha: 12.81496254020314\n",
      "timeframe: 2 section: 282 alpha: 46.69716447444952\n",
      "timeframe: 1 section: 240 alpha: 13.061099246952223\n",
      "timeframe: 2 section: 102 alpha: 43.141162385693505\n",
      "timeframe: 1 section: 380 alpha: 30.93922303305201\n",
      "timeframe: 2 section: 199 alpha: 27.085138182608127\n",
      "timeframe: 1 section: 318 alpha: 7.922723666254957\n",
      "timeframe: 1 section: 457 alpha: 24.046955738930592\n",
      "timeframe: 1 section: 309 alpha: 30.618702801928805\n",
      "timeframe: 1 section: 331 alpha: 11.393475882207799\n",
      "timeframe: 2 section: 40 alpha: 45.75192419844964\n",
      "timeframe: 1 section: 184 alpha: 39.040133221966464\n",
      "timeframe: 1 section: 507 alpha: 5.777947483662034\n",
      "timeframe: 1 section: 548 alpha: 32.80769895437275\n",
      "timeframe: 1 section: 527 alpha: 36.46182308681542\n",
      "timeframe: 1 section: 415 alpha: 30.000701313318448\n",
      "timeframe: 1 section: 422 alpha: 30.660438486047195\n",
      "timeframe: 1 section: 471 alpha: 30.571031932005443\n",
      "timeframe: 2 section: 277 alpha: 6.207503453984217\n",
      "timeframe: 2 section: 5 alpha: 22.66031362444414\n",
      "timeframe: 1 section: 555 alpha: 27.785140217564116\n",
      "timeframe: 2 section: 193 alpha: 14.802489861453017\n",
      "timeframe: 1 section: 199 alpha: 20.786016531581986\n",
      "timeframe: 1 section: 276 alpha: 4.534179702924347\n",
      "timeframe: 1 section: 352 alpha: 14.787765070349305\n",
      "timeframe: 1 section: 269 alpha: 45.10530842231748\n",
      "timeframe: 1 section: 408 alpha: 23.609513623742064\n",
      "timeframe: 2 section: 20 alpha: 10.110655514217902\n",
      "timeframe: 2 section: 26 alpha: 10.25967967080304\n",
      "timeframe: 1 section: 374 alpha: 32.6498514299474\n",
      "timeframe: 1 section: 395 alpha: 25.418404494401493\n",
      "timeframe: 1 section: 429 alpha: 25.83110050846717\n",
      "timeframe: 2 section: 270 alpha: 29.456970494807376\n",
      "timeframe: 1 section: 499 alpha: 14.833775112612068\n",
      "timeframe: 1 section: 219 alpha: 6.922386198746823\n",
      "timeframe: 2 section: 109 alpha: 42.37267554966221\n",
      "timeframe: 1 section: 464 alpha: 8.500389572371478\n",
      "timeframe: 2 section: 159 alpha: 24.350004505714452\n",
      "timeframe: 1 section: 212 alpha: 29.052364258294627\n",
      "timeframe: 1 section: 324 alpha: 33.6433706383134\n",
      "timeframe: 1 section: 492 alpha: 33.702901019703646\n",
      "timeframe: 1 section: 359 alpha: 10.304791007572343\n",
      "timeframe: 1 section: 206 alpha: 34.16150711842147\n",
      "timeframe: 1 section: 450 alpha: 20.137831079407388\n",
      "timeframe: 1 section: 171 alpha: 38.49126751634045\n",
      "timeframe: 2 section: 46 alpha: 18.38447262502289\n",
      "timeframe: 1 section: 282 alpha: 16.29406581160242\n",
      "timeframe: 2 section: 115 alpha: 53.94782273766732\n",
      "timeframe: 2 section: 144 alpha: 10.48374791761311\n",
      "timeframe: 1 section: 443 alpha: 27.619781105917802\n",
      "timeframe: 1 section: 192 alpha: 13.463956584562288\n",
      "timeframe: 2 section: 88 alpha: 30.92477721917159\n",
      "timeframe: 1 section: 303 alpha: 46.39299637437969\n",
      "timeframe: 2 section: 124 alpha: 17.089513210790578\n",
      "timeframe: 1 section: 514 alpha: 23.08541137223455\n",
      "timeframe: 2 section: 55 alpha: 5.812886120463306\n",
      "timeframe: 2 section: 256 alpha: 56.817139694687235\n",
      "timeframe: 1 section: 234 alpha: 29.51073062815641\n",
      "timeframe: 1 section: 387 alpha: 31.124708006504193\n",
      "timeframe: 1 section: 289 alpha: 32.59137034505263\n",
      "timeframe: 2 section: 173 alpha: 15.245528967874712\n",
      "timeframe: 1 section: 177 alpha: 43.26832736742588\n",
      "timeframe: 1 section: 227 alpha: 10.442027188744008\n",
      "timeframe: 1 section: 346 alpha: 23.43022664134672\n",
      "timeframe: 1 section: 541 alpha: 8.792668882244659\n",
      "timeframe: 1 section: 520 alpha: 11.549015660082807\n",
      "timeframe: 1 section: 262 alpha: 30.1443839079947\n",
      "timeframe: 2 section: 96 alpha: 11.956014633106602\n",
      "timeframe: 1 section: 486 alpha: 19.539067348369926\n",
      "timeframe: 2 section: 165 alpha: 25.268825886606276\n",
      "timeframe: 2 section: 12 alpha: 25.832057284753283\n",
      "timeframe: 1 section: 366 alpha: 20.429865103546522\n",
      "timeframe: 2 section: 214 alpha: 11.255237606676506\n",
      "timeframe: 2 section: 138 alpha: 14.562637801896388\n",
      "timeframe: 1 section: 430 alpha: 13.371536281328593\n",
      "timeframe: 1 section: 534 alpha: 28.31282795439347\n",
      "timeframe: 2 section: 179 alpha: 19.71602909190644\n",
      "timeframe: 2 section: 221 alpha: 30.32506558471125\n",
      "timeframe: 2 section: 302 alpha: 4.901980037334073\n",
      "timeframe: 2 section: 152 alpha: 31.44695132954509\n",
      "timeframe: 2 section: 83 alpha: 35.96106331764213\n",
      "timeframe: 1 section: 332 alpha: 8.684168483792035\n",
      "timeframe: 1 section: 381 alpha: 18.65414054093332\n",
      "timeframe: 1 section: 241 alpha: 32.50403927677215\n",
      "timeframe: 2 section: 33 alpha: 40.02000154587825\n",
      "timeframe: 2 section: 68 alpha: 5.949644120283858\n",
      "timeframe: 1 section: 297 alpha: 18.34553846410854\n",
      "timeframe: 1 section: 458 alpha: 19.244263249978292\n",
      "timeframe: 2 section: 75 alpha: 36.8253699854\n",
      "timeframe: 1 section: 549 alpha: 15.14432012983672\n",
      "timeframe: 2 section: 62 alpha: 15.28771264680896\n",
      "timeframe: 1 section: 339 alpha: 22.09258868993345\n",
      "timeframe: 1 section: 401 alpha: 27.835787116721356\n",
      "timeframe: 2 section: 131 alpha: 20.932814677549146\n",
      "timeframe: 1 section: 185 alpha: 12.871487793642848\n",
      "timeframe: 2 section: 235 alpha: 16.01349831746031\n",
      "timeframe: 2 section: 250 alpha: 38.202515511657396\n",
      "timeframe: 2 section: 200 alpha: 10.817693574239499\n",
      "timeframe: 2 section: 208 alpha: 15.964850459304387\n",
      "timeframe: 2 section: 288 alpha: 27.519235869304882\n",
      "timeframe: 2 section: 330 alpha: 0.11513894733080586\n",
      "timeframe: 1 section: 451 alpha: 25.518271367638174\n",
      "timeframe: 2 section: 358 alpha: 61.6620280215463\n",
      "timeframe: 2 section: 243 alpha: 47.885422230063206\n",
      "timeframe: 2 section: 263 alpha: 32.3086328370581\n",
      "timeframe: 1 section: 310 alpha: 56.05072796040979\n",
      "timeframe: 2 section: 309 alpha: 24.99682238269183\n",
      "timeframe: 1 section: 416 alpha: 26.577830715243802\n",
      "timeframe: 1 section: 423 alpha: 32.236419162066134\n",
      "timeframe: 1 section: 248 alpha: 19.481963527026355\n",
      "timeframe: 2 section: 228 alpha: 15.886451880098171\n",
      "timeframe: 2 section: 271 alpha: 30.154893563829894\n",
      "timeframe: 1 section: 472 alpha: 41.48459367346186\n",
      "timeframe: 2 section: 337 alpha: 20.035686848402417\n",
      "timeframe: 2 section: 316 alpha: 74.22851066991868\n",
      "timeframe: 2 section: 257 alpha: 16.843659758602332\n",
      "timeframe: 2 section: 160 alpha: 26.49241153929628\n",
      "timeframe: 2 section: 145 alpha: 57.3238499548421\n",
      "timeframe: 2 section: 372 alpha: 26.836334353935097\n",
      "timeframe: 1 section: 478 alpha: 21.337908461530606\n",
      "timeframe: 1 section: 353 alpha: 24.510642108221464\n",
      "timeframe: 1 section: 409 alpha: 23.971443583233846\n",
      "timeframe: 1 section: 360 alpha: 9.813052957312863\n",
      "timeframe: 1 section: 528 alpha: 24.88047427253543\n",
      "timeframe: 2 section: 187 alpha: 28.466820646958862\n",
      "timeframe: 1 section: 325 alpha: 28.328439870728083\n",
      "timeframe: 2 section: 27 alpha: 11.770307450382482\n",
      "timeframe: 1 section: 500 alpha: 30.540979176475\n",
      "timeframe: 2 section: 194 alpha: 18.013847299266345\n",
      "timeframe: 1 section: 465 alpha: 16.014530329660854\n",
      "timeframe: 1 section: 283 alpha: 38.82887088816222\n",
      "timeframe: 2 section: 295 alpha: 18.000945228527367\n",
      "timeframe: 2 section: 379 alpha: 20.46257896227869\n",
      "timeframe: 2 section: 365 alpha: 18.019940979169753\n",
      "timeframe: 2 section: 323 alpha: 56.9870034875844\n",
      "timeframe: 2 section: 278 alpha: 11.750389640300861\n",
      "timeframe: 2 section: 351 alpha: 50.574764103175134\n",
      "timeframe: 1 section: 388 alpha: 21.855192213854643\n",
      "timeframe: 2 section: 400 alpha: 9.750749953838616\n",
      "timeframe: 1 section: 444 alpha: 22.540258173362712\n",
      "timeframe: 2 section: 103 alpha: 42.20402985434506\n",
      "timeframe: 2 section: 6 alpha: 14.976740304756547\n",
      "timeframe: 1 section: 213 alpha: 19.916638947746197\n",
      "timeframe: 1 section: 220 alpha: 13.132236637637684\n",
      "timeframe: 1 section: 290 alpha: 18.03745035314064\n",
      "timeframe: 2 section: 393 alpha: 22.10332897180949\n",
      "timeframe: 1 section: 178 alpha: 18.16517970329182\n",
      "timeframe: 1 section: 535 alpha: 17.372918460483312\n",
      "timeframe: 2 section: 21 alpha: 19.582500752382497\n",
      "timeframe: 2 section: 125 alpha: 19.47768225552962\n",
      "timeframe: 2 section: 0 alpha: 22.791007900058176\n",
      "timeframe: 2 section: 283 alpha: 32.764356873871435\n",
      "timeframe: 2 section: 41 alpha: 41.209629891994304\n",
      "timeframe: 2 section: 110 alpha: 12.422661541308198\n",
      "timeframe: 1 section: 304 alpha: 50.633838270667006\n",
      "timeframe: 2 section: 435 alpha: 10.534523606278324\n",
      "timeframe: 1 section: 542 alpha: 22.31350962269167\n",
      "timeframe: 2 section: 34 alpha: 41.445418188645654\n",
      "timeframe: 2 section: 56 alpha: 24.132598017425046\n",
      "timeframe: 1 section: 521 alpha: 29.794129518117387\n",
      "timeframe: 2 section: 47 alpha: 11.626501364520648\n",
      "timeframe: 2 section: 116 alpha: 40.92120132772147\n",
      "timeframe: 2 section: 244 alpha: 6.601030765892766\n",
      "timeframe: 1 section: 493 alpha: 19.310777781482447\n",
      "timeframe: 2 section: 421 alpha: 18.76437809450842\n",
      "timeframe: 2 section: 344 alpha: 13.225027506452381\n",
      "timeframe: 2 section: 373 alpha: 16.053070133172643\n",
      "timeframe: 2 section: 174 alpha: 11.71487666264793\n",
      "timeframe: 2 section: 180 alpha: 40.55562437815558\n",
      "timeframe: 2 section: 442 alpha: 10.65261026493482\n",
      "timeframe: 2 section: 258 alpha: 58.73485382600498\n",
      "timeframe: 2 section: 264 alpha: 6.1435635744061745\n",
      "timeframe: 2 section: 386 alpha: 23.28893657914104\n",
      "timeframe: 1 section: 367 alpha: 21.368314552534713\n",
      "timeframe: 2 section: 414 alpha: 37.931583241556005\n",
      "timeframe: 1 section: 402 alpha: 31.041821642204695\n",
      "timeframe: 2 section: 449 alpha: 21.72416062563762\n",
      "timeframe: 2 section: 407 alpha: 52.48364130482851\n",
      "timeframe: 2 section: 463 alpha: 65.79666056543773\n",
      "timeframe: 2 section: 491 alpha: 32.852271891083724\n",
      "timeframe: 2 section: 89 alpha: 27.813587074371657\n",
      "timeframe: 2 section: 380 alpha: 14.194645089303641\n",
      "timeframe: 2 section: 153 alpha: 36.7341746913963\n",
      "timeframe: 2 section: 166 alpha: 37.941986229199415\n",
      "timeframe: 2 section: 338 alpha: 10.197765873316085\n",
      "timeframe: 2 section: 215 alpha: 30.832917805581765\n",
      "timeframe: 2 section: 331 alpha: 12.531425968201276\n",
      "timeframe: 2 section: 139 alpha: 11.472434992536236\n",
      "timeframe: 2 section: 146 alpha: 7.432471698661496\n",
      "timeframe: 2 section: 97 alpha: 21.091705316507497\n",
      "timeframe: 2 section: 512 alpha: 14.520723755141109\n",
      "timeframe: 2 section: 303 alpha: 25.904007033577848\n",
      "timeframe: 2 section: 456 alpha: 12.649895095294376\n",
      "timeframe: 2 section: 13 alpha: 59.01225973046023\n",
      "timeframe: 1 section: 479 alpha: 6.926464993400979\n",
      "timeframe: 2 section: 209 alpha: 25.97698276058564\n",
      "timeframe: 2 section: 104 alpha: 43.29389443695751\n",
      "timeframe: 2 section: 317 alpha: 20.922099844129967\n",
      "timeframe: 3 section: 5 alpha: 0.41737403492745956\n",
      "timeframe: 2 section: 251 alpha: 17.753439960490542\n",
      "timeframe: 1 section: 311 alpha: 22.3020694300224\n",
      "timeframe: 2 section: 272 alpha: 18.03723648169562\n",
      "timeframe: 2 section: 201 alpha: 64.18959793089662\n",
      "timeframe: 2 section: 310 alpha: 19.024682056989565\n",
      "timeframe: 2 section: 519 alpha: 10.789664166526137\n",
      "timeframe: 2 section: 505 alpha: 17.739786953471903\n",
      "timeframe: 2 section: 289 alpha: 17.644138059445638\n",
      "timeframe: 3 section: 82 alpha: 39.49181220023859\n",
      "timeframe: 2 section: 132 alpha: 13.529517936881186\n",
      "timeframe: 2 section: 484 alpha: 22.327047961219254\n",
      "timeframe: 2 section: 428 alpha: 22.52498654306995\n",
      "timeframe: 2 section: 245 alpha: 32.65063849091136\n",
      "timeframe: 2 section: 470 alpha: 8.799683825569845\n",
      "timeframe: 2 section: 436 alpha: 9.333027453047626\n",
      "timeframe: 2 section: 63 alpha: 12.019103911810388\n",
      "timeframe: 2 section: 161 alpha: 12.878206639598963\n",
      "timeframe: 2 section: 498 alpha: 48.32168992566313\n",
      "timeframe: 2 section: 126 alpha: 76.47796010902111\n",
      "timeframe: 3 section: 19 alpha: 19.55614018740912\n",
      "timeframe: 3 section: 12 alpha: 21.808632380658572\n",
      "timeframe: 2 section: 352 alpha: 48.89236664218977\n",
      "timeframe: 2 section: 229 alpha: 42.61405906836659\n",
      "timeframe: 2 section: 324 alpha: 14.233714685599798\n",
      "timeframe: 2 section: 69 alpha: 11.124646434604083\n",
      "timeframe: 2 section: 422 alpha: 29.696372466123464\n",
      "timeframe: 2 section: 477 alpha: 60.669132889583125\n",
      "timeframe: 2 section: 84 alpha: 32.39735552124286\n",
      "timeframe: 2 section: 359 alpha: 28.595426844338643\n",
      "timeframe: 2 section: 222 alpha: 54.28250505580453\n",
      "timeframe: 2 section: 366 alpha: 74.31995781944299\n",
      "timeframe: 2 section: 181 alpha: 24.601532394005435\n",
      "timeframe: 3 section: 54 alpha: 42.76354714861761\n",
      "timeframe: 2 section: 188 alpha: 35.00602156524012\n",
      "timeframe: 2 section: 533 alpha: 21.045788694799302\n",
      "timeframe: 2 section: 28 alpha: 42.37117376596227\n",
      "timeframe: 3 section: 61 alpha: 15.978188759100897\n",
      "timeframe: 2 section: 7 alpha: 27.732313678742564\n",
      "timeframe: 2 section: 394 alpha: 27.59327140102818\n",
      "timeframe: 3 section: 26 alpha: 11.408186984861894\n",
      "timeframe: 2 section: 76 alpha: 66.26408917058286\n",
      "timeframe: 2 section: 35 alpha: 23.96559857178781\n",
      "timeframe: 2 section: 443 alpha: 29.930783085596893\n",
      "timeframe: 2 section: 265 alpha: 4.009054079676756\n",
      "timeframe: 2 section: 345 alpha: 30.62065516836107\n",
      "timeframe: 2 section: 374 alpha: 15.032351017418316\n",
      "timeframe: 3 section: 47 alpha: 11.394962261463519\n",
      "timeframe: 2 section: 526 alpha: 33.810298466542854\n",
      "timeframe: 3 section: 145 alpha: 35.77661872401881\n",
      "timeframe: 3 section: 96 alpha: 22.91441705926424\n",
      "timeframe: 2 section: 195 alpha: 24.347399942424158\n",
      "timeframe: 2 section: 14 alpha: 28.96395299980698\n",
      "timeframe: 2 section: 450 alpha: 5.581509024478251\n",
      "timeframe: 2 section: 154 alpha: 8.130665929748277\n",
      "timeframe: 2 section: 105 alpha: 8.436764942926573\n",
      "timeframe: 2 section: 48 alpha: 4.015593496214981\n",
      "timeframe: 3 section: 68 alpha: 6.418712166821616\n",
      "timeframe: 2 section: 401 alpha: 26.27759250556272\n",
      "timeframe: 2 section: 279 alpha: 23.783754165340852\n",
      "timeframe: 2 section: 339 alpha: 11.666066409041779\n",
      "timeframe: 2 section: 236 alpha: 32.99403497773699\n",
      "timeframe: 2 section: 296 alpha: 49.782005005536135\n",
      "timeframe: 2 section: 42 alpha: 29.030799842539647\n",
      "timeframe: 2 section: 429 alpha: 45.93753410623391\n",
      "timeframe: 2 section: 540 alpha: 37.725708910796286\n",
      "timeframe: 2 section: 554 alpha: 12.51152483876142\n",
      "timeframe: 3 section: 103 alpha: 24.732201287120272\n",
      "timeframe: 3 section: 40 alpha: 31.79521841248843\n",
      "timeframe: 2 section: 147 alpha: 30.72603750514523\n",
      "timeframe: 3 section: 33 alpha: 26.565942183365713\n",
      "timeframe: 2 section: 70 alpha: 46.24735714280318\n",
      "timeframe: 2 section: 210 alpha: 15.924758060828777\n",
      "timeframe: 2 section: 284 alpha: 27.735300791873744\n",
      "timeframe: 2 section: 111 alpha: 28.43501827541854\n",
      "timeframe: 2 section: 547 alpha: 9.490164880710973\n",
      "timeframe: 2 section: 117 alpha: 19.762547366347814\n",
      "timeframe: 2 section: 216 alpha: 83.41266246307028\n",
      "timeframe: 2 section: 259 alpha: 136.4402613589485\n",
      "timeframe: 3 section: 124 alpha: 19.124614798729027\n",
      "timeframe: 2 section: 252 alpha: 55.139299369835\n",
      "timeframe: 2 section: 437 alpha: 24.647476252436824\n",
      "timeframe: 3 section: 89 alpha: 30.34314317980393\n",
      "timeframe: 2 section: 175 alpha: 46.947448398837146\n",
      "timeframe: 2 section: 304 alpha: 33.87726041234151\n",
      "timeframe: 2 section: 332 alpha: 4.407662339583215\n",
      "timeframe: 2 section: 471 alpha: 37.926932137153415\n",
      "timeframe: 3 section: 117 alpha: 57.55613336888079\n",
      "timeframe: 3 section: 75 alpha: 55.20440821999749\n",
      "timeframe: 2 section: 464 alpha: 8.700275557056004\n",
      "timeframe: 3 section: 55 alpha: 4.404401109194192\n",
      "timeframe: 2 section: 506 alpha: 23.89395408962022\n",
      "timeframe: 2 section: 387 alpha: 12.886134319131532\n",
      "timeframe: 2 section: 90 alpha: 51.63666786434038\n",
      "timeframe: 2 section: 140 alpha: 46.70222171216298\n",
      "timeframe: 2 section: 520 alpha: 8.759750286326724\n",
      "timeframe: 2 section: 513 alpha: 31.684877782044623\n",
      "timeframe: 2 section: 98 alpha: 84.94123132306667\n",
      "timeframe: 2 section: 444 alpha: 25.00254271839064\n",
      "timeframe: 2 section: 457 alpha: 27.469746808688882\n",
      "timeframe: 2 section: 408 alpha: 28.180895451193752\n",
      "timeframe: 2 section: 311 alpha: 40.90009774156755\n",
      "timeframe: 2 section: 492 alpha: 35.77803938226901\n",
      "timeframe: 2 section: 318 alpha: 9.939300717442597\n",
      "timeframe: 2 section: 395 alpha: 13.066223336721015\n",
      "timeframe: 3 section: 159 alpha: 1.3808690338436884\n",
      "timeframe: 2 section: 430 alpha: 50.94401004963951\n",
      "timeframe: 2 section: 49 alpha: 27.041056922415475\n",
      "timeframe: 2 section: 290 alpha: 11.57038050180437\n",
      "timeframe: 3 section: 131 alpha: 27.120508582326973\n",
      "timeframe: 2 section: 360 alpha: 7.851893806375671\n",
      "timeframe: 2 section: 273 alpha: 20.556047188725433\n",
      "timeframe: 2 section: 133 alpha: 65.91989688145891\n",
      "timeframe: 2 section: 415 alpha: 79.88219551889442\n",
      "timeframe: 2 section: 375 alpha: 8.192345917777741\n",
      "timeframe: 3 section: 110 alpha: 41.55417702149888\n",
      "timeframe: 3 section: 138 alpha: 22.59318156676389\n",
      "timeframe: 2 section: 485 alpha: 8.618699433651111\n",
      "timeframe: 3 section: 83 alpha: 13.876738644601648\n",
      "timeframe: 2 section: 423 alpha: 35.52072998545902\n",
      "timeframe: 3 section: 27 alpha: 161.98734611409847\n",
      "timeframe: 3 section: 173 alpha: 34.81304035691426\n",
      "timeframe: 3 section: 152 alpha: 25.649838506382\n",
      "timeframe: 2 section: 202 alpha: 55.409065282875744\n",
      "timeframe: 3 section: 257 alpha: 17.94701320490078\n",
      "timeframe: 2 section: 167 alpha: 17.733539238566127\n",
      "timeframe: 3 section: 208 alpha: 0.14312644140616976\n",
      "timeframe: 2 section: 353 alpha: 27.448431832854734\n",
      "timeframe: 2 section: 534 alpha: 25.820950611859516\n",
      "timeframe: 2 section: 451 alpha: 13.316461419296836\n",
      "timeframe: 2 section: 478 alpha: 22.71937253971139\n",
      "timeframe: 3 section: 187 alpha: 32.259382798570705\n",
      "timeframe: 3 section: 6 alpha: 42.71190876357838\n",
      "timeframe: 2 section: 112 alpha: 14.559831101960444\n",
      "timeframe: 2 section: 381 alpha: 34.52045163144473\n",
      "timeframe: 3 section: 20 alpha: 0.4991684909365498\n",
      "timeframe: 2 section: 499 alpha: 14.130413863744083\n",
      "timeframe: 2 section: 325 alpha: 55.22180033758338\n",
      "timeframe: 2 section: 266 alpha: 10.989465352428269\n",
      "timeframe: 2 section: 223 alpha: 28.976927119985206\n",
      "timeframe: 2 section: 507 alpha: 41.63408184552521\n",
      "timeframe: 2 section: 346 alpha: 24.379055407827074\n",
      "timeframe: 2 section: 548 alpha: 11.73238696277373\n",
      "timeframe: 2 section: 280 alpha: 17.51803827150464\n",
      "timeframe: 2 section: 230 alpha: 12.379963071261127\n",
      "timeframe: 3 section: 69 alpha: 49.73004385557247\n",
      "timeframe: 2 section: 189 alpha: 35.44435452831051\n",
      "timeframe: 2 section: 527 alpha: 43.15231795410291\n",
      "timeframe: 3 section: 215 alpha: 44.98560586568061\n",
      "timeframe: 2 section: 521 alpha: 25.181670577311245\n",
      "timeframe: 2 section: 388 alpha: 4.450788498991011\n",
      "timeframe: 2 section: 196 alpha: 25.42492050655225\n",
      "timeframe: 3 section: 180 alpha: 46.459494861063206\n",
      "timeframe: 3 section: 62 alpha: 26.272267279636544\n",
      "timeframe: 2 section: 182 alpha: 16.146008298523086\n",
      "timeframe: 2 section: 431 alpha: 44.71144445641223\n",
      "timeframe: 2 section: 340 alpha: 32.14827091800037\n",
      "timeframe: 2 section: 367 alpha: 22.990466683692283\n",
      "timeframe: 3 section: 166 alpha: 58.94442223200657\n",
      "timeframe: 3 section: 250 alpha: 64.04094715560345\n",
      "timeframe: 3 section: 146 alpha: 6.363796522483722\n",
      "timeframe: 3 section: 201 alpha: 26.486616809588426\n",
      "timeframe: 3 section: 48 alpha: 7.247119199562194\n",
      "timeframe: 3 section: 236 alpha: 28.726083988693823\n",
      "timeframe: 2 section: 555 alpha: 24.800213471858466\n",
      "timeframe: 2 section: 237 alpha: 30.791891907035552\n",
      "timeframe: 3 section: 243 alpha: 54.24364465035912\n",
      "timeframe: 3 section: 118 alpha: 21.63950110295386\n",
      "timeframe: 3 section: 104 alpha: 22.577923990455258\n",
      "timeframe: 3 section: 194 alpha: 48.2034297516448\n",
      "timeframe: 2 section: 217 alpha: 17.221272724142416\n",
      "timeframe: 3 section: 34 alpha: 17.284150655536553\n",
      "timeframe: 3 section: 229 alpha: 50.21272174230714\n",
      "timeframe: 2 section: 305 alpha: 27.41459254862206\n",
      "timeframe: 2 section: 465 alpha: 76.71966834640186\n",
      "timeframe: 2 section: 438 alpha: 42.81767097723607\n",
      "timeframe: 3 section: 271 alpha: 13.490307374679011\n",
      "timeframe: 2 section: 354 alpha: 17.70275042532607\n",
      "timeframe: 2 section: 297 alpha: 5.4381230609790965\n",
      "timeframe: 3 section: 90 alpha: 95.57446084121537\n",
      "timeframe: 2 section: 333 alpha: 17.115462636615035\n",
      "timeframe: 2 section: 416 alpha: 18.053641240899392\n",
      "timeframe: 3 section: 160 alpha: 12.701270561307245\n",
      "timeframe: 3 section: 258 alpha: 59.35922048173075\n",
      "timeframe: 3 section: 97 alpha: 20.864086944674963\n",
      "timeframe: 3 section: 278 alpha: 8.795351472197567\n",
      "timeframe: 2 section: 402 alpha: 21.645014601246693\n",
      "timeframe: 2 section: 376 alpha: 16.345117445256196\n",
      "timeframe: 2 section: 285 alpha: 14.643638869022583\n",
      "timeframe: 2 section: 445 alpha: 19.607300159251608\n",
      "timeframe: 3 section: 13 alpha: 51.49709639985356\n",
      "timeframe: 2 section: 396 alpha: 23.18350638480948\n",
      "timeframe: 2 section: 514 alpha: 13.406130323356738\n",
      "timeframe: 3 section: 125 alpha: 9.289157562201021\n",
      "timeframe: 2 section: 409 alpha: 31.554733204497705\n",
      "timeframe: 3 section: 56 alpha: 2.6809593870232864\n",
      "timeframe: 2 section: 77 alpha: 36.945931541792014\n",
      "timeframe: 2 section: 500 alpha: 21.730033939852817\n",
      "timeframe: 2 section: 118 alpha: 9.358310053611017\n",
      "timeframe: 3 section: 209 alpha: 1.9256022562045105\n",
      "timeframe: 2 section: 291 alpha: 25.507785163859644\n",
      "timeframe: 2 section: 224 alpha: 27.44943853622277\n",
      "timeframe: 3 section: 285 alpha: 16.54453685257966\n",
      "timeframe: 3 section: 70 alpha: 27.861526220488788\n",
      "timeframe: 3 section: 153 alpha: 17.367023654453863\n",
      "timeframe: 3 section: 76 alpha: 104.90461308898306\n",
      "timeframe: 3 section: 264 alpha: 6.583345035414013\n",
      "timeframe: 2 section: 493 alpha: 21.928759535547524\n",
      "timeframe: 2 section: 479 alpha: 5.768775931552751\n",
      "timeframe: 2 section: 486 alpha: 22.831343878486408\n",
      "timeframe: 2 section: 312 alpha: 28.657622099793407\n",
      "timeframe: 2 section: 541 alpha: 33.44775018894524\n",
      "timeframe: 2 section: 382 alpha: 13.875097050150329\n",
      "timeframe: 3 section: 306 alpha: 30.62150946411432\n",
      "timeframe: 2 section: 424 alpha: 56.07103126953882\n",
      "timeframe: 2 section: 389 alpha: 12.2794608869686\n",
      "timeframe: 2 section: 319 alpha: 18.793589556256602\n",
      "timeframe: 2 section: 432 alpha: 24.914583161799047\n",
      "timeframe: 2 section: 472 alpha: 21.61907268340392\n",
      "timeframe: 2 section: 361 alpha: 25.965260186519004\n",
      "timeframe: 3 section: 105 alpha: 6.333399003386408\n",
      "timeframe: 3 section: 181 alpha: 17.391842343206825\n",
      "timeframe: 3 section: 84 alpha: 12.30841965918114\n",
      "timeframe: 3 section: 244 alpha: 42.67676235622835\n",
      "timeframe: 3 section: 313 alpha: 8.473939655271904\n",
      "timeframe: 3 section: 49 alpha: 43.3248310943375\n",
      "timeframe: 3 section: 292 alpha: 9.928736808926955\n",
      "timeframe: 2 section: 549 alpha: 21.10423009191949\n",
      "timeframe: 3 section: 35 alpha: 50.57077754927614\n",
      "timeframe: 2 section: 508 alpha: 24.45739205068907\n",
      "timeframe: 3 section: 299 alpha: 17.65519140564572\n",
      "timeframe: 2 section: 535 alpha: 39.337978765214\n",
      "timeframe: 3 section: 111 alpha: 20.86640187824134\n",
      "timeframe: 3 section: 41 alpha: 13.296798375429136\n",
      "timeframe: 2 section: 168 alpha: 38.665855004866934\n",
      "timeframe: 3 section: 355 alpha: 9.686686884695177\n",
      "timeframe: 2 section: 458 alpha: 51.03596002027601\n",
      "timeframe: 2 section: 341 alpha: 18.685310359369264\n",
      "timeframe: 2 section: 91 alpha: 44.78409707003844\n",
      "timeframe: 3 section: 28 alpha: 44.96233533733951\n",
      "timeframe: 3 section: 174 alpha: 15.104889935230322\n",
      "timeframe: 2 section: 347 alpha: 16.015990787654673\n",
      "timeframe: 2 section: 515 alpha: 25.76664600982138\n",
      "timeframe: 2 section: 528 alpha: 12.843597309884622\n",
      "timeframe: 3 section: 222 alpha: 29.06741725605101\n",
      "timeframe: 2 section: 298 alpha: 13.033048945245486\n",
      "timeframe: 3 section: 341 alpha: 15.274102993077102\n",
      "timeframe: 2 section: 452 alpha: 24.659010011072656\n",
      "timeframe: 2 section: 203 alpha: 26.961652436055644\n",
      "timeframe: 3 section: 188 alpha: 42.71126629675839\n",
      "timeframe: 2 section: 466 alpha: 50.60328179223953\n",
      "timeframe: 3 section: 334 alpha: 33.99540419348933\n",
      "timeframe: 2 section: 231 alpha: 27.34096141659959\n",
      "timeframe: 3 section: 21 alpha: 10.936781088589685\n",
      "timeframe: 3 section: 126 alpha: 17.44281377581485\n",
      "timeframe: 3 section: 327 alpha: 13.970414861182592\n",
      "timeframe: 3 section: 154 alpha: 17.72620435894135\n",
      "timeframe: 3 section: 245 alpha: 75.01644354367977\n",
      "timeframe: 3 section: 14 alpha: 24.338161287556265\n",
      "timeframe: 2 section: 417 alpha: 8.551557250383595\n",
      "timeframe: 3 section: 161 alpha: 3.0176633473307306\n",
      "timeframe: 2 section: 334 alpha: 14.556128038548405\n",
      "timeframe: 2 section: 368 alpha: 17.619318849203047\n",
      "timeframe: 3 section: 216 alpha: 15.522868254210515\n",
      "timeframe: 2 section: 446 alpha: 14.84515090327669\n",
      "timeframe: 2 section: 522 alpha: 37.12295335130373\n",
      "timeframe: 2 section: 238 alpha: 14.525251672520406\n",
      "timeframe: 3 section: 320 alpha: 35.45642402013825\n",
      "timeframe: 3 section: 119 alpha: 15.832490012848092\n",
      "timeframe: 3 section: 0 alpha: 28.76292379830373\n",
      "timeframe: 2 section: 306 alpha: 19.144165991427197\n",
      "timeframe: 2 section: 355 alpha: 14.739986696001946\n",
      "timeframe: 3 section: 376 alpha: 33.00220601188993\n",
      "timeframe: 3 section: 139 alpha: 38.498626151392465\n",
      "timeframe: 2 section: 439 alpha: 26.38225112854436\n",
      "timeframe: 3 section: 202 alpha: 23.672857280529914\n",
      "timeframe: 3 section: 265 alpha: 1.4727356503529307\n",
      "timeframe: 3 section: 63 alpha: 15.559535178854953\n",
      "timeframe: 3 section: 71 alpha: 14.711516296254775\n",
      "timeframe: 3 section: 85 alpha: 24.316355013087644\n",
      "timeframe: 2 section: 326 alpha: 28.16482521715435\n",
      "timeframe: 2 section: 480 alpha: 49.40872532776916\n",
      "timeframe: 2 section: 501 alpha: 111.03849846407287\n",
      "timeframe: 3 section: 98 alpha: 21.56530676792568\n",
      "timeframe: 3 section: 36 alpha: 36.73217561370882\n",
      "timeframe: 2 section: 390 alpha: 17.175244566405496\n",
      "timeframe: 3 section: 348 alpha: 59.263334521860195\n",
      "timeframe: 3 section: 307 alpha: 17.87015986436721\n",
      "timeframe: 2 section: 397 alpha: 25.369013296004923\n",
      "timeframe: 3 section: 167 alpha: 7.367910972541703\n",
      "timeframe: 2 section: 410 alpha: 13.504820809467589\n",
      "timeframe: 2 section: 286 alpha: 40.736883540573245\n",
      "timeframe: 3 section: 279 alpha: 39.72289515175285\n",
      "timeframe: 3 section: 132 alpha: 26.338383383976534\n",
      "timeframe: 2 section: 425 alpha: 8.966284760054238\n",
      "timeframe: 3 section: 383 alpha: 1.4738733859377053\n",
      "timeframe: 3 section: 237 alpha: 33.35783388889968\n",
      "timeframe: 3 section: 147 alpha: 11.957039296602279\n",
      "timeframe: 3 section: 50 alpha: 43.086220417907995\n",
      "timeframe: 2 section: 516 alpha: 29.885870247270976\n",
      "timeframe: 3 section: 91 alpha: 23.841024762890285\n",
      "timeframe: 2 section: 403 alpha: 20.140122981334677\n",
      "timeframe: 3 section: 259 alpha: 32.348158824783646\n",
      "timeframe: 3 section: 369 alpha: 22.091029948594997\n",
      "timeframe: 2 section: 119 alpha: 20.675979464594135\n",
      "timeframe: 3 section: 362 alpha: 15.646076961190847\n",
      "timeframe: 2 section: 487 alpha: 22.064728359293415\n",
      "timeframe: 2 section: 377 alpha: 30.86946349414084\n",
      "timeframe: 3 section: 210 alpha: 9.719644614194353\n",
      "timeframe: 3 section: 286 alpha: 46.428981365204905\n",
      "timeframe: 2 section: 342 alpha: 10.76598356274252\n",
      "timeframe: 2 section: 383 alpha: 11.723764167609348\n",
      "timeframe: 3 section: 293 alpha: 123.65826844917615\n",
      "timeframe: 3 section: 112 alpha: 6.246059858722197\n",
      "timeframe: 3 section: 251 alpha: 50.772980905507005\n",
      "timeframe: 3 section: 7 alpha: 21.8497589693999\n",
      "timeframe: 2 section: 320 alpha: 13.715405333682323\n",
      "timeframe: 2 section: 459 alpha: 22.52819828376513\n",
      "timeframe: 3 section: 57 alpha: 1.8618852090154299\n",
      "timeframe: 3 section: 272 alpha: 54.368536159256045\n",
      "timeframe: 3 section: 300 alpha: 20.79724514224166\n",
      "timeframe: 2 section: 313 alpha: 62.641249185663156\n",
      "timeframe: 2 section: 542 alpha: 21.671604872142563\n",
      "timeframe: 3 section: 29 alpha: 1.9104729132873828\n",
      "timeframe: 3 section: 15 alpha: 25.55422624900394\n",
      "timeframe: 2 section: 292 alpha: 15.045469122392936\n",
      "timeframe: 2 section: 369 alpha: 22.404501614211078\n",
      "timeframe: 3 section: 342 alpha: 13.642323582547464\n",
      "timeframe: 3 section: 77 alpha: 49.17734672068181\n",
      "timeframe: 2 section: 502 alpha: 13.231562403110647\n",
      "timeframe: 2 section: 433 alpha: 43.1651402448088\n",
      "timeframe: 2 section: 473 alpha: 28.092625252452134\n",
      "timeframe: 2 section: 509 alpha: 35.60840667821473\n",
      "timeframe: 3 section: 314 alpha: 21.813491850273593\n",
      "timeframe: 3 section: 182 alpha: 29.920554652466738\n",
      "timeframe: 3 section: 42 alpha: 40.0002255537692\n",
      "timeframe: 3 section: 411 alpha: 2.917307202360684\n",
      "timeframe: 2 section: 299 alpha: 22.41544123931191\n",
      "timeframe: 2 section: 529 alpha: 16.89131326391272\n",
      "timeframe: 2 section: 356 alpha: 27.866055781983444\n",
      "timeframe: 2 section: 391 alpha: 19.74378854887462\n",
      "timeframe: 2 section: 467 alpha: 22.373043017138986\n",
      "timeframe: 3 section: 404 alpha: 49.860948249817284\n",
      "timeframe: 3 section: 356 alpha: 46.008361220954164\n",
      "timeframe: 2 section: 362 alpha: 37.50003092537454\n",
      "timeframe: 2 section: 494 alpha: 21.600511105071686\n",
      "timeframe: 3 section: 195 alpha: 8.727866605210426\n",
      "timeframe: 3 section: 308 alpha: 21.11471022976607\n",
      "timeframe: 3 section: 120 alpha: 15.282213642783095\n",
      "timeframe: 2 section: 523 alpha: 17.863931038254247\n",
      "timeframe: 3 section: 162 alpha: 10.657393117794552\n",
      "timeframe: 3 section: 230 alpha: 30.976360598151597\n",
      "timeframe: 3 section: 106 alpha: 36.167901427117066\n",
      "timeframe: 3 section: 86 alpha: 30.194535817507592\n",
      "timeframe: 2 section: 453 alpha: 25.718179717615644\n",
      "timeframe: 2 section: 307 alpha: 16.198269695613604\n",
      "timeframe: 2 section: 418 alpha: 13.270509964293005\n",
      "timeframe: 2 section: 481 alpha: 22.3704302588401\n",
      "timeframe: 2 section: 447 alpha: 11.252717745893044\n",
      "timeframe: 3 section: 155 alpha: 5.603901038601775\n",
      "timeframe: 3 section: 175 alpha: 27.017839584296038\n",
      "timeframe: 3 section: 370 alpha: 33.17764275535024\n",
      "timeframe: 3 section: 22 alpha: 13.9839674779004\n",
      "timeframe: 2 section: 536 alpha: 17.49267904429845\n",
      "timeframe: 3 section: 328 alpha: 11.401626741205206\n",
      "timeframe: 3 section: 223 alpha: 69.60694865951592\n",
      "timeframe: 3 section: 148 alpha: 16.247198168947914\n",
      "timeframe: 2 section: 517 alpha: 40.12450079606862\n",
      "timeframe: 2 section: 335 alpha: 38.21191087541993\n",
      "timeframe: 2 section: 411 alpha: 4.736396008147576\n",
      "timeframe: 2 section: 398 alpha: 5.886883198653346\n",
      "timeframe: 2 section: 348 alpha: 76.78589174447626\n",
      "timeframe: 3 section: 64 alpha: 17.664890367011616\n",
      "timeframe: 3 section: 16 alpha: 13.764837422367123\n",
      "timeframe: 3 section: 397 alpha: 24.049916370701425\n",
      "timeframe: 3 section: 189 alpha: 28.393781669831437\n",
      "timeframe: 3 section: 72 alpha: 12.36776724744131\n",
      "timeframe: 3 section: 266 alpha: 27.108027153899737\n",
      "timeframe: 2 section: 327 alpha: 40.70312273081427\n",
      "timeframe: 3 section: 30 alpha: 23.148395538589323\n",
      "timeframe: 3 section: 127 alpha: 28.48253565189208\n",
      "timeframe: 3 section: 51 alpha: 18.96477708767199\n",
      "timeframe: 2 section: 426 alpha: 10.153226507837143\n",
      "timeframe: 2 section: 404 alpha: 20.506498216808463\n",
      "timeframe: 2 section: 370 alpha: 34.09741605144887\n",
      "timeframe: 3 section: 377 alpha: 36.709250406793196\n",
      "timeframe: 2 section: 503 alpha: 18.353160691815027\n",
      "timeframe: 3 section: 1 alpha: 45.07895115558324\n",
      "timeframe: 2 section: 378 alpha: 30.66749462693212\n",
      "timeframe: 3 section: 217 alpha: 27.12208452862653\n",
      "timeframe: 3 section: 335 alpha: 69.0905038166314\n",
      "timeframe: 2 section: 468 alpha: 42.310255203836334\n",
      "timeframe: 3 section: 140 alpha: 29.714514623846195\n",
      "timeframe: 2 section: 440 alpha: 6.857195022543289\n",
      "timeframe: 2 section: 287 alpha: 29.061890536451003\n",
      "timeframe: 3 section: 99 alpha: 11.29121715385771\n",
      "timeframe: 3 section: 321 alpha: 35.57855822065244\n",
      "timeframe: 3 section: 58 alpha: 47.251217002018635\n",
      "timeframe: 2 section: 343 alpha: 35.52608681597712\n",
      "timeframe: 2 section: 293 alpha: 63.408158898501185\n",
      "timeframe: 3 section: 246 alpha: 22.431439453086217\n",
      "timeframe: 2 section: 550 alpha: 26.762718470129464\n",
      "timeframe: 2 section: 384 alpha: 13.532432813565794\n",
      "timeframe: 3 section: 238 alpha: 36.869833898160515\n",
      "timeframe: 3 section: 405 alpha: 38.756906520095725\n",
      "timeframe: 2 section: 300 alpha: 28.82721158801302\n",
      "timeframe: 2 section: 543 alpha: 13.075201417467625\n",
      "timeframe: 3 section: 273 alpha: 38.2883569275789\n",
      "timeframe: 3 section: 280 alpha: 30.79961125101474\n",
      "timeframe: 3 section: 37 alpha: 7.889884849492386\n",
      "timeframe: 3 section: 412 alpha: 12.676382387889369\n",
      "timeframe: 3 section: 349 alpha: 40.48781172194877\n",
      "timeframe: 2 section: 434 alpha: 66.42907900527771\n",
      "timeframe: 2 section: 488 alpha: 35.818232932457796\n",
      "timeframe: 3 section: 301 alpha: 22.00099574178594\n",
      "timeframe: 2 section: 460 alpha: 35.18166972888031\n",
      "timeframe: 2 section: 524 alpha: 7.146367898908304\n",
      "timeframe: 2 section: 474 alpha: 13.513274712735344\n",
      "timeframe: 3 section: 363 alpha: 18.301842159628563\n",
      "timeframe: 3 section: 113 alpha: 27.998142935553663\n",
      "timeframe: 3 section: 260 alpha: 52.42680051238485\n",
      "timeframe: 3 section: 23 alpha: 28.3947042261586\n",
      "timeframe: 2 section: 363 alpha: 17.260088389010733\n",
      "timeframe: 3 section: 329 alpha: 92.29317038760715\n",
      "timeframe: 3 section: 224 alpha: 37.6693315467859\n",
      "timeframe: 3 section: 371 alpha: 18.149077450930903\n",
      "timeframe: 3 section: 156 alpha: 20.200907103108893\n",
      "timeframe: 3 section: 92 alpha: 20.824710361802346\n",
      "timeframe: 2 section: 314 alpha: 31.92156095796506\n",
      "timeframe: 2 section: 371 alpha: 48.94248737354144\n",
      "timeframe: 2 section: 448 alpha: 99.59744338481967\n",
      "timeframe: 2 section: 392 alpha: 14.445288741014929\n",
      "timeframe: 3 section: 203 alpha: 32.328355987852476\n",
      "timeframe: 2 section: 510 alpha: 11.18509244684476\n",
      "timeframe: 3 section: 390 alpha: 19.974518798999433\n",
      "timeframe: 2 section: 405 alpha: 27.909556582896858\n",
      "timeframe: 3 section: 73 alpha: 0.17945987043229464\n",
      "timeframe: 3 section: 287 alpha: 5.809047108205939\n",
      "timeframe: 2 section: 454 alpha: 22.098208458372536\n",
      "timeframe: 3 section: 418 alpha: 42.02926870581506\n",
      "timeframe: 2 section: 321 alpha: 37.6611400641033\n",
      "timeframe: 2 section: 357 alpha: 37.287834101672786\n",
      "timeframe: 2 section: 308 alpha: 58.735468354625866\n",
      "timeframe: 2 section: 495 alpha: 48.31513988006026\n",
      "timeframe: 3 section: 168 alpha: 32.6030559219473\n",
      "timeframe: 3 section: 336 alpha: 15.77097934151125\n",
      "timeframe: 3 section: 384 alpha: 34.67398546327057\n",
      "timeframe: 2 section: 349 alpha: 38.77277876076483\n",
      "timeframe: 2 section: 482 alpha: 18.72137376648142\n",
      "timeframe: 3 section: 357 alpha: 53.2467133802132\n",
      "timeframe: 3 section: 211 alpha: 17.309558999394607\n",
      "timeframe: 3 section: 343 alpha: 25.52169221559426\n",
      "timeframe: 3 section: 252 alpha: 44.61298438307509\n",
      "timeframe: 2 section: 504 alpha: 28.49843364591706\n",
      "timeframe: 2 section: 336 alpha: 7.5427280421977505\n",
      "timeframe: 3 section: 149 alpha: 103.64375380956953\n",
      "timeframe: 3 section: 309 alpha: 33.48062662406354\n",
      "timeframe: 3 section: 183 alpha: 21.155475152243167\n",
      "timeframe: 2 section: 399 alpha: 9.971426804584137\n",
      "timeframe: 3 section: 398 alpha: 2.356899101674544\n",
      "timeframe: 3 section: 432 alpha: 45.91810501874527\n",
      "timeframe: 3 section: 43 alpha: 32.28437173203741\n",
      "timeframe: 3 section: 196 alpha: 11.101674585602339\n",
      "timeframe: 3 section: 121 alpha: 29.707124082372015\n",
      "timeframe: 2 section: 412 alpha: 17.629459697571406\n",
      "timeframe: 2 section: 419 alpha: 17.537112247461994\n",
      "timeframe: 3 section: 294 alpha: 71.48554393476495\n",
      "timeframe: 3 section: 8 alpha: 10.708158067561127\n",
      "timeframe: 2 section: 518 alpha: 26.119705798104782\n",
      "timeframe: 3 section: 315 alpha: 15.487787101204292\n",
      "timeframe: 3 section: 78 alpha: 40.44244668424271\n",
      "timeframe: 3 section: 93 alpha: 20.735283930579016\n",
      "timeframe: 3 section: 231 alpha: 31.334459888418962\n",
      "timeframe: 2 section: 530 alpha: 36.887212547070924\n",
      "timeframe: 3 section: 52 alpha: 40.957600808853236\n",
      "timeframe: 3 section: 391 alpha: 17.44888118368569\n",
      "timeframe: 3 section: 107 alpha: 36.09479842233626\n",
      "timeframe: 3 section: 204 alpha: 10.185774329594079\n",
      "timeframe: 2 section: 441 alpha: 52.18191580108299\n",
      "timeframe: 3 section: 413 alpha: 48.95018592590373\n",
      "timeframe: 3 section: 31 alpha: 46.1217477527071\n",
      "timeframe: 3 section: 176 alpha: 35.57174813992742\n",
      "timeframe: 3 section: 247 alpha: 83.48688192727481\n",
      "timeframe: 3 section: 87 alpha: 61.04703765930695\n",
      "timeframe: 3 section: 65 alpha: 27.581677650624503\n",
      "timeframe: 2 section: 537 alpha: 41.07050254325808\n",
      "timeframe: 3 section: 163 alpha: 24.219022068685813\n",
      "timeframe: 2 section: 427 alpha: 55.464057937428684\n",
      "timeframe: 3 section: 128 alpha: 33.14644036910582\n",
      "timeframe: 3 section: 114 alpha: 21.95315236041017\n",
      "timeframe: 3 section: 190 alpha: 16.154160526539364\n",
      "timeframe: 3 section: 330 alpha: 6.1825687761655415\n",
      "timeframe: 3 section: 218 alpha: 26.678315306884606\n",
      "timeframe: 3 section: 133 alpha: 40.434029648730615\n",
      "timeframe: 3 section: 141 alpha: 47.741582939067165\n",
      "timeframe: 3 section: 274 alpha: 8.104282476837987\n",
      "timeframe: 2 section: 544 alpha: 9.54977274282825\n",
      "timeframe: 2 section: 294 alpha: 39.647486555475645\n",
      "timeframe: 3 section: 406 alpha: 53.155437077531424\n",
      "timeframe: 3 section: 261 alpha: 15.25947643153075\n",
      "timeframe: 3 section: 24 alpha: 22.170430549231966\n",
      "timeframe: 3 section: 74 alpha: 9.29568131482821\n",
      "timeframe: 2 section: 315 alpha: 26.88380821646988\n",
      "timeframe: 2 section: 475 alpha: 11.637913391853516\n",
      "timeframe: 2 section: 322 alpha: 42.65210655867257\n",
      "timeframe: 3 section: 239 alpha: 52.584697997115704\n",
      "timeframe: 3 section: 2 alpha: 20.083671726145887\n",
      "timeframe: 2 section: 483 alpha: 42.15922948318212\n",
      "timeframe: 3 section: 267 alpha: 8.716045879235613\n",
      "timeframe: 2 section: 301 alpha: 38.289616278693444\n",
      "timeframe: 3 section: 281 alpha: 49.53419316246641\n",
      "timeframe: 3 section: 502 alpha: 4.327206096682704\n",
      "timeframe: 3 section: 59 alpha: 26.50942301324484\n",
      "timeframe: 3 section: 378 alpha: 19.88351578663228\n",
      "timeframe: 2 section: 328 alpha: 22.74082473583955\n",
      "timeframe: 2 section: 525 alpha: 57.94777385714968\n",
      "timeframe: 3 section: 350 alpha: 27.185255699525893\n",
      "timeframe: 3 section: 17 alpha: 19.426709917340144\n",
      "timeframe: 2 section: 413 alpha: 22.68529056431346\n",
      "timeframe: 3 section: 169 alpha: 32.616978252207836\n",
      "timeframe: 3 section: 439 alpha: 16.719551972855392\n",
      "timeframe: 3 section: 358 alpha: 67.26979355916649\n",
      "timeframe: 3 section: 38 alpha: 25.669103502566177\n",
      "timeframe: 3 section: 225 alpha: 38.22996614852481\n",
      "timeframe: 2 section: 469 alpha: 55.6912063138728\n",
      "timeframe: 3 section: 467 alpha: 16.686994533224627\n",
      "timeframe: 3 section: 100 alpha: 19.14559092968554\n",
      "timeframe: 3 section: 425 alpha: 28.86070880682945\n",
      "timeframe: 3 section: 337 alpha: 8.980932660100688\n",
      "timeframe: 2 section: 461 alpha: 48.463427399048655\n",
      "timeframe: 3 section: 474 alpha: 8.857159611634167\n",
      "timeframe: 3 section: 446 alpha: 68.39444940770403\n",
      "timeframe: 3 section: 322 alpha: 59.85299140367584\n",
      "timeframe: 2 section: 455 alpha: 42.89896999840819\n",
      "timeframe: 2 section: 511 alpha: 25.61797441876244\n",
      "timeframe: 3 section: 481 alpha: 29.515734983312115\n",
      "timeframe: 2 section: 489 alpha: 7.033165860802845\n",
      "timeframe: 3 section: 372 alpha: 20.057234583782048\n",
      "timeframe: 3 section: 495 alpha: 77.22253422575199\n",
      "timeframe: 3 section: 302 alpha: 5.4805226999865155\n",
      "timeframe: 2 section: 420 alpha: 16.860499785715174\n",
      "timeframe: 2 section: 496 alpha: 19.291945936951763\n",
      "timeframe: 2 section: 538 alpha: 32.86413803540015\n",
      "timeframe: 2 section: 406 alpha: 34.88674986360774\n",
      "timeframe: 3 section: 460 alpha: 11.770174290203068\n",
      "timeframe: 3 section: 288 alpha: 15.312527833818248\n",
      "timeframe: 3 section: 79 alpha: 47.78056428645566\n",
      "timeframe: 3 section: 453 alpha: 29.518483038591494\n",
      "timeframe: 3 section: 212 alpha: 31.716456961417034\n",
      "timeframe: 3 section: 108 alpha: 15.807748896650157\n",
      "timeframe: 3 section: 295 alpha: 20.682631497126447\n",
      "timeframe: 2 section: 364 alpha: 20.280890486146077\n",
      "timeframe: 4 section: 9 alpha: 40.630441936363006\n",
      "timeframe: 3 section: 205 alpha: 34.24087815174963\n",
      "timeframe: 2 section: 551 alpha: 19.088861599505243\n",
      "timeframe: 3 section: 157 alpha: 35.924614635564254\n",
      "timeframe: 3 section: 94 alpha: 7.978959258295244\n",
      "timeframe: 4 section: 16 alpha: 123.95393767553786\n",
      "timeframe: 3 section: 385 alpha: 79.20122989080079\n",
      "timeframe: 3 section: 275 alpha: 5.714636435745785\n",
      "timeframe: 2 section: 385 alpha: 11.469143629315244\n",
      "timeframe: 3 section: 399 alpha: 17.274316023096976\n",
      "timeframe: 3 section: 440 alpha: 21.47180007286057\n",
      "timeframe: 2 section: 350 alpha: 24.70075917448996\n",
      "timeframe: 3 section: 66 alpha: 3.9450809205457014\n",
      "timeframe: 3 section: 344 alpha: 50.8042025104731\n",
      "timeframe: 4 section: 30 alpha: 7.1402596674695795\n",
      "timeframe: 4 section: 23 alpha: 40.053337011240345\n",
      "timeframe: 4 section: 2 alpha: 33.714021968743104\n",
      "timeframe: 2 section: 476 alpha: 10.972192907894522\n",
      "timeframe: 3 section: 364 alpha: 24.490415540419882\n",
      "timeframe: 3 section: 9 alpha: 26.79454896365904\n",
      "timeframe: 3 section: 248 alpha: 141.08276583039054\n",
      "timeframe: 3 section: 122 alpha: 15.047509473506402\n",
      "timeframe: 3 section: 18 alpha: 13.662739243646257\n",
      "timeframe: 3 section: 197 alpha: 14.412398080445435\n",
      "timeframe: 3 section: 170 alpha: 30.052061458006676\n",
      "timeframe: 3 section: 544 alpha: 7.380096724189202\n",
      "timeframe: 3 section: 32 alpha: 56.68164122426367\n",
      "timeframe: 3 section: 60 alpha: 5.7127076554492335\n",
      "timeframe: 3 section: 150 alpha: 28.00826118756461\n",
      "timeframe: 4 section: 37 alpha: 7.699870922476338\n",
      "timeframe: 3 section: 488 alpha: 36.54402214746024\n",
      "timeframe: 3 section: 516 alpha: 19.19879882586521\n",
      "timeframe: 4 section: 51 alpha: 66.44506765100903\n",
      "timeframe: 4 section: 44 alpha: 38.05794044851691\n",
      "timeframe: 3 section: 164 alpha: 6.859241403020317\n",
      "timeframe: 3 section: 3 alpha: 61.53829774371485\n",
      "timeframe: 3 section: 331 alpha: 9.415926238826973\n",
      "timeframe: 3 section: 177 alpha: 26.448302000546747\n",
      "timeframe: 3 section: 44 alpha: 5.267673544645968\n",
      "timeframe: 3 section: 310 alpha: 56.25713473591761\n",
      "timeframe: 3 section: 419 alpha: 44.20150339332603\n",
      "timeframe: 3 section: 184 alpha: 28.19916445558985\n",
      "timeframe: 3 section: 253 alpha: 22.220457472004927\n",
      "timeframe: 3 section: 468 alpha: 26.718202287554504\n",
      "timeframe: 3 section: 523 alpha: 14.77155840310223\n",
      "timeframe: 3 section: 537 alpha: 125.37120001695583\n",
      "timeframe: 3 section: 503 alpha: 7.788292131156459\n",
      "timeframe: 3 section: 219 alpha: 3.798119907222088\n",
      "timeframe: 3 section: 191 alpha: 29.085711235561355\n",
      "timeframe: 3 section: 392 alpha: 90.02288948991706\n",
      "timeframe: 3 section: 379 alpha: 19.392924870883366\n",
      "timeframe: 3 section: 115 alpha: 54.8291775376378\n",
      "timeframe: 3 section: 268 alpha: 1.5541173980173335\n",
      "timeframe: 3 section: 316 alpha: 88.14158945626923\n",
      "timeframe: 3 section: 232 alpha: 6.333469118286738\n",
      "timeframe: 2 section: 531 alpha: 14.584211642978\n",
      "timeframe: 4 section: 58 alpha: 18.97366384364995\n",
      "timeframe: 3 section: 433 alpha: 14.075147130495898\n",
      "timeframe: 3 section: 53 alpha: 36.66450729099858\n",
      "timeframe: 2 section: 490 alpha: 15.063679260184834\n",
      "timeframe: 3 section: 407 alpha: 21.867688382688957\n",
      "timeframe: 4 section: 17 alpha: 11.592437495475341\n",
      "timeframe: 4 section: 10 alpha: 9.943197578107036\n",
      "timeframe: 3 section: 25 alpha: 37.57858364104829\n",
      "timeframe: 3 section: 509 alpha: 54.873760782816866\n",
      "timeframe: 3 section: 129 alpha: 15.147208284873056\n",
      "timeframe: 2 section: 329 alpha: 13.435302038787977\n",
      "timeframe: 4 section: 65 alpha: 27.12803709979647\n",
      "timeframe: 3 section: 282 alpha: 15.50373316090932\n",
      "timeframe: 4 section: 24 alpha: 12.1071792632996\n",
      "timeframe: 4 section: 72 alpha: 29.870904359980404\n",
      "timeframe: 4 section: 79 alpha: 25.419321631754826\n",
      "timeframe: 4 section: 31 alpha: 51.35204726444804\n",
      "timeframe: 3 section: 249 alpha: 38.517313844874934\n",
      "timeframe: 4 section: 86 alpha: 28.319354800467824\n",
      "timeframe: 4 section: 93 alpha: 18.305678580741862\n",
      "timeframe: 3 section: 373 alpha: 16.283402678852998\n",
      "timeframe: 3 section: 551 alpha: 65.41222514188854\n",
      "timeframe: 3 section: 338 alpha: 5.333591633272107\n",
      "timeframe: 3 section: 482 alpha: 17.862290976146394\n",
      "timeframe: 3 section: 426 alpha: 55.08651083735303\n",
      "timeframe: 3 section: 142 alpha: 30.28876255122676\n",
      "timeframe: 3 section: 134 alpha: 92.85202789920615\n",
      "timeframe: 2 section: 539 alpha: 19.586636295847107\n",
      "timeframe: 3 section: 67 alpha: 45.34468055180147\n",
      "timeframe: 3 section: 88 alpha: 50.672004294834714\n",
      "timeframe: 4 section: 3 alpha: 30.6109281510275\n",
      "timeframe: 4 section: 38 alpha: 62.63198213497086\n",
      "timeframe: 4 section: 45 alpha: 8.029975721922536\n",
      "timeframe: 3 section: 39 alpha: 28.083084737394195\n",
      "timeframe: 4 section: 52 alpha: 52.10101409967745\n",
      "timeframe: 4 section: 107 alpha: 31.51079973414003\n",
      "timeframe: 3 section: 530 alpha: 44.41202397816681\n",
      "timeframe: 4 section: 100 alpha: 19.755811908788512\n",
      "timeframe: 2 section: 545 alpha: 67.15807677374212\n",
      "timeframe: 3 section: 123 alpha: 54.84077331819899\n",
      "timeframe: 3 section: 447 alpha: 11.21424940818378\n",
      "timeframe: 3 section: 10 alpha: 10.976786749456531\n",
      "timeframe: 3 section: 359 alpha: 57.516386971151945\n",
      "timeframe: 4 section: 114 alpha: 12.666391537594679\n",
      "timeframe: 3 section: 80 alpha: 6.635764178529918\n",
      "timeframe: 2 section: 552 alpha: 21.772303057289758\n",
      "timeframe: 3 section: 240 alpha: 34.418019955886784\n",
      "timeframe: 3 section: 380 alpha: 30.820863906150002\n",
      "timeframe: 4 section: 66 alpha: 79.40085618909359\n",
      "timeframe: 3 section: 206 alpha: 22.91868139876421\n",
      "timeframe: 4 section: 11 alpha: 21.709243350637667\n",
      "timeframe: 3 section: 276 alpha: 5.2215759398487105\n",
      "timeframe: 3 section: 226 alpha: 35.43378671253277\n",
      "timeframe: 3 section: 101 alpha: 35.361140402964686\n",
      "timeframe: 2 section: 462 alpha: 39.668660083264236\n",
      "timeframe: 3 section: 262 alpha: 56.23292439974643\n",
      "timeframe: 3 section: 400 alpha: 17.001230709757078\n",
      "timeframe: 4 section: 135 alpha: 27.37516934095335\n",
      "timeframe: 4 section: 18 alpha: 21.17300807709102\n",
      "timeframe: 3 section: 496 alpha: 50.17961402536612\n",
      "timeframe: 4 section: 94 alpha: 19.765378527809332\n",
      "timeframe: 2 section: 497 alpha: 61.150519179447784\n",
      "timeframe: 4 section: 25 alpha: 27.8443569366654\n",
      "timeframe: 3 section: 233 alpha: 1.5671026424575365\n",
      "timeframe: 4 section: 121 alpha: 54.21677980581744\n",
      "timeframe: 4 section: 32 alpha: 30.142187312877837\n",
      "timeframe: 4 section: 80 alpha: 15.528884375816153\n",
      "timeframe: 3 section: 109 alpha: 31.275316674591874\n",
      "timeframe: 4 section: 73 alpha: 2.4498253074966287\n",
      "timeframe: 3 section: 323 alpha: 76.36404990079456\n",
      "timeframe: 3 section: 254 alpha: 7.85851612620772\n",
      "timeframe: 4 section: 170 alpha: 93.78478576445124\n",
      "timeframe: 3 section: 158 alpha: 48.588684252250495\n",
      "timeframe: 4 section: 87 alpha: 35.69575607624891\n",
      "timeframe: 3 section: 414 alpha: 44.402935366382806\n",
      "timeframe: 4 section: 142 alpha: 19.873090055169243\n",
      "timeframe: 4 section: 4 alpha: 11.789707863843528\n",
      "timeframe: 3 section: 303 alpha: 71.18618653179341\n",
      "timeframe: 3 section: 332 alpha: 3.697872310236767\n",
      "timeframe: 4 section: 39 alpha: 41.42698284320029\n",
      "timeframe: 4 section: 59 alpha: 34.254326643132295\n",
      "timeframe: 3 section: 345 alpha: 82.01720075307365\n",
      "timeframe: 4 section: 108 alpha: 17.48967452354523\n",
      "timeframe: 3 section: 351 alpha: 32.93673283840199\n",
      "timeframe: 4 section: 128 alpha: 31.75693796535363\n",
      "timeframe: 4 section: 156 alpha: 24.076522300595066\n",
      "timeframe: 3 section: 504 alpha: 26.121834708723537\n",
      "timeframe: 3 section: 524 alpha: 4.986573335176843\n",
      "timeframe: 3 section: 296 alpha: 27.819291634392663\n",
      "timeframe: 4 section: 163 alpha: 30.12809549578118\n",
      "timeframe: 3 section: 475 alpha: 47.63058663956202\n",
      "timeframe: 3 section: 185 alpha: 6.827427100245201\n",
      "timeframe: 3 section: 213 alpha: 21.02708042872076\n",
      "timeframe: 3 section: 289 alpha: 52.21351144907929\n",
      "timeframe: 3 section: 339 alpha: 186.81937091120363\n",
      "timeframe: 4 section: 67 alpha: 31.528096080218653\n",
      "timeframe: 3 section: 171 alpha: 21.933315267007753\n",
      "timeframe: 3 section: 4 alpha: 91.36748361238217\n",
      "timeframe: 4 section: 101 alpha: 38.34277030004953\n",
      "timeframe: 3 section: 386 alpha: 39.99924014033796\n",
      "timeframe: 4 section: 46 alpha: 27.240987494841892\n",
      "timeframe: 3 section: 365 alpha: 26.869497805103247\n",
      "timeframe: 3 section: 517 alpha: 24.299993544315033\n",
      "timeframe: 3 section: 454 alpha: 27.400395989876262\n",
      "timeframe: 4 section: 177 alpha: 50.41389400137873\n",
      "timeframe: 3 section: 441 alpha: 15.338611595851336\n",
      "timeframe: 4 section: 53 alpha: 26.72467256549536\n",
      "timeframe: 3 section: 143 alpha: 159.43325354631162\n",
      "timeframe: 3 section: 45 alpha: 12.26586278575696\n",
      "timeframe: 4 section: 149 alpha: 30.579006452895456\n",
      "timeframe: 3 section: 374 alpha: 20.26845241795183\n",
      "timeframe: 3 section: 178 alpha: 52.639307235199595\n",
      "timeframe: 4 section: 12 alpha: 54.11867380978684\n",
      "timeframe: 3 section: 393 alpha: 27.619176257974235\n",
      "timeframe: 3 section: 461 alpha: 42.07619801012955\n",
      "timeframe: 3 section: 317 alpha: 24.954240543076835\n",
      "timeframe: 4 section: 115 alpha: 126.14520793865137\n",
      "timeframe: 3 section: 469 alpha: 40.85473898416494\n",
      "timeframe: 3 section: 135 alpha: 9.619912998183764\n",
      "timeframe: 4 section: 184 alpha: 42.05315978588725\n",
      "timeframe: 3 section: 483 alpha: 21.643728940562426\n",
      "timeframe: 3 section: 95 alpha: 20.2401511071183\n",
      "timeframe: 4 section: 191 alpha: 51.660478310809125\n",
      "timeframe: 3 section: 545 alpha: 69.12984199712155\n",
      "timeframe: 3 section: 81 alpha: 5.906181526621717\n",
      "timeframe: 2 section: 546 alpha: 11.035727349099098\n",
      "timeframe: 4 section: 5 alpha: 5.298558553065205\n",
      "timeframe: 4 section: 198 alpha: 32.91283653932588\n",
      "timeframe: 4 section: 19 alpha: 45.15485152448354\n",
      "timeframe: 4 section: 136 alpha: 30.358511811996973\n",
      "timeframe: 4 section: 143 alpha: 176.46171632172982\n",
      "timeframe: 4 section: 74 alpha: 13.083694190846233\n",
      "timeframe: 4 section: 81 alpha: 16.668970571448565\n",
      "timeframe: 3 section: 165 alpha: 34.29093177888391\n",
      "timeframe: 3 section: 130 alpha: 75.74689438863902\n",
      "timeframe: 3 section: 311 alpha: 46.10179200002767\n",
      "timeframe: 4 section: 88 alpha: 28.797924122971807\n",
      "timeframe: 4 section: 171 alpha: 28.974192549187606\n",
      "timeframe: 4 section: 205 alpha: 35.795455543776285\n",
      "timeframe: 4 section: 33 alpha: 48.74886148689102\n",
      "timeframe: 4 section: 109 alpha: 17.459379840313453\n",
      "timeframe: 3 section: 489 alpha: 31.039042006330334\n",
      "timeframe: 3 section: 269 alpha: 13.575631293118835\n",
      "timeframe: 3 section: 241 alpha: 17.10056695580596\n",
      "timeframe: 4 section: 157 alpha: 25.13558675661237\n",
      "timeframe: 2 section: 532 alpha: 23.339307463131686\n",
      "timeframe: 4 section: 60 alpha: 1.2217331332239236\n",
      "timeframe: 4 section: 95 alpha: 13.987080587668526\n",
      "timeframe: 3 section: 116 alpha: 34.836046951920416\n",
      "timeframe: 4 section: 122 alpha: 85.04369844374467\n",
      "timeframe: 3 section: 510 alpha: 51.63997064002352\n",
      "timeframe: 3 section: 220 alpha: 20.2757233037834\n",
      "timeframe: 4 section: 164 alpha: 53.23410095142199\n",
      "timeframe: 3 section: 448 alpha: 4.531851994789432\n",
      "timeframe: 4 section: 129 alpha: 35.227176054583694\n",
      "timeframe: 4 section: 47 alpha: 23.522273100659497\n",
      "timeframe: 3 section: 538 alpha: 56.67735954094958\n",
      "timeframe: 3 section: 420 alpha: 48.17337844638183\n",
      "timeframe: 4 section: 68 alpha: 10.362225165738497\n",
      "timeframe: 4 section: 26 alpha: 7.0698455969953455\n",
      "timeframe: 4 section: 40 alpha: 50.05627865364337\n",
      "timeframe: 4 section: 102 alpha: 19.22907187234102\n",
      "timeframe: 4 section: 212 alpha: 34.5017015075189\n",
      "timeframe: 4 section: 54 alpha: 22.134050177930916\n",
      "timeframe: 3 section: 151 alpha: 32.77379346300473\n",
      "timeframe: 4 section: 178 alpha: 60.51780179298776\n",
      "timeframe: 4 section: 150 alpha: 19.839693698990455\n",
      "timeframe: 3 section: 552 alpha: 38.85324738791488\n",
      "timeframe: 4 section: 13 alpha: 45.52152282562735\n",
      "timeframe: 3 section: 360 alpha: 0.11917134977674324\n",
      "timeframe: 3 section: 427 alpha: 60.25913017762875\n",
      "timeframe: 3 section: 408 alpha: 29.362721709382395\n",
      "timeframe: 4 section: 137 alpha: 8.580604832540866\n",
      "timeframe: 3 section: 531 alpha: 7.30916275288905\n",
      "timeframe: 4 section: 185 alpha: 38.44052878478103\n",
      "timeframe: 2 section: 553 alpha: 34.188243990015536\n",
      "timeframe: 4 section: 226 alpha: 30.21495212087623\n",
      "timeframe: 3 section: 11 alpha: 49.74484331343944\n",
      "timeframe: 3 section: 198 alpha: 31.507562361797046\n",
      "timeframe: 4 section: 116 alpha: 68.94593314089927\n",
      "timeframe: 4 section: 20 alpha: 15.315210110717958\n",
      "timeframe: 3 section: 102 alpha: 29.876307192847126\n",
      "timeframe: 4 section: 219 alpha: 13.68895449398792\n",
      "timeframe: 4 section: 233 alpha: 4.111615290440502\n",
      "timeframe: 4 section: 6 alpha: 64.6338341127339\n",
      "timeframe: 4 section: 199 alpha: 17.88101773972136\n",
      "timeframe: 4 section: 144 alpha: 25.118549840574367\n",
      "timeframe: 3 section: 352 alpha: 9.157084501173962\n",
      "timeframe: 4 section: 192 alpha: 27.295318756769696\n",
      "timeframe: 4 section: 247 alpha: 26.665662027834045\n",
      "timeframe: 4 section: 89 alpha: 29.592631779143463\n",
      "timeframe: 4 section: 34 alpha: 19.028472331812875\n",
      "timeframe: 3 section: 283 alpha: 34.53214697198971\n",
      "timeframe: 3 section: 192 alpha: 16.866206290867446\n",
      "timeframe: 3 section: 340 alpha: 27.047053026561752\n",
      "timeframe: 3 section: 505 alpha: 11.890808502540708\n",
      "timeframe: 3 section: 144 alpha: 37.432561996193954\n",
      "timeframe: 4 section: 110 alpha: 34.95746490468492\n",
      "timeframe: 4 section: 240 alpha: 21.575277347839698\n",
      "timeframe: 3 section: 277 alpha: 8.10494140742507\n",
      "timeframe: 3 section: 234 alpha: 22.950277602649848\n",
      "timeframe: 3 section: 297 alpha: 6.385846178848886\n",
      "timeframe: 4 section: 75 alpha: 45.56336078524376\n",
      "timeframe: 3 section: 375 alpha: 23.322184921093186\n",
      "timeframe: 4 section: 172 alpha: 23.677332106396747\n",
      "timeframe: 4 section: 48 alpha: 10.83273415921639\n",
      "timeframe: 4 section: 96 alpha: 24.99891959327859\n",
      "timeframe: 4 section: 254 alpha: 6.392005684165447\n",
      "timeframe: 4 section: 206 alpha: 50.197865913222806\n",
      "timeframe: 4 section: 61 alpha: 32.54335758888658\n",
      "timeframe: 4 section: 123 alpha: 15.402993963148608\n",
      "timeframe: 3 section: 525 alpha: 35.01733449553428\n",
      "timeframe: 4 section: 82 alpha: 73.54266948785212\n",
      "timeframe: 3 section: 263 alpha: 11.768121149923209\n",
      "timeframe: 3 section: 207 alpha: 35.288624671202314\n",
      "timeframe: 4 section: 27 alpha: 8.237919050308076\n",
      "timeframe: 3 section: 333 alpha: 45.31069930358932\n",
      "timeframe: 3 section: 214 alpha: 11.892104130300728\n",
      "timeframe: 4 section: 165 alpha: 46.033486049423054\n",
      "timeframe: 3 section: 227 alpha: 25.75769979277342\n",
      "timeframe: 3 section: 324 alpha: 26.45471202319203\n",
      "timeframe: 4 section: 69 alpha: 10.977826508579184\n",
      "timeframe: 4 section: 261 alpha: 8.622907990843041\n",
      "timeframe: 4 section: 158 alpha: 63.019879640798436\n",
      "timeframe: 3 section: 394 alpha: 10.906590376618981\n",
      "timeframe: 4 section: 130 alpha: 29.631226860350765\n",
      "timeframe: 4 section: 41 alpha: 40.5298248772774\n",
      "timeframe: 3 section: 136 alpha: 17.91210769208259\n",
      "timeframe: 4 section: 14 alpha: 8.569542072288035\n",
      "timeframe: 4 section: 179 alpha: 7.767012816003643\n",
      "timeframe: 4 section: 213 alpha: 32.25003438791374\n",
      "timeframe: 3 section: 434 alpha: 13.04753081756864\n",
      "timeframe: 3 section: 242 alpha: 13.028527768089383\n",
      "timeframe: 3 section: 186 alpha: 23.30108456676574\n",
      "timeframe: 3 section: 470 alpha: 24.65880175226424\n",
      "timeframe: 4 section: 227 alpha: 10.177756720390738\n",
      "timeframe: 3 section: 346 alpha: 16.8730144963954\n",
      "timeframe: 4 section: 55 alpha: 3.5389258675070847\n",
      "timeframe: 4 section: 145 alpha: 24.42234330342397\n",
      "timeframe: 4 section: 103 alpha: 28.823054277330062\n",
      "timeframe: 4 section: 117 alpha: 20.950149894730977\n",
      "timeframe: 4 section: 275 alpha: 4.844086406749457\n",
      "timeframe: 4 section: 248 alpha: 168.45174546126404\n",
      "timeframe: 4 section: 138 alpha: 42.145006790103906\n",
      "timeframe: 3 section: 476 alpha: 12.775293777038137\n",
      "timeframe: 4 section: 151 alpha: 13.8537156358601\n",
      "timeframe: 3 section: 401 alpha: 24.662692312750387\n",
      "timeframe: 4 section: 234 alpha: 22.64270759609435\n",
      "timeframe: 4 section: 282 alpha: 34.230566479197876\n",
      "timeframe: 3 section: 304 alpha: 51.54586240128987\n",
      "timeframe: 3 section: 497 alpha: 25.395785501813723\n",
      "timeframe: 4 section: 268 alpha: 0.05840987282895103\n",
      "timeframe: 4 section: 220 alpha: 25.285475002157522\n",
      "timeframe: 3 section: 381 alpha: 22.880366902230072\n",
      "timeframe: 4 section: 200 alpha: 19.483153533516003\n",
      "timeframe: 4 section: 186 alpha: 28.32153294223793\n",
      "timeframe: 4 section: 49 alpha: 7.891151387504224\n",
      "timeframe: 4 section: 21 alpha: 24.797089159361473\n",
      "timeframe: 3 section: 546 alpha: 28.179292004557194\n",
      "timeframe: 3 section: 449 alpha: 7.079716286311815\n",
      "timeframe: 4 section: 7 alpha: 19.431782090931826\n",
      "timeframe: 3 section: 290 alpha: 71.36258403359021\n",
      "timeframe: 4 section: 289 alpha: 34.074994439107414\n",
      "timeframe: 4 section: 241 alpha: 50.96168318767486\n",
      "timeframe: 4 section: 90 alpha: 21.32683411119898\n",
      "timeframe: 4 section: 296 alpha: 48.4579956460657\n",
      "timeframe: 3 section: 490 alpha: 27.74843147621242\n",
      "timeframe: 4 section: 193 alpha: 34.7389507054891\n",
      "timeframe: 4 section: 76 alpha: 62.49171186511358\n",
      "timeframe: 4 section: 62 alpha: 20.120652295366636\n",
      "timeframe: 4 section: 255 alpha: 81.80289370227841\n",
      "timeframe: 4 section: 124 alpha: 37.02830719681213\n",
      "timeframe: 4 section: 173 alpha: 37.60486737946482\n",
      "timeframe: 4 section: 111 alpha: 22.860730966713056\n",
      "timeframe: 3 section: 442 alpha: 11.746768767416615\n",
      "timeframe: 3 section: 366 alpha: 52.96052729914799\n",
      "timeframe: 4 section: 35 alpha: 23.098060374806046\n",
      "timeframe: 4 section: 262 alpha: 27.29157321865556\n",
      "timeframe: 4 section: 97 alpha: 33.911505343190846\n",
      "timeframe: 3 section: 387 alpha: 44.00736643585603\n",
      "timeframe: 4 section: 303 alpha: 72.29024672118008\n",
      "timeframe: 4 section: 207 alpha: 37.69191803210387\n",
      "timeframe: 4 section: 310 alpha: 43.775766319790584\n",
      "timeframe: 4 section: 317 alpha: 50.17143332395241\n",
      "timeframe: 4 section: 345 alpha: 63.18454983868785\n",
      "timeframe: 3 section: 518 alpha: 42.74816593032081\n",
      "timeframe: 3 section: 511 alpha: 29.162083078539744\n",
      "timeframe: 3 section: 312 alpha: 32.238671263650396\n",
      "timeframe: 4 section: 331 alpha: 67.75887051855156\n",
      "timeframe: 4 section: 83 alpha: 33.71485907674447\n",
      "timeframe: 3 section: 318 alpha: 59.433117745537906\n",
      "timeframe: 4 section: 42 alpha: 30.274765745662304\n",
      "timeframe: 4 section: 70 alpha: 7.469941286794341\n",
      "timeframe: 4 section: 15 alpha: 31.22844379601518\n",
      "timeframe: 3 section: 270 alpha: 32.28182349589035\n",
      "timeframe: 4 section: 214 alpha: 7.795075022272686\n",
      "timeframe: 4 section: 324 alpha: 27.93570840086243\n",
      "timeframe: 4 section: 166 alpha: 45.10257219039491\n",
      "timeframe: 4 section: 180 alpha: 39.84560671033414\n",
      "timeframe: 4 section: 159 alpha: 19.599806151053873\n",
      "timeframe: 4 section: 56 alpha: 3.4224416117374705\n",
      "timeframe: 3 section: 353 alpha: 12.628779959859742\n",
      "timeframe: 4 section: 338 alpha: 21.145712581348867\n",
      "timeframe: 3 section: 506 alpha: 24.87605221198589\n",
      "timeframe: 4 section: 118 alpha: 22.760305015707733\n",
      "timeframe: 3 section: 255 alpha: 78.40743463384175\n",
      "timeframe: 4 section: 104 alpha: 22.561913098041654\n",
      "timeframe: 4 section: 249 alpha: 26.24076302121022\n",
      "timeframe: 4 section: 359 alpha: 20.11924398005362\n",
      "timeframe: 4 section: 276 alpha: 8.704217204559836\n",
      "timeframe: 4 section: 352 alpha: 26.981816570987085\n",
      "timeframe: 4 section: 228 alpha: 4.021288667875751\n",
      "timeframe: 3 section: 484 alpha: 28.221897756728104\n",
      "timeframe: 3 section: 415 alpha: 33.05051056956824\n",
      "timeframe: 4 section: 146 alpha: 15.71607926910962\n",
      "timeframe: 3 section: 46 alpha: 11.216159393631306\n",
      "timeframe: 3 section: 361 alpha: 15.31238578319146\n",
      "timeframe: 3 section: 137 alpha: 38.70337004097091\n",
      "timeframe: 4 section: 201 alpha: 42.96113052604515\n",
      "timeframe: 3 section: 193 alpha: 14.965899356728606\n",
      "timeframe: 4 section: 131 alpha: 20.96439548191693\n",
      "timeframe: 3 section: 298 alpha: 9.898759752541238\n",
      "timeframe: 4 section: 50 alpha: 34.12280586235867\n",
      "timeframe: 4 section: 283 alpha: 44.21262458194552\n",
      "timeframe: 4 section: 297 alpha: 10.434124971242419\n",
      "timeframe: 4 section: 28 alpha: 48.75915245785008\n",
      "timeframe: 4 section: 269 alpha: 6.1578412240078295\n",
      "timeframe: 3 section: 539 alpha: 49.5233608679334\n",
      "timeframe: 4 section: 235 alpha: 35.18670006111842\n",
      "timeframe: 4 section: 152 alpha: 52.81020782207707\n",
      "timeframe: 4 section: 221 alpha: 49.49245183547808\n",
      "timeframe: 4 section: 187 alpha: 13.663280157879134\n",
      "timeframe: 4 section: 290 alpha: 15.430036536936477\n",
      "timeframe: 4 section: 242 alpha: 38.170771406057845\n",
      "timeframe: 3 section: 455 alpha: 17.453433471367877\n",
      "timeframe: 3 section: 462 alpha: 48.84709830231145\n",
      "timeframe: 3 section: 221 alpha: 37.67548718247669\n",
      "timeframe: 4 section: 139 alpha: 13.35834359120028\n",
      "timeframe: 3 section: 532 alpha: 13.237720602498129\n",
      "timeframe: 3 section: 179 alpha: 80.72111839596306\n",
      "timeframe: 4 section: 77 alpha: 62.637450224724944\n",
      "timeframe: 4 section: 22 alpha: 11.511116842864324\n",
      "timeframe: 4 section: 263 alpha: 20.10818215940122\n",
      "timeframe: 4 section: 194 alpha: 23.581079070401476\n",
      "timeframe: 4 section: 373 alpha: 7.441411913037303\n",
      "timeframe: 4 section: 98 alpha: 26.74339526290131\n",
      "timeframe: 4 section: 208 alpha: 1.3418849285358525\n",
      "timeframe: 4 section: 256 alpha: 25.40370867437455\n",
      "timeframe: 4 section: 63 alpha: 19.56827093303407\n",
      "timeframe: 4 section: 8 alpha: 44.70814774793787\n",
      "timeframe: 3 section: 228 alpha: 7.017256398105832\n",
      "timeframe: 3 section: 235 alpha: 38.70783316365011\n",
      "timeframe: 3 section: 450 alpha: 43.5644704588825\n",
      "timeframe: 4 section: 332 alpha: 15.762227280464446\n",
      "timeframe: 3 section: 395 alpha: 55.57133952783433\n",
      "timeframe: 4 section: 167 alpha: 19.851276782188236\n",
      "timeframe: 3 section: 428 alpha: 49.18364499380532\n",
      "timeframe: 4 section: 181 alpha: 22.843509864181655\n",
      "timeframe: 4 section: 318 alpha: 28.06112280516857\n",
      "timeframe: 4 section: 304 alpha: 51.198786090796865\n",
      "timeframe: 3 section: 409 alpha: 12.90952034035647\n",
      "timeframe: 4 section: 36 alpha: 9.960585224668328\n",
      "timeframe: 4 section: 112 alpha: 17.409796436157343\n",
      "timeframe: 4 section: 174 alpha: 40.06313515055215\n",
      "timeframe: 4 section: 339 alpha: 9.890662047284579\n",
      "timeframe: 4 section: 366 alpha: 34.420928162073935\n",
      "timeframe: 4 section: 380 alpha: 121.08475344927197\n",
      "timeframe: 3 section: 172 alpha: 28.983569894650845\n",
      "timeframe: 3 section: 553 alpha: 48.339915365054324\n",
      "timeframe: 3 section: 284 alpha: 26.639158491413863\n",
      "timeframe: 4 section: 125 alpha: 36.80759004334412\n",
      "timeframe: 4 section: 43 alpha: 28.967873033332165\n",
      "timeframe: 4 section: 160 alpha: 99.96207566686869\n",
      "timeframe: 4 section: 71 alpha: 22.05023465050536\n",
      "timeframe: 4 section: 360 alpha: 81.64481104666703\n",
      "timeframe: 4 section: 277 alpha: 10.45610892245083\n",
      "timeframe: 4 section: 311 alpha: 62.45021547432452\n",
      "timeframe: 4 section: 84 alpha: 20.778205702835994\n",
      "timeframe: 4 section: 119 alpha: 15.755168012934565\n",
      "timeframe: 4 section: 353 alpha: 13.665618066549166\n",
      "timeframe: 4 section: 57 alpha: 22.65729667810393\n",
      "timeframe: 4 section: 105 alpha: 18.590388810273513\n",
      "timeframe: 4 section: 147 alpha: 28.29817949153524\n",
      "timeframe: 4 section: 250 alpha: 44.90185543329708\n",
      "timeframe: 3 section: 471 alpha: 13.366199098185227\n",
      "timeframe: 4 section: 346 alpha: 29.21790978601455\n",
      "timeframe: 4 section: 91 alpha: 43.21094248140361\n",
      "timeframe: 3 section: 507 alpha: 22.608829140513052\n",
      "timeframe: 4 section: 229 alpha: 43.98084948859738\n",
      "timeframe: 4 section: 215 alpha: 40.549714034315976\n",
      "timeframe: 4 section: 298 alpha: 69.07345376523381\n",
      "timeframe: 3 section: 421 alpha: 32.622060524173165\n",
      "timeframe: 4 section: 422 alpha: 5.615056346659833\n",
      "timeframe: 4 section: 270 alpha: 20.307690970750976\n",
      "timeframe: 4 section: 401 alpha: 37.560487806270295\n",
      "timeframe: 4 section: 325 alpha: 46.43711586734274\n",
      "timeframe: 3 section: 435 alpha: 41.66285139856966\n",
      "timeframe: 4 section: 202 alpha: 28.48898014489116\n",
      "timeframe: 3 section: 354 alpha: 24.86508637116814\n",
      "timeframe: 4 section: 387 alpha: 13.448573575176896\n",
      "timeframe: 3 section: 388 alpha: 5.3744806111982015\n",
      "timeframe: 4 section: 284 alpha: 13.017479444149826\n",
      "timeframe: 4 section: 408 alpha: 35.77004945490404\n",
      "timeframe: 4 section: 374 alpha: 6.325521497669625\n",
      "timeframe: 4 section: 394 alpha: 21.19712124648722\n",
      "timeframe: 4 section: 429 alpha: 22.50468508006115\n",
      "timeframe: 4 section: 415 alpha: 45.98587212744995\n",
      "timeframe: 3 section: 512 alpha: 7.858729098412525\n",
      "timeframe: 4 section: 243 alpha: 12.528917337684934\n",
      "timeframe: 4 section: 188 alpha: 34.41499022742884\n",
      "timeframe: 3 section: 443 alpha: 40.19712907791308\n",
      "timeframe: 4 section: 209 alpha: 4.32809354074208\n",
      "timeframe: 3 section: 199 alpha: 28.344497329375006\n",
      "timeframe: 4 section: 29 alpha: 17.356396707311387\n",
      "timeframe: 4 section: 436 alpha: 39.44904181723311\n",
      "timeframe: 4 section: 153 alpha: 62.344242116631484\n",
      "timeframe: 4 section: 257 alpha: 1.2436496927136411\n",
      "timeframe: 4 section: 132 alpha: 24.736745492932638\n",
      "timeframe: 4 section: 264 alpha: 5.426558618346356\n",
      "timeframe: 4 section: 443 alpha: 66.84557753032152\n",
      "timeframe: 3 section: 547 alpha: 40.528115754346324\n",
      "timeframe: 3 section: 382 alpha: 5.847967761637413\n",
      "timeframe: 4 section: 195 alpha: 27.56096633185151\n",
      "timeframe: 4 section: 450 alpha: 26.523404657740613\n",
      "timeframe: 3 section: 325 alpha: 33.023607320057245\n",
      "timeframe: 4 section: 99 alpha: 22.702997817083904\n",
      "timeframe: 4 section: 291 alpha: 16.102353652276918\n",
      "timeframe: 4 section: 222 alpha: 35.65569498845356\n",
      "timeframe: 4 section: 457 alpha: 36.08811638451133\n",
      "timeframe: 4 section: 471 alpha: 67.42820625523457\n",
      "timeframe: 4 section: 319 alpha: 29.41377209658491\n",
      "timeframe: 4 section: 64 alpha: 28.18672375886859\n",
      "timeframe: 3 section: 526 alpha: 40.11387253722251\n",
      "timeframe: 3 section: 519 alpha: 12.850314369123307\n",
      "timeframe: 4 section: 333 alpha: 25.12508175342\n",
      "timeframe: 4 section: 175 alpha: 43.13766298792399\n",
      "timeframe: 4 section: 140 alpha: 54.47705015676957\n",
      "timeframe: 4 section: 464 alpha: 19.564826746859858\n",
      "timeframe: 4 section: 168 alpha: 22.224522704674445\n",
      "timeframe: 4 section: 340 alpha: 33.6816805858588\n",
      "timeframe: 4 section: 161 alpha: 26.189569426184246\n",
      "timeframe: 4 section: 113 alpha: 25.446357256857347\n",
      "timeframe: 4 section: 182 alpha: 46.88533506517825\n",
      "timeframe: 4 section: 236 alpha: 28.828182953446284\n",
      "timeframe: 4 section: 367 alpha: 29.66596415666051\n",
      "timeframe: 4 section: 492 alpha: 11.689613417732744\n",
      "timeframe: 3 section: 305 alpha: 40.10347496355324\n",
      "timeframe: 4 section: 305 alpha: 56.72040313598782\n",
      "timeframe: 3 section: 291 alpha: 18.961186958929574\n",
      "timeframe: 4 section: 120 alpha: 73.04992308403223\n",
      "timeframe: 3 section: 498 alpha: 47.530857028927564\n",
      "timeframe: 4 section: 85 alpha: 33.651686695345155\n",
      "timeframe: 4 section: 278 alpha: 19.555844630398948\n",
      "timeframe: 4 section: 126 alpha: 1.384916469618075\n",
      "timeframe: 4 section: 78 alpha: 31.68036688050063\n",
      "timeframe: 4 section: 381 alpha: 34.845714921263564\n",
      "timeframe: 4 section: 148 alpha: 5.1600519460859315\n",
      "timeframe: 3 section: 319 alpha: 59.68072765659167\n",
      "timeframe: 4 section: 251 alpha: 40.52162233246214\n",
      "timeframe: 3 section: 477 alpha: 34.948619714939014\n",
      "timeframe: 4 section: 361 alpha: 32.30608580575261\n",
      "timeframe: 4 section: 478 alpha: 24.617392840494244\n",
      "timeframe: 4 section: 499 alpha: 22.42698227718545\n",
      "timeframe: 4 section: 216 alpha: 44.77773042596172\n",
      "timeframe: 4 section: 485 alpha: 24.951803852314452\n",
      "timeframe: 4 section: 312 alpha: 50.9931010486116\n",
      "timeframe: 4 section: 230 alpha: 22.287512571401255\n",
      "timeframe: 4 section: 506 alpha: 32.47446490167172\n",
      "timeframe: 4 section: 430 alpha: 45.87641956558297\n",
      "timeframe: 4 section: 299 alpha: 55.054079180832645\n",
      "timeframe: 3 section: 429 alpha: 52.711332090022324\n",
      "timeframe: 4 section: 388 alpha: 13.291939219927652\n",
      "timeframe: 4 section: 326 alpha: 58.80845741822886\n",
      "timeframe: 4 section: 203 alpha: 23.631001344636452\n",
      "timeframe: 3 section: 491 alpha: 43.8309556811632\n",
      "timeframe: 4 section: 402 alpha: 32.067485799842025\n",
      "timeframe: 4 section: 347 alpha: 40.23132105733828\n",
      "timeframe: 3 section: 402 alpha: 18.570222741026175\n",
      "timeframe: 4 section: 106 alpha: 33.345069779670624\n",
      "timeframe: 4 section: 513 alpha: 10.23148284716714\n",
      "timeframe: 4 section: 285 alpha: 23.297960606121286\n",
      "timeframe: 4 section: 375 alpha: 10.819426150512632\n",
      "timeframe: 4 section: 92 alpha: 21.857243556280295\n",
      "timeframe: 4 section: 409 alpha: 33.74319036050809\n",
      "timeframe: 3 section: 347 alpha: 61.3103352499375\n",
      "timeframe: 4 section: 423 alpha: 50.120253852213125\n",
      "timeframe: 3 section: 367 alpha: 38.33180728188072\n",
      "timeframe: 4 section: 416 alpha: 34.531611108987505\n",
      "timeframe: 4 section: 154 alpha: 68.60747490942727\n",
      "timeframe: 4 section: 395 alpha: 84.30097240116964\n",
      "timeframe: 4 section: 133 alpha: 14.251140223887434\n",
      "timeframe: 4 section: 196 alpha: 15.642612149120804\n",
      "timeframe: 4 section: 541 alpha: 125.70900647920669\n",
      "timeframe: 4 section: 520 alpha: 7.113710354992278\n",
      "timeframe: 3 section: 416 alpha: 15.574526343372028\n",
      "timeframe: 4 section: 292 alpha: 26.094103094435788\n",
      "timeframe: 4 section: 244 alpha: 8.000958661536403\n",
      "timeframe: 4 section: 271 alpha: 22.69565447235398\n",
      "timeframe: 4 section: 451 alpha: 18.921682119380772\n",
      "timeframe: 4 section: 444 alpha: 27.031661688837946\n",
      "timeframe: 4 section: 354 alpha: 61.714994092709404\n",
      "timeframe: 4 section: 258 alpha: 72.49446887222534\n",
      "timeframe: 4 section: 534 alpha: 28.00439947554198\n",
      "timeframe: 4 section: 465 alpha: 20.112065560715806\n",
      "timeframe: 4 section: 527 alpha: 59.07823933216568\n",
      "timeframe: 4 section: 472 alpha: 25.224916945603365\n",
      "timeframe: 4 section: 334 alpha: 35.80934298783374\n",
      "timeframe: 4 section: 265 alpha: 21.109496769285514\n",
      "timeframe: 4 section: 210 alpha: 61.94509825134134\n",
      "timeframe: 4 section: 169 alpha: 96.14165328983839\n",
      "timeframe: 3 section: 256 alpha: 30.684657381587506\n",
      "timeframe: 4 section: 458 alpha: 14.6400196621819\n",
      "timeframe: 4 section: 189 alpha: 27.609131091251157\n",
      "timeframe: 4 section: 320 alpha: 18.673242947957785\n",
      "timeframe: 4 section: 141 alpha: 52.21205510510067\n",
      "timeframe: 4 section: 223 alpha: 63.49749573704976\n",
      "timeframe: 4 section: 127 alpha: 34.874210261986164\n",
      "timeframe: 3 section: 444 alpha: 38.09393902858106\n",
      "timeframe: 4 section: 183 alpha: 45.90620194800794\n",
      "timeframe: 3 section: 456 alpha: 20.607285766617913\n",
      "timeframe: 4 section: 162 alpha: 18.79802617865689\n",
      "timeframe: 4 section: 341 alpha: 46.2793667088154\n",
      "timeframe: 4 section: 493 alpha: 10.310947913405348\n",
      "timeframe: 4 section: 176 alpha: 14.202372688650714\n",
      "timeframe: 4 section: 548 alpha: 22.917656906067897\n",
      "timeframe: 3 section: 451 alpha: 7.980416127622382\n",
      "timeframe: 3 section: 389 alpha: 11.197194413315701\n",
      "timeframe: 4 section: 279 alpha: 32.309881913358645\n",
      "timeframe: 4 section: 382 alpha: 32.045737374940984\n",
      "timeframe: 4 section: 431 alpha: 8.792221826880459\n",
      "timeframe: 4 section: 500 alpha: 5.379771702631341\n",
      "timeframe: 4 section: 507 alpha: 11.426631500949508\n",
      "timeframe: 3 section: 436 alpha: 9.01711978982913\n",
      "timeframe: 4 section: 368 alpha: 20.376213180031023\n",
      "timeframe: 4 section: 437 alpha: 67.36135193254135\n",
      "timeframe: 3 section: 548 alpha: 19.36825628491634\n",
      "timeframe: 4 section: 486 alpha: 45.55018332199128\n",
      "timeframe: 4 section: 306 alpha: 39.50802867436792\n",
      "timeframe: 4 section: 300 alpha: 55.3690059481457\n",
      "timeframe: 4 section: 313 alpha: 48.044095055258225\n",
      "timeframe: 4 section: 237 alpha: 32.11111718463086\n",
      "timeframe: 4 section: 389 alpha: 7.712982851351107\n",
      "timeframe: 4 section: 514 alpha: 25.379755135819465\n",
      "timeframe: 4 section: 217 alpha: 51.34024192903434\n",
      "timeframe: 4 section: 252 alpha: 33.37063691785233\n",
      "timeframe: 4 section: 204 alpha: 18.42875122582771\n",
      "timeframe: 4 section: 479 alpha: 38.56955747257411\n",
      "timeframe: 4 section: 403 alpha: 44.01374066081774\n",
      "timeframe: 4 section: 376 alpha: 14.569769347112908\n",
      "timeframe: 4 section: 410 alpha: 12.21503044165913\n",
      "timeframe: 4 section: 362 alpha: 25.842882731743906\n",
      "timeframe: 4 section: 555 alpha: 33.72574976060862\n",
      "timeframe: 3 section: 430 alpha: 21.39422052691968\n",
      "timeframe: 3 section: 508 alpha: 37.58092170067898\n",
      "timeframe: 4 section: 327 alpha: 18.49894118338074\n",
      "timeframe: 4 section: 155 alpha: 3.645979106561045\n",
      "timeframe: 3 section: 422 alpha: 10.513531494177105\n",
      "timeframe: 3 section: 396 alpha: 52.923794368747814\n",
      "timeframe: 4 section: 424 alpha: 44.47438203787004\n",
      "timeframe: 4 section: 231 alpha: 27.54092586846523\n",
      "timeframe: 4 section: 293 alpha: 126.53234861591176\n",
      "timeframe: 4 section: 286 alpha: 34.551739331796334\n",
      "timeframe: 4 section: 355 alpha: 20.95023668941471\n",
      "timeframe: 4 section: 134 alpha: 27.79547775466293\n",
      "timeframe: 4 section: 521 alpha: 50.75286670419143\n",
      "timeframe: 3 section: 533 alpha: 22.395492966699393\n",
      "timeframe: 4 section: 417 alpha: 43.552351494928885\n",
      "timeframe: 4 section: 197 alpha: 27.424868210367023\n",
      "timeframe: 3 section: 513 alpha: 38.004631253606874\n",
      "timeframe: 4 section: 396 alpha: 73.31036391645668\n",
      "timeframe: 4 section: 245 alpha: 54.87299822656628\n",
      "timeframe: 4 section: 445 alpha: 51.55715541721411\n",
      "timeframe: 4 section: 466 alpha: 24.956699162323844\n",
      "timeframe: 4 section: 542 alpha: 70.52869464326653\n",
      "timeframe: 4 section: 494 alpha: 8.32639214165123\n",
      "timeframe: 3 section: 463 alpha: 61.86185236681929\n",
      "timeframe: 3 section: 540 alpha: 32.48505608763809\n",
      "timeframe: 4 section: 272 alpha: 26.905515732496063\n",
      "timeframe: 4 section: 259 alpha: 38.71603729330396\n",
      "timeframe: 4 section: 432 alpha: 49.560255314942694\n",
      "timeframe: 4 section: 224 alpha: 53.380048082570255\n",
      "timeframe: 4 section: 211 alpha: 105.40440621042787\n",
      "timeframe: 4 section: 348 alpha: 27.15631607530532\n",
      "timeframe: 4 section: 452 alpha: 21.887253187487673\n",
      "timeframe: 4 section: 266 alpha: 36.2990947812704\n",
      "timeframe: 4 section: 549 alpha: 14.87713157999521\n",
      "timeframe: 4 section: 335 alpha: 50.56426123462648\n",
      "timeframe: 4 section: 459 alpha: 55.76713054901093\n",
      "timeframe: 4 section: 528 alpha: 38.049720630372946\n",
      "timeframe: 4 section: 190 alpha: 12.324527710281874\n",
      "timeframe: 3 section: 554 alpha: 63.51617907820069\n",
      "timeframe: 4 section: 383 alpha: 24.533354625222024\n",
      "timeframe: 4 section: 342 alpha: 15.748388232914888\n",
      "timeframe: 4 section: 369 alpha: 8.717470405878224\n",
      "timeframe: 4 section: 473 alpha: 14.937019095219581\n",
      "timeframe: 4 section: 508 alpha: 29.79036203305354\n",
      "timeframe: 4 section: 321 alpha: 62.923281017821125\n",
      "timeframe: 4 section: 238 alpha: 21.39397906586827\n",
      "timeframe: 3 section: 472 alpha: 52.36913361515521\n",
      "timeframe: 4 section: 280 alpha: 31.404950515454956\n",
      "timeframe: 4 section: 411 alpha: 71.27524235818628\n",
      "timeframe: 4 section: 535 alpha: 33.25974174743328\n",
      "timeframe: 4 section: 314 alpha: 15.495346942291306\n",
      "timeframe: 4 section: 487 alpha: 34.7854849275609\n",
      "timeframe: 4 section: 438 alpha: 45.707608429051334\n",
      "timeframe: 3 section: 445 alpha: 5.478434765610747\n",
      "timeframe: 4 section: 390 alpha: 40.43076426737122\n",
      "timeframe: 4 section: 501 alpha: 49.94446044596971\n",
      "timeframe: 4 section: 480 alpha: 21.63640447511656\n",
      "timeframe: 4 section: 363 alpha: 43.62892159776549\n",
      "timeframe: 4 section: 307 alpha: 44.180652814506416\n",
      "timeframe: 4 section: 301 alpha: 16.222938471785213\n",
      "timeframe: 4 section: 218 alpha: 22.535709198479417\n",
      "timeframe: 4 section: 404 alpha: 42.289107879794486\n",
      "timeframe: 4 section: 294 alpha: 19.02900408388714\n",
      "timeframe: 4 section: 328 alpha: 27.40519288008217\n",
      "timeframe: 4 section: 253 alpha: 20.801374050162917\n",
      "timeframe: 3 section: 437 alpha: 27.191313978387743\n",
      "timeframe: 3 section: 410 alpha: 28.349250619687762\n",
      "timeframe: 3 section: 417 alpha: 10.501289714436357\n",
      "timeframe: 3 section: 485 alpha: 24.105348491155443\n",
      "timeframe: 4 section: 515 alpha: 41.188714929659795\n",
      "timeframe: 4 section: 495 alpha: 73.89423630371658\n",
      "timeframe: 4 section: 425 alpha: 25.590762220986562\n",
      "timeframe: 4 section: 356 alpha: 34.814248883193734\n",
      "timeframe: 3 section: 431 alpha: 11.06342242224916\n",
      "timeframe: 4 section: 287 alpha: 19.531258346377953\n",
      "timeframe: 4 section: 522 alpha: 27.14766903611783\n",
      "timeframe: 4 section: 377 alpha: 72.34025719921875\n",
      "timeframe: 4 section: 467 alpha: 22.6584931797846\n",
      "timeframe: 4 section: 273 alpha: 24.84048746575948\n",
      "timeframe: 3 section: 499 alpha: 24.40940745182171\n",
      "timeframe: 4 section: 232 alpha: 31.98957868062122\n",
      "timeframe: 3 section: 200 alpha: 21.612258413644597\n",
      "timeframe: 4 section: 446 alpha: 4.995102063646492\n",
      "timeframe: 4 section: 336 alpha: 14.918046192528024\n",
      "timeframe: 3 section: 520 alpha: 4.67988569168438\n",
      "timeframe: 3 section: 368 alpha: 12.495322711667436\n",
      "timeframe: 4 section: 397 alpha: 34.73601761738233\n",
      "timeframe: 4 section: 453 alpha: 41.234757511372614\n",
      "timeframe: 4 section: 260 alpha: 12.222735558970129\n",
      "timeframe: 4 section: 543 alpha: 86.88430368260286\n",
      "timeframe: 4 section: 433 alpha: 37.28306011248104\n",
      "timeframe: 4 section: 246 alpha: 33.5116298902708\n",
      "timeframe: 3 section: 326 alpha: 23.275232367209274\n",
      "timeframe: 3 section: 549 alpha: 9.663695044258167\n",
      "timeframe: 4 section: 418 alpha: 19.609510961093836\n",
      "timeframe: 4 section: 550 alpha: 19.13906205575558\n",
      "timeframe: 4 section: 460 alpha: 36.638652061459226\n",
      "timeframe: 4 section: 474 alpha: 8.66523766048418\n",
      "timeframe: 4 section: 225 alpha: 30.81106031481939\n",
      "timeframe: 4 section: 267 alpha: 35.017970303592364\n",
      "timeframe: 4 section: 322 alpha: 50.17994788442528\n",
      "timeframe: 4 section: 439 alpha: 88.04537081319229\n",
      "timeframe: 4 section: 343 alpha: 31.191038756794544\n",
      "timeframe: 4 section: 391 alpha: 28.654840425888057\n",
      "timeframe: 3 section: 527 alpha: 36.79690812197816\n",
      "timeframe: 4 section: 509 alpha: 49.70036075556405\n",
      "timeframe: 3 section: 478 alpha: 33.75749106764092\n",
      "timeframe: 4 section: 536 alpha: 42.68037503339503\n",
      "timeframe: 4 section: 529 alpha: 40.430795855625824\n",
      "timeframe: 4 section: 370 alpha: 7.892570106350001\n",
      "timeframe: 4 section: 384 alpha: 38.43041465553349\n",
      "timeframe: 4 section: 405 alpha: 108.51704725264122\n",
      "timeframe: 4 section: 329 alpha: 82.19271736515728\n",
      "timeframe: 4 section: 412 alpha: 25.728564006133695\n",
      "timeframe: 4 section: 502 alpha: 17.12822413212557\n",
      "timeframe: 4 section: 308 alpha: 18.40976680615945\n",
      "timeframe: 4 section: 349 alpha: 38.008249586186764\n",
      "timeframe: 3 section: 492 alpha: 40.93885334735174\n",
      "timeframe: 3 section: 452 alpha: 42.64462154982059\n",
      "timeframe: 3 section: 403 alpha: 32.22393590879209\n",
      "timeframe: 4 section: 315 alpha: 33.01842498229051\n",
      "timeframe: 4 section: 488 alpha: 32.52433732865717\n",
      "timeframe: 4 section: 295 alpha: 22.98565346730697\n",
      "timeframe: 4 section: 481 alpha: 25.942027768406007\n",
      "timeframe: 4 section: 302 alpha: 9.286473735833393\n",
      "timeframe: 4 section: 239 alpha: 22.452252100024495\n",
      "timeframe: 4 section: 496 alpha: 52.89688736842045\n",
      "timeframe: 4 section: 364 alpha: 34.27768946707508\n",
      "timeframe: 4 section: 274 alpha: 16.776328722519295\n",
      "timeframe: 4 section: 357 alpha: 31.441272539778932\n",
      "timeframe: 4 section: 281 alpha: 71.01423072610991\n",
      "timeframe: 4 section: 544 alpha: 23.377919629577885\n",
      "timeframe: 4 section: 398 alpha: 9.464595295644036\n",
      "timeframe: 4 section: 426 alpha: 18.273492156992162\n",
      "timeframe: 4 section: 378 alpha: 18.942218408645044\n",
      "timeframe: 4 section: 288 alpha: 34.570105891267474\n",
      "timeframe: 3 section: 464 alpha: 9.934697406216289\n",
      "timeframe: 4 section: 523 alpha: 11.998676619867503\n",
      "timeframe: 4 section: 440 alpha: 10.620581657227582\n",
      "timeframe: 4 section: 468 alpha: 9.880619679000771\n",
      "timeframe: 4 section: 337 alpha: 1.4822199942691932\n",
      "timeframe: 4 section: 516 alpha: 29.52137532503808\n",
      "timeframe: 4 section: 434 alpha: 47.413405504102286\n",
      "timeframe: 4 section: 475 alpha: 26.220663317430976\n",
      "timeframe: 4 section: 447 alpha: 27.19244634895914\n",
      "timeframe: 3 section: 500 alpha: 36.35702452194277\n",
      "timeframe: 4 section: 419 alpha: 28.805747840257055\n",
      "timeframe: 3 section: 534 alpha: 27.34909092117659\n",
      "timeframe: 4 section: 461 alpha: 15.02074378243369\n",
      "timeframe: 4 section: 392 alpha: 39.06086637595441\n",
      "timeframe: 4 section: 537 alpha: 16.298847272593385\n",
      "timeframe: 4 section: 454 alpha: 35.0050546128726\n",
      "timeframe: 4 section: 551 alpha: 32.720324875373436\n",
      "timeframe: 4 section: 371 alpha: 24.748884114344648\n",
      "timeframe: 3 section: 457 alpha: 24.08049610706219\n",
      "timeframe: 4 section: 323 alpha: 52.79098330773437\n",
      "timeframe: 4 section: 330 alpha: 9.261206856901003\n",
      "timeframe: 4 section: 385 alpha: 20.84589871893891\n",
      "timeframe: 3 section: 423 alpha: 30.9071640132141\n",
      "timeframe: 3 section: 541 alpha: 107.37870987240197\n",
      "timeframe: 4 section: 344 alpha: 30.388613184177814\n",
      "timeframe: 4 section: 406 alpha: 75.14237331404858\n",
      "timeframe: 4 section: 530 alpha: 46.978068870306\n",
      "timeframe: 4 section: 489 alpha: 42.437174654144684\n",
      "timeframe: 4 section: 503 alpha: 18.787867299528386\n",
      "timeframe: 4 section: 350 alpha: 13.933443360072074\n",
      "timeframe: 4 section: 413 alpha: 40.55927251490226\n",
      "timeframe: 3 section: 514 alpha: 28.846378758166747\n",
      "timeframe: 4 section: 316 alpha: 88.7832069249758\n",
      "timeframe: 4 section: 358 alpha: 143.60840630795298\n",
      "timeframe: 4 section: 482 alpha: 21.480614574053533\n",
      "timeframe: 4 section: 510 alpha: 21.987212144391837\n",
      "timeframe: 4 section: 309 alpha: 64.27593138789298\n",
      "timeframe: 4 section: 517 alpha: 41.418707096187504\n",
      "timeframe: 4 section: 399 alpha: 16.069762994246958\n",
      "timeframe: 4 section: 469 alpha: 37.947414677680506\n",
      "timeframe: 4 section: 435 alpha: 18.292654854971985\n",
      "timeframe: 4 section: 427 alpha: 46.370404093750516\n",
      "timeframe: 4 section: 441 alpha: 35.203338587722165\n",
      "timeframe: 4 section: 538 alpha: 15.866491994938041\n",
      "timeframe: 4 section: 420 alpha: 34.05736823787121\n",
      "timeframe: 4 section: 379 alpha: 15.335638138307226\n",
      "timeframe: 4 section: 497 alpha: 36.14487614548779\n",
      "timeframe: 4 section: 524 alpha: 13.506368673265465\n",
      "timeframe: 4 section: 393 alpha: 19.437459971914667\n",
      "timeframe: 4 section: 462 alpha: 15.619481986475643\n",
      "timeframe: 4 section: 448 alpha: 34.8282250217404\n",
      "timeframe: 4 section: 476 alpha: 30.657763072373818\n",
      "timeframe: 3 section: 555 alpha: 37.570778125039745\n",
      "timeframe: 3 section: 438 alpha: 10.666508719898651\n",
      "timeframe: 4 section: 365 alpha: 27.196224983046527\n",
      "timeframe: 4 section: 414 alpha: 23.265069303893227\n",
      "timeframe: 4 section: 545 alpha: 54.209435723127854\n",
      "timeframe: 3 section: 479 alpha: 4.858138127369761\n",
      "timeframe: 4 section: 372 alpha: 53.45026707600299\n",
      "timeframe: 3 section: 486 alpha: 23.161547726828726\n",
      "timeframe: 4 section: 504 alpha: 25.24381748741113\n",
      "timeframe: 4 section: 407 alpha: 23.59360677800138\n",
      "timeframe: 4 section: 351 alpha: 35.401907132345656\n",
      "timeframe: 4 section: 386 alpha: 56.76535770118112\n",
      "timeframe: 4 section: 449 alpha: 130.9249816279951\n",
      "timeframe: 4 section: 552 alpha: 44.32637794645617\n",
      "timeframe: 4 section: 455 alpha: 30.62923397908853\n",
      "timeframe: 3 section: 473 alpha: 17.56841574455629\n",
      "timeframe: 4 section: 490 alpha: 40.30478142694165\n",
      "timeframe: 3 section: 521 alpha: 106.40213324543542\n",
      "timeframe: 4 section: 400 alpha: 30.876971568752534\n",
      "timeframe: 4 section: 483 alpha: 18.30519167231794\n",
      "timeframe: 4 section: 525 alpha: 26.79048967190312\n",
      "timeframe: 4 section: 442 alpha: 19.31850719033837\n",
      "timeframe: 4 section: 511 alpha: 52.72648203914942\n",
      "timeframe: 4 section: 463 alpha: 55.13966678479189\n",
      "timeframe: 4 section: 518 alpha: 23.841615302001163\n",
      "timeframe: 4 section: 470 alpha: 30.25052865300014\n",
      "timeframe: 4 section: 531 alpha: 22.19827401530145\n",
      "timeframe: 4 section: 539 alpha: 17.84423299862261\n",
      "timeframe: 4 section: 421 alpha: 39.206040877902105\n",
      "timeframe: 4 section: 505 alpha: 6.077160174058941\n",
      "timeframe: 4 section: 546 alpha: 47.206591426675104\n",
      "timeframe: 4 section: 477 alpha: 44.590318380091816\n",
      "timeframe: 4 section: 498 alpha: 36.797334666296024\n",
      "timeframe: 4 section: 428 alpha: 47.66865597842745\n",
      "timeframe: 4 section: 0 alpha: 28.977342492014\n",
      "timeframe: 4 section: 456 alpha: 51.911389166485975\n",
      "timeframe: 3 section: 493 alpha: 49.5961232328906\n",
      "timeframe: 4 section: 491 alpha: 19.417614315975445\n",
      "timeframe: 4 section: 553 alpha: 57.65430185667362\n",
      "timeframe: 4 section: 512 alpha: 1.5251105609768891\n",
      "timeframe: 4 section: 519 alpha: 10.177083422658253\n",
      "timeframe: 3 section: 424 alpha: 39.17222120813532\n",
      "timeframe: 4 section: 532 alpha: 101.13291679961141\n",
      "timeframe: 3 section: 528 alpha: 59.63248706099016\n",
      "timeframe: 4 section: 526 alpha: 43.198956360027644\n",
      "timeframe: 4 section: 540 alpha: 39.8132396032085\n",
      "timeframe: 4 section: 547 alpha: 12.891330862607893\n",
      "timeframe: 3 section: 542 alpha: 81.24854035266134\n",
      "timeframe: 4 section: 1 alpha: 17.3742502833032\n",
      "timeframe: 4 section: 484 alpha: 29.44094059416942\n",
      "timeframe: 3 section: 515 alpha: 16.439320572061867\n",
      "timeframe: 3 section: 494 alpha: 27.579966741867647\n",
      "timeframe: 3 section: 550 alpha: 31.50287949082069\n",
      "timeframe: 4 section: 533 alpha: 37.61602846777004\n",
      "timeframe: 3 section: 465 alpha: 37.54809448944159\n",
      "timeframe: 4 section: 554 alpha: 65.81229217328259\n",
      "timeframe: 3 section: 501 alpha: 34.98616490399832\n",
      "timeframe: 3 section: 458 alpha: 41.95410934675149\n",
      "timeframe: 3 section: 543 alpha: 4.893749603859307\n",
      "timeframe: 3 section: 480 alpha: 46.15905645793437\n",
      "timeframe: 3 section: 522 alpha: 42.026696610761505\n",
      "timeframe: 3 section: 535 alpha: 20.145690981649146\n",
      "timeframe: 3 section: 487 alpha: 43.93162774195336\n",
      "timeframe: 3 section: 466 alpha: 29.72880386629883\n",
      "timeframe: 3 section: 529 alpha: 21.4418362352855\n",
      "timeframe: 3 section: 459 alpha: 34.7295455827712\n",
      "timeframe: 3 section: 536 alpha: 36.45049988558566\n",
      "CPU times: user 3.76 s, sys: 12.3 s, total: 16.1 s\n",
      "Wall time: 4min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-399:\n",
      "Process ForkPoolWorker-390:\n",
      "Process ForkPoolWorker-343:\n",
      "Process ForkPoolWorker-371:\n",
      "Process ForkPoolWorker-373:\n",
      "Process ForkPoolWorker-366:\n",
      "Process ForkPoolWorker-394:\n",
      "Process ForkPoolWorker-383:\n",
      "Process ForkPoolWorker-398:\n",
      "Process ForkPoolWorker-397:\n",
      "Process ForkPoolWorker-315:\n",
      "Process ForkPoolWorker-374:\n",
      "Process ForkPoolWorker-354:\n",
      "Process ForkPoolWorker-379:\n",
      "Process ForkPoolWorker-340:\n",
      "Process ForkPoolWorker-310:\n",
      "Process ForkPoolWorker-335:\n",
      "Process ForkPoolWorker-360:\n",
      "Process ForkPoolWorker-338:\n",
      "Process ForkPoolWorker-349:\n",
      "Process ForkPoolWorker-388:\n",
      "Process ForkPoolWorker-333:\n",
      "Process ForkPoolWorker-330:\n",
      "Process ForkPoolWorker-384:\n",
      "Process ForkPoolWorker-347:\n",
      "Process ForkPoolWorker-325:\n",
      "Process ForkPoolWorker-329:\n",
      "Process ForkPoolWorker-382:\n",
      "Process ForkPoolWorker-375:\n",
      "Process ForkPoolWorker-348:\n",
      "Process ForkPoolWorker-346:\n",
      "Process ForkPoolWorker-387:\n",
      "Process ForkPoolWorker-332:\n",
      "Process ForkPoolWorker-369:\n",
      "Process ForkPoolWorker-313:\n",
      "Process ForkPoolWorker-396:\n",
      "Process ForkPoolWorker-395:\n",
      "Process ForkPoolWorker-370:\n",
      "Process ForkPoolWorker-393:\n",
      "Process ForkPoolWorker-376:\n",
      "Process ForkPoolWorker-363:\n",
      "Process ForkPoolWorker-357:\n",
      "Process ForkPoolWorker-364:\n",
      "Process ForkPoolWorker-323:\n",
      "Process ForkPoolWorker-312:\n",
      "Process ForkPoolWorker-381:\n",
      "Process ForkPoolWorker-359:\n",
      "Process ForkPoolWorker-380:\n",
      "Process ForkPoolWorker-352:\n",
      "Process ForkPoolWorker-392:\n",
      "Process ForkPoolWorker-331:\n",
      "Process ForkPoolWorker-389:\n",
      "Process ForkPoolWorker-317:\n",
      "Process ForkPoolWorker-386:\n",
      "Process ForkPoolWorker-336:\n",
      "Process ForkPoolWorker-344:\n",
      "Process ForkPoolWorker-400:\n",
      "Process ForkPoolWorker-319:\n",
      "Process ForkPoolWorker-306:\n",
      "Process ForkPoolWorker-337:\n",
      "Process ForkPoolWorker-391:\n",
      "Process ForkPoolWorker-326:\n",
      "Process ForkPoolWorker-342:\n",
      "Process ForkPoolWorker-367:\n",
      "Process ForkPoolWorker-365:\n",
      "Process ForkPoolWorker-307:\n",
      "Process ForkPoolWorker-355:\n",
      "Process ForkPoolWorker-304:\n",
      "Process ForkPoolWorker-341:\n",
      "Process ForkPoolWorker-350:\n",
      "Process ForkPoolWorker-301:\n",
      "Process ForkPoolWorker-318:\n",
      "Process ForkPoolWorker-316:\n",
      "Process ForkPoolWorker-385:\n",
      "Process ForkPoolWorker-320:\n",
      "Process ForkPoolWorker-358:\n",
      "Process ForkPoolWorker-328:\n",
      "Process ForkPoolWorker-322:\n",
      "Process ForkPoolWorker-353:\n",
      "Process ForkPoolWorker-361:\n",
      "Process ForkPoolWorker-303:\n",
      "Process ForkPoolWorker-311:\n",
      "Process ForkPoolWorker-378:\n",
      "Process ForkPoolWorker-334:\n",
      "Process ForkPoolWorker-351:\n",
      "Process ForkPoolWorker-368:\n",
      "Process ForkPoolWorker-362:\n",
      "Process ForkPoolWorker-308:\n",
      "Process ForkPoolWorker-372:\n",
      "Process ForkPoolWorker-356:\n",
      "Process ForkPoolWorker-324:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-321:\n",
      "Process ForkPoolWorker-309:\n",
      "Process ForkPoolWorker-327:\n",
      "Process ForkPoolWorker-339:\n",
      "Process ForkPoolWorker-314:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-305:\n",
      "Process ForkPoolWorker-302:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-345:\n",
      "Process ForkPoolWorker-377:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pool = mp.Pool(processes=100)\n",
    "\n",
    "results_time = pool.map(fit_lasso_time, range(nSegments * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_time = []\n",
    "\n",
    "for i in range(nSegments * 5):\n",
    "    preds_lasso_time.append(results_time[i].predict(X_test_time[i//556]))\n",
    "\n",
    "\n",
    "#preds_lasso_time_s = np.transpose(preds_lasso_time[:-556].reshape(4,556,80), (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 80, 556)\n",
      "(1, 60, 556)\n",
      "(211280,)\n"
     ]
    }
   ],
   "source": [
    "preds_lasso_time_s = np.array(preds_lasso_time[:-556])\n",
    "preds_lasso_time_s = np.transpose(preds_lasso_time_s.reshape(4,556,80), (0, 2, 1))\n",
    "print(preds_lasso_time_s.shape)\n",
    "\n",
    "preds_lasso_time_e = np.array(preds_lasso_time[-556:])\n",
    "preds_lasso_time_e = np.transpose(preds_lasso_time_e.reshape(1,556,60), (0, 2, 1))\n",
    "print(preds_lasso_time_e.shape)\n",
    "\n",
    "preds_flat = np.concatenate((preds_lasso_time_s.flatten(), preds_lasso_time_e.flatten()))\n",
    "print(preds_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211280,)\n"
     ]
    }
   ],
   "source": [
    "y_flat = np.concatenate((np.array(Y_test_time[:-1]).flatten(), np.array(Y_test_time[-1]).flatten()))\n",
    "print(y_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec CV et time, globale\n",
      "MSE: 105.44522582146786\n",
      "MAE: 7.01154682526274\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec CV et time, globale\")\n",
    "print(\"MSE:\", mean_squared_error(preds_flat, y_flat))\n",
    "print(\"MAE:\", mean_absolute_error(preds_flat, y_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "As=[]\n",
    "for i in range(5):\n",
    "    A = [a.coef_ for a in results_time[i*nSegments:(i+1)*nSegments]]\n",
    "    A = np.array(A)\n",
    "    As.append(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "for i in range(19):\n",
    "    A.append(As[i//4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risque_time(A, X, Y):\n",
    "    n = 45\n",
    "    T = 19\n",
    "    r = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for t in range(T):\n",
    "            if t//4 == 4:\n",
    "                r += np.mean((Y[t//4][i*3+t%3] - np.dot(A[t], X[t//4][i*3+t%3]))**2)\n",
    "            else:\n",
    "                r += np.mean((Y[t//4][i*4+t%4] - np.dot(A[t], X[t//4][i*4+t%4]))**2)\n",
    "    r = r/(n*T)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=19\n",
    "T//4, T%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=13\n",
    "j=5\n",
    "k=T//4\n",
    "\n",
    "if t//4 == 4:\n",
    "    Y_train_time[t//4][i*3+t%3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.02917980806032"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risque_time(A, X_train_time, Y_train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risque du modèle spécifique: 85.03**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle sélectif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 Created!\n",
      "n = 65\n",
      "Z3 Centré !\n"
     ]
    }
   ],
   "source": [
    "Z3 = []\n",
    "\n",
    "for i in range(int((speedDF.shape[1])/20)):\n",
    "    Z3.append(speedDF.iloc[:,i*20:(i+1)*20].values)\n",
    "\n",
    "print(\"Z3 Created!\")\n",
    "n3 = len(Z3)\n",
    "print(\"n =\", n3)\n",
    "\n",
    "Z3 = np.array(Z3)\n",
    "\n",
    "Z3_train = Z3[:45]\n",
    "Z3_test = Z3[45:]\n",
    "\n",
    "\n",
    "M3 = (1/45)*Z3_train.sum(axis=0)\n",
    "\n",
    "for i in range(45):\n",
    "    Z3_train[i] = Z3_train[i] - M3\n",
    "for i in range(65-45):\n",
    "    Z3_test[i] = Z3_test[i] - M3\n",
    "    \n",
    "print(\"Z3 Centré !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_Y(Z, T):\n",
    "    \n",
    "    X1 = Z[:, :, :T]\n",
    "    Y1 = Z[:, :, 1:T+1]\n",
    "    X2 = Z[:, :, T:-1]\n",
    "    Y2 = Z[:, :, T+1:]\n",
    "    X1 = np.concatenate(X1, axis=1)\n",
    "    Y1 = np.concatenate(Y1, axis=1)\n",
    "    X2 = np.concatenate(X2, axis=1)\n",
    "    Y2 = np.concatenate(Y2, axis=1)\n",
    "    return X1.T, Y1.T, X2.T, Y2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 556) (405, 556)\n",
      "(200, 556) (180, 556)\n"
     ]
    }
   ],
   "source": [
    "X1_train, Y1_train, X2_train, Y2_train  = X_Y(Z3_train, T)\n",
    "print(X1_train.shape, X2_train.shape)\n",
    "X1_test, Y1_test, X2_test, Y2_test   = X_Y(Z3_test, T)\n",
    "print(X1_test.shape, X2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-817:\n",
      "Process ForkPoolWorker-818:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "A_lasso_parra_1 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments)]\n",
    "A_lasso_parra_2 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=100) for i in range(nSegments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-820:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "def fit_lasso_double(i):\n",
    "    A_lasso_parra_1[i].fit(X1_train, Y1_train[:, i])\n",
    "    A_lasso_parra_2[i].fit(X2_train, Y2_train[:, i])\n",
    "    print(i)\n",
    "    return A_lasso_parra_1[i], A_lasso_parra_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "18\n",
      "36\n",
      "14\n",
      "16\n",
      "30\n",
      "114\n",
      "120\n",
      "104\n",
      "148\n",
      "86\n",
      "82\n",
      "70\n",
      "34\n",
      "170\n",
      "126\n",
      "108\n",
      "50\n",
      "19\n",
      "38\n",
      "98\n",
      "164\n",
      "156\n",
      "154\n",
      "56\n",
      "10\n",
      "160\n",
      "52\n",
      "15\n",
      "58\n",
      "4\n",
      "35\n",
      "130\n",
      "74\n",
      "105\n",
      "162\n",
      "112\n",
      "146\n",
      "118\n",
      "22\n",
      "158\n",
      "37\n",
      "178\n",
      "66\n",
      "24\n",
      "68\n",
      "144\n",
      "138\n",
      "2\n",
      "12\n",
      "84\n",
      "80\n",
      "134\n",
      "194\n",
      "136\n",
      "90\n",
      "106\n",
      "116\n",
      "132\n",
      "72\n",
      "61\n",
      "204\n",
      "67\n",
      "110\n",
      "96\n",
      "124\n",
      "23\n",
      "44\n",
      "184\n",
      "8\n",
      "71\n",
      "76\n",
      "54\n",
      "51\n",
      "127\n",
      "62\n",
      "88\n",
      "174\n",
      "46\n",
      "57\n",
      "20\n",
      "168\n",
      "176\n",
      "180\n",
      "186\n",
      "102\n",
      "6\n",
      "137\n",
      "94\n",
      "140\n",
      "155\n",
      "145\n",
      "149\n",
      "26\n",
      "78\n",
      "40\n",
      "192\n",
      "32\n",
      "92\n",
      "172\n",
      "122\n",
      "159\n",
      "83\n",
      "166\n",
      "64\n",
      "206\n",
      "190\n",
      "39\n",
      "161\n",
      "205\n",
      "121\n",
      "42\n",
      "128\n",
      "169\n",
      "3\n",
      "31\n",
      "182\n",
      "181\n",
      "208\n",
      "93\n",
      "73\n",
      "81\n",
      "171\n",
      "0\n",
      "196\n",
      "100\n",
      "53\n",
      "87\n",
      "55\n",
      "69\n",
      "48\n",
      "152\n",
      "202\n",
      "28\n",
      "200\n",
      "123\n",
      "185\n",
      "17\n",
      "157\n",
      "109\n",
      "119\n",
      "150\n",
      "147\n",
      "11\n",
      "75\n",
      "224\n",
      "5\n",
      "99\n",
      "79\n",
      "193\n",
      "242\n",
      "142\n",
      "49\n",
      "258\n",
      "25\n",
      "135\n",
      "228\n",
      "115\n",
      "210\n",
      "220\n",
      "165\n",
      "107\n",
      "13\n",
      "111\n",
      "268\n",
      "244\n",
      "59\n",
      "198\n",
      "195\n",
      "131\n",
      "188\n",
      "177\n",
      "163\n",
      "27\n",
      "250\n",
      "117\n",
      "139\n",
      "276\n",
      "89\n",
      "179\n",
      "212\n",
      "125\n",
      "85\n",
      "191\n",
      "264\n",
      "254\n",
      "113\n",
      "216\n",
      "9\n",
      "133\n",
      "234\n",
      "218\n",
      "65\n",
      "245\n",
      "153\n",
      "260\n",
      "7\n",
      "274\n",
      "226\n",
      "248\n",
      "97\n",
      "209\n",
      "41\n",
      "63\n",
      "95\n",
      "173\n",
      "29\n",
      "101\n",
      "238\n",
      "21\n",
      "298\n",
      "187\n",
      "256\n",
      "167\n",
      "232\n",
      "129\n",
      "230\n",
      "214\n",
      "91\n",
      "201\n",
      "280\n",
      "225\n",
      "308\n",
      "175\n",
      "278\n",
      "286\n",
      "222\n",
      "249\n",
      "300\n",
      "207\n",
      "183\n",
      "277\n",
      "270\n",
      "77\n",
      "45\n",
      "316\n",
      "243\n",
      "314\n",
      "275\n",
      "197\n",
      "282\n",
      "261\n",
      "294\n",
      "370\n",
      "257\n",
      "290\n",
      "288\n",
      "141\n",
      "203\n",
      "103\n",
      "330\n",
      "342\n",
      "33\n",
      "252\n",
      "143\n",
      "269\n",
      "292\n",
      "43\n",
      "47\n",
      "151\n",
      "233\n",
      "284\n",
      "240\n",
      "336\n",
      "358\n",
      "246\n",
      "332\n",
      "380\n",
      "338\n",
      "262\n",
      "376\n",
      "296\n",
      "1\n",
      "266\n",
      "374\n",
      "371\n",
      "272\n",
      "354\n",
      "302\n",
      "265\n",
      "324\n",
      "259\n",
      "227\n",
      "211\n",
      "360\n",
      "318\n",
      "239\n",
      "217\n",
      "229\n",
      "322\n",
      "251\n",
      "199\n",
      "372\n",
      "317\n",
      "221\n",
      "368\n",
      "326\n",
      "213\n",
      "430\n",
      "398\n",
      "299\n",
      "352\n",
      "189\n",
      "235\n",
      "340\n",
      "304\n",
      "312\n",
      "422\n",
      "310\n",
      "366\n",
      "400\n",
      "231\n",
      "301\n",
      "356\n",
      "375\n",
      "306\n",
      "346\n",
      "328\n",
      "320\n",
      "388\n",
      "271\n",
      "344\n",
      "267\n",
      "432\n",
      "255\n",
      "236\n",
      "334\n",
      "412\n",
      "337\n",
      "382\n",
      "378\n",
      "373\n",
      "287\n",
      "440\n",
      "348\n",
      "394\n",
      "431\n",
      "406\n",
      "436\n",
      "339\n",
      "215\n",
      "450\n",
      "309\n",
      "291\n",
      "444\n",
      "392\n",
      "263\n",
      "333\n",
      "315\n",
      "355\n",
      "362\n",
      "295\n",
      "297\n",
      "241\n",
      "219\n",
      "389\n",
      "424\n",
      "468\n",
      "413\n",
      "293\n",
      "416\n",
      "402\n",
      "420\n",
      "279\n",
      "331\n",
      "396\n",
      "289\n",
      "414\n",
      "345\n",
      "283\n",
      "307\n",
      "281\n",
      "390\n",
      "359\n",
      "426\n",
      "437\n",
      "442\n",
      "285\n",
      "223\n",
      "343\n",
      "253\n",
      "350\n",
      "247\n",
      "381\n",
      "408\n",
      "410\n",
      "448\n",
      "466\n",
      "445\n",
      "404\n",
      "462\n",
      "341\n",
      "418\n",
      "313\n",
      "369\n",
      "303\n",
      "273\n",
      "379\n",
      "384\n",
      "386\n",
      "399\n",
      "500\n",
      "446\n",
      "361\n",
      "391\n",
      "454\n",
      "329\n",
      "364\n",
      "502\n",
      "395\n",
      "325\n",
      "494\n",
      "434\n",
      "504\n",
      "428\n",
      "323\n",
      "353\n",
      "349\n",
      "512\n",
      "438\n",
      "319\n",
      "451\n",
      "474\n",
      "476\n",
      "452\n",
      "327\n",
      "506\n",
      "401\n",
      "377\n",
      "456\n",
      "470\n",
      "508\n",
      "367\n",
      "516\n",
      "405\n",
      "524\n",
      "393\n",
      "423\n",
      "480\n",
      "458\n",
      "305\n",
      "443\n",
      "464\n",
      "335\n",
      "429\n",
      "383\n",
      "484\n",
      "514\n",
      "411\n",
      "548\n",
      "433\n",
      "503\n",
      "363\n",
      "507\n",
      "449\n",
      "482\n",
      "544\n",
      "311\n",
      "417\n",
      "520\n",
      "460\n",
      "347\n",
      "407\n",
      "237\n",
      "486\n",
      "435\n",
      "505\n",
      "496\n",
      "490\n",
      "467\n",
      "441\n",
      "469\n",
      "492\n",
      "421\n",
      "427\n",
      "351\n",
      "403\n",
      "546\n",
      "357\n",
      "549\n",
      "518\n",
      "538\n",
      "528\n",
      "510\n",
      "425\n",
      "532\n",
      "515\n",
      "542\n",
      "530\n",
      "536\n",
      "472\n",
      "498\n",
      "534\n",
      "478\n",
      "387\n",
      "501\n",
      "550\n",
      "552\n",
      "475\n",
      "397\n",
      "321\n",
      "385\n",
      "483\n",
      "554\n",
      "415\n",
      "526\n",
      "453\n",
      "481\n",
      "525\n",
      "459\n",
      "540\n",
      "521\n",
      "439\n",
      "365\n",
      "488\n",
      "471\n",
      "477\n",
      "447\n",
      "513\n",
      "457\n",
      "519\n",
      "409\n",
      "455\n",
      "487\n",
      "509\n",
      "522\n",
      "419\n",
      "517\n",
      "485\n",
      "537\n",
      "545\n",
      "465\n",
      "491\n",
      "495\n",
      "543\n",
      "463\n",
      "531\n",
      "497\n",
      "499\n",
      "539\n",
      "551\n",
      "511\n",
      "479\n",
      "541\n",
      "523\n",
      "547\n",
      "529\n",
      "555\n",
      "461\n",
      "553\n",
      "493\n",
      "489\n",
      "473\n",
      "535\n",
      "533\n",
      "527\n",
      "CPU times: user 53.7 s, sys: 2min 38s, total: 3min 32s\n",
      "Wall time: 33min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1004:\n",
      "Process ForkPoolWorker-997:\n",
      "Process ForkPoolWorker-1005:\n",
      "Process ForkPoolWorker-994:\n",
      "Process ForkPoolWorker-1013:\n",
      "Process ForkPoolWorker-993:\n",
      "Process ForkPoolWorker-996:\n",
      "Process ForkPoolWorker-1007:\n",
      "Process ForkPoolWorker-1010:\n",
      "Process ForkPoolWorker-1006:\n",
      "Process ForkPoolWorker-974:\n",
      "Process ForkPoolWorker-991:\n",
      "Process ForkPoolWorker-990:\n",
      "Process ForkPoolWorker-1000:\n",
      "Process ForkPoolWorker-1016:\n",
      "Process ForkPoolWorker-1002:\n",
      "Process ForkPoolWorker-1009:\n",
      "Process ForkPoolWorker-1003:\n",
      "Process ForkPoolWorker-1008:\n",
      "Process ForkPoolWorker-1018:\n",
      "Process ForkPoolWorker-1011:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-983:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-961:\n",
      "Process ForkPoolWorker-957:\n",
      "Process ForkPoolWorker-928:\n",
      "Process ForkPoolWorker-969:\n",
      "Process ForkPoolWorker-943:\n",
      "Process ForkPoolWorker-968:\n",
      "Process ForkPoolWorker-949:\n",
      "Process ForkPoolWorker-988:\n",
      "Process ForkPoolWorker-978:\n",
      "Process ForkPoolWorker-963:\n",
      "Process ForkPoolWorker-922:\n",
      "Process ForkPoolWorker-972:\n",
      "Process ForkPoolWorker-995:\n",
      "Process ForkPoolWorker-935:\n",
      "Process ForkPoolWorker-975:\n",
      "Process ForkPoolWorker-971:\n",
      "Process ForkPoolWorker-986:\n",
      "Process ForkPoolWorker-952:\n",
      "Process ForkPoolWorker-932:\n",
      "Process ForkPoolWorker-944:\n",
      "Process ForkPoolWorker-973:\n",
      "Process ForkPoolWorker-946:\n",
      "Process ForkPoolWorker-933:\n",
      "Process ForkPoolWorker-959:\n",
      "Process ForkPoolWorker-924:\n",
      "Process ForkPoolWorker-1001:\n",
      "Process ForkPoolWorker-979:\n",
      "Process ForkPoolWorker-939:\n",
      "Process ForkPoolWorker-925:\n",
      "Process ForkPoolWorker-945:\n",
      "Process ForkPoolWorker-951:\n",
      "Process ForkPoolWorker-940:\n",
      "Process ForkPoolWorker-941:\n",
      "Process ForkPoolWorker-921:\n",
      "Process ForkPoolWorker-947:\n",
      "Process ForkPoolWorker-950:\n",
      "Process ForkPoolWorker-980:\n",
      "Process ForkPoolWorker-955:\n",
      "Process ForkPoolWorker-956:\n",
      "Process ForkPoolWorker-936:\n",
      "Process ForkPoolWorker-1015:\n",
      "Process ForkPoolWorker-958:\n",
      "Process ForkPoolWorker-967:\n",
      "Process ForkPoolWorker-982:\n",
      "Process ForkPoolWorker-954:\n",
      "Process ForkPoolWorker-1012:\n",
      "Process ForkPoolWorker-960:\n",
      "Process ForkPoolWorker-965:\n",
      "Process ForkPoolWorker-989:\n",
      "Process ForkPoolWorker-919:\n",
      "Process ForkPoolWorker-942:\n",
      "Process ForkPoolWorker-976:\n",
      "Process ForkPoolWorker-998:\n",
      "Process ForkPoolWorker-923:\n",
      "Process ForkPoolWorker-953:\n",
      "Process ForkPoolWorker-966:\n",
      "Process ForkPoolWorker-964:\n",
      "Process ForkPoolWorker-934:\n",
      "Process ForkPoolWorker-962:\n",
      "Process ForkPoolWorker-938:\n",
      "Process ForkPoolWorker-977:\n",
      "Process ForkPoolWorker-992:\n",
      "Process ForkPoolWorker-929:\n",
      "Process ForkPoolWorker-926:\n",
      "Process ForkPoolWorker-916:\n",
      "Process ForkPoolWorker-917:\n",
      "Process ForkPoolWorker-927:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-948:\n",
      "Process ForkPoolWorker-930:\n",
      "Process ForkPoolWorker-937:\n",
      "Process ForkPoolWorker-981:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-920:\n",
      "Process ForkPoolWorker-918:\n",
      "Process ForkPoolWorker-931:\n",
      "Process ForkPoolWorker-984:\n",
      "Process ForkPoolWorker-1014:\n",
      "Process ForkPoolWorker-1017:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-987:\n",
      "Process ForkPoolWorker-999:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-970:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-985:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pool = mp.Pool(processes=100)\n",
    "\n",
    "results_double = pool.map(fit_lasso_double, range(nSegments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_double = []\n",
    "\n",
    "for i in range(nSegments):\n",
    "    pred1 = results_double[i][0].predict(X1_test)\n",
    "    pred2 = results_double[i][1].predict(X2_test)\n",
    "    preds_lasso_double.append(np.concatenate((pred1,pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.46944828052457"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_double[10][1].mse_path_[np.where(results_double[10][1].alphas_ == results_double[10][1].alpha_)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lasso_double = np.array(preds_lasso_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 380)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_lasso_double.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 380)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_concat = np.concatenate((Y1_test, Y2_test)).T\n",
    "Y_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec CV et time, split en T=10\n",
      "MSE: 103.21306633834385\n",
      "MAE: 6.940675328469302\n"
     ]
    }
   ],
   "source": [
    "print(\"Avec CV et time, split en T=10\")\n",
    "print(\"MSE:\", mean_squared_error(preds_lasso_double.flatten(), Y_concat.flatten()))\n",
    "print(\"MAE:\", mean_absolute_error(preds_lasso_double.flatten(), Y_concat.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step(T):\n",
    "    print(\"\\n------ STEP\", T ,\"------\\n\")\n",
    "    print('Splitting data')\n",
    "    X1_train, Y1_train, X2_train, Y2_train  = X_Y(Z3_train, T)\n",
    "    print(\"Train: X1 shape:\", X1_train.shape, \"X2 shape:\", X2_train.shape)\n",
    "    X1_test, Y1_test, X2_test, Y2_test   = X_Y(Z3_test, T)\n",
    "    print(\"Test: X1 shape:\", X1_test.shape, \"X2 shape:\", X2_test.shape)\n",
    "    print()\n",
    "    \n",
    "    A_lasso_parra_1 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=10) for i in range(10)]\n",
    "    A_lasso_parra_2 = [linear_model.LassoCV(n_jobs=-1, cv=5, max_iter=10000, tol=0.0001, n_alphas=10) for i in range(10)]\n",
    "    print('Models created !')\n",
    "    \n",
    "    def fit_lasso_double(i):\n",
    "        A_lasso_parra_1[i].fit(X1_train, Y1_train[:, i])\n",
    "        A_lasso_parra_2[i].fit(X2_train, Y2_train[:, i])\n",
    "        return A_lasso_parra_1[i], A_lasso_parra_2[i]\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    start = time.time()\n",
    "    pool = mp.Pool(processes=10)\n",
    "    results_double = pool.map(fit_lasso_double, range(10))\n",
    "    end=time.time()\n",
    "    print(\"Training done in \", end - start, \"seconds\")\n",
    "    \n",
    "    mse=0\n",
    "    for i in range(10):\n",
    "        mse += T * np.mean(results_double[i][0].mse_path_[np.where(results_double[i][0].alphas_ == results_double[i][0].alpha_)[0][0]])\n",
    "        mse += (19-T) * np.mean(results_double[i][1].mse_path_[np.where(results_double[i][1].alphas_ == results_double[i][1].alpha_)[0][0]])\n",
    "    mse = mse/(19*10)\n",
    "    \n",
    "    print('MSE:', mse)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport worker\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 Created!\n",
      "n = 65\n",
      "Z Centré !\n"
     ]
    }
   ],
   "source": [
    "W = worker.T_optim(speedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ STEP 1 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (45, 556) X2 shape: (810, 556)\n",
      "Test: X1 shape: (20, 556) X2 shape: (360, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  32.95591616630554 seconds\n",
      "MSE: 88.45780683638188\n",
      "\n",
      "------ STEP 2 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (90, 556) X2 shape: (765, 556)\n",
      "Test: X1 shape: (40, 556) X2 shape: (340, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  35.873591899871826 seconds\n",
      "MSE: 88.69318773014912\n",
      "\n",
      "------ STEP 3 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (135, 556) X2 shape: (720, 556)\n",
      "Test: X1 shape: (60, 556) X2 shape: (320, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  40.24766731262207 seconds\n",
      "MSE: 89.5123232730679\n",
      "\n",
      "------ STEP 4 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (180, 556) X2 shape: (675, 556)\n",
      "Test: X1 shape: (80, 556) X2 shape: (300, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  97.3743577003479 seconds\n",
      "MSE: 89.6260708158256\n",
      "\n",
      "------ STEP 5 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (225, 556) X2 shape: (630, 556)\n",
      "Test: X1 shape: (100, 556) X2 shape: (280, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  95.09438061714172 seconds\n",
      "MSE: 89.77199351795741\n",
      "\n",
      "------ STEP 6 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (270, 556) X2 shape: (585, 556)\n",
      "Test: X1 shape: (120, 556) X2 shape: (260, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  86.63007307052612 seconds\n",
      "MSE: 89.61616929753893\n",
      "\n",
      "------ STEP 7 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (315, 556) X2 shape: (540, 556)\n",
      "Test: X1 shape: (140, 556) X2 shape: (240, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  74.84304523468018 seconds\n",
      "MSE: 89.90367510639949\n",
      "\n",
      "------ STEP 8 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (360, 556) X2 shape: (495, 556)\n",
      "Test: X1 shape: (160, 556) X2 shape: (220, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  71.19341611862183 seconds\n",
      "MSE: 89.36370852275913\n",
      "\n",
      "------ STEP 9 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (405, 556) X2 shape: (450, 556)\n",
      "Test: X1 shape: (180, 556) X2 shape: (200, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  56.17234182357788 seconds\n",
      "MSE: 89.41797089745903\n",
      "\n",
      "------ STEP 10 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (450, 556) X2 shape: (405, 556)\n",
      "Test: X1 shape: (200, 556) X2 shape: (180, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  48.10473561286926 seconds\n",
      "MSE: 89.2351980775071\n",
      "\n",
      "------ STEP 11 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (495, 556) X2 shape: (360, 556)\n",
      "Test: X1 shape: (220, 556) X2 shape: (160, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  48.3069953918457 seconds\n",
      "MSE: 88.96705242028767\n",
      "\n",
      "------ STEP 12 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (540, 556) X2 shape: (315, 556)\n",
      "Test: X1 shape: (240, 556) X2 shape: (140, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  53.272119760513306 seconds\n",
      "MSE: 88.2557710684287\n",
      "\n",
      "------ STEP 13 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (585, 556) X2 shape: (270, 556)\n",
      "Test: X1 shape: (260, 556) X2 shape: (120, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  73.68909025192261 seconds\n",
      "MSE: 87.78814886483164\n",
      "\n",
      "------ STEP 14 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (630, 556) X2 shape: (225, 556)\n",
      "Test: X1 shape: (280, 556) X2 shape: (100, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  78.44259691238403 seconds\n",
      "MSE: 88.04352237480562\n",
      "\n",
      "------ STEP 15 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (675, 556) X2 shape: (180, 556)\n",
      "Test: X1 shape: (300, 556) X2 shape: (80, 556)\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  97.12826037406921 seconds\n",
      "MSE: 88.52084115690877\n",
      "\n",
      "------ STEP 16 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (720, 556) X2 shape: (135, 556)\n",
      "Test: X1 shape: (320, 556) X2 shape: (60, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  34.0647189617157 seconds\n",
      "MSE: 88.18107205684025\n",
      "\n",
      "------ STEP 17 ------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (765, 556) X2 shape: (90, 556)\n",
      "Test: X1 shape: (340, 556) X2 shape: (40, 556)\n",
      "\n",
      "Training...\n",
      "Training done in  38.34453010559082 seconds\n",
      "MSE: 88.18327590131813\n",
      "CPU times: user 2.01 s, sys: 2.74 s, total: 4.75 s\n",
      "Wall time: 17min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6ca43db588>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6be926bdd8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,18), W.Ts)\n",
    "plt.plot(range(1,18), [89.59]*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker v0.2\n",
      "Z3 Created!\n",
      "n = 65\n",
      "Z Centré !\n"
     ]
    }
   ],
   "source": [
    "W2 = worker.T_optim(speedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "------ STEP 1 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (45, 556) X2 shape: (810, 556)\n",
      "Test: X1 shape: (20, 556) X2 shape: (360, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  388.6070713996887 seconds\n",
      "MSE: 100.32089699966409\n",
      "\n",
      "--------------------\n",
      "------ STEP 2 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (90, 556) X2 shape: (765, 556)\n",
      "Test: X1 shape: (40, 556) X2 shape: (340, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  428.9380078315735 seconds\n",
      "MSE: 100.82066943669241\n",
      "\n",
      "--------------------\n",
      "------ STEP 3 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (135, 556) X2 shape: (720, 556)\n",
      "Test: X1 shape: (60, 556) X2 shape: (320, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  471.4565269947052 seconds\n",
      "MSE: 101.05199147381843\n",
      "\n",
      "--------------------\n",
      "------ STEP 4 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (180, 556) X2 shape: (675, 556)\n",
      "Test: X1 shape: (80, 556) X2 shape: (300, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  641.0438439846039 seconds\n",
      "MSE: 101.25406812604716\n",
      "\n",
      "--------------------\n",
      "------ STEP 5 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (225, 556) X2 shape: (630, 556)\n",
      "Test: X1 shape: (100, 556) X2 shape: (280, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  579.2586665153503 seconds\n",
      "MSE: 101.23306444428914\n",
      "\n",
      "--------------------\n",
      "------ STEP 6 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (270, 556) X2 shape: (585, 556)\n",
      "Test: X1 shape: (120, 556) X2 shape: (260, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  455.8152551651001 seconds\n",
      "MSE: 101.15883647782329\n",
      "\n",
      "--------------------\n",
      "------ STEP 7 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (315, 556) X2 shape: (540, 556)\n",
      "Test: X1 shape: (140, 556) X2 shape: (240, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  372.35116267204285 seconds\n",
      "MSE: 101.20461658848455\n",
      "\n",
      "--------------------\n",
      "------ STEP 8 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (360, 556) X2 shape: (495, 556)\n",
      "Test: X1 shape: (160, 556) X2 shape: (220, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  290.0502245426178 seconds\n",
      "MSE: 101.09104760194461\n",
      "\n",
      "--------------------\n",
      "------ STEP 9 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (405, 556) X2 shape: (450, 556)\n",
      "Test: X1 shape: (180, 556) X2 shape: (200, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  244.89900159835815 seconds\n",
      "MSE: 100.90205675387031\n",
      "\n",
      "--------------------\n",
      "------ STEP 10 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (450, 556) X2 shape: (405, 556)\n",
      "Test: X1 shape: (200, 556) X2 shape: (180, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  216.86948204040527 seconds\n",
      "MSE: 100.81888286342877\n",
      "\n",
      "--------------------\n",
      "------ STEP 11 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (495, 556) X2 shape: (360, 556)\n",
      "Test: X1 shape: (220, 556) X2 shape: (160, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  227.0064446926117 seconds\n",
      "MSE: 100.80448068158483\n",
      "\n",
      "--------------------\n",
      "------ STEP 12 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (540, 556) X2 shape: (315, 556)\n",
      "Test: X1 shape: (240, 556) X2 shape: (140, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  263.143541097641 seconds\n",
      "MSE: 100.93378478738838\n",
      "\n",
      "--------------------\n",
      "------ STEP 13 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (585, 556) X2 shape: (270, 556)\n",
      "Test: X1 shape: (260, 556) X2 shape: (120, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  335.03546237945557 seconds\n",
      "MSE: 100.74984946419683\n",
      "\n",
      "--------------------\n",
      "------ STEP 14 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (630, 556) X2 shape: (225, 556)\n",
      "Test: X1 shape: (280, 556) X2 shape: (100, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  444.068710565567 seconds\n",
      "MSE: 100.73184378317795\n",
      "\n",
      "--------------------\n",
      "------ STEP 15 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (675, 556) X2 shape: (180, 556)\n",
      "Test: X1 shape: (300, 556) X2 shape: (80, 556)\n",
      "\n",
      "Training on 20 processors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in  532.4327018260956 seconds\n",
      "MSE: 100.9070990670666\n",
      "\n",
      "--------------------\n",
      "------ STEP 16 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (720, 556) X2 shape: (135, 556)\n",
      "Test: X1 shape: (320, 556) X2 shape: (60, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  414.14392828941345 seconds\n",
      "MSE: 100.79962888595428\n",
      "\n",
      "--------------------\n",
      "------ STEP 17 ------\n",
      "--------------------\n",
      "\n",
      "Splitting data\n",
      "Train: X1 shape: (765, 556) X2 shape: (90, 556)\n",
      "Test: X1 shape: (340, 556) X2 shape: (40, 556)\n",
      "\n",
      "Training on 20 processors...\n",
      "Training done in  399.4573087692261 seconds\n",
      "MSE: 100.59669428862325\n",
      "CPU times: user 1min 25s, sys: 3min 52s, total: 5min 17s\n",
      "Wall time: 1h 51min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.32089699966409,\n",
       " 100.82066943669241,\n",
       " 101.05199147381843,\n",
       " 101.25406812604716,\n",
       " 101.23306444428914,\n",
       " 101.15883647782329,\n",
       " 101.20461658848455,\n",
       " 101.09104760194461,\n",
       " 100.90205675387031,\n",
       " 100.81888286342877,\n",
       " 100.80448068158483,\n",
       " 100.93378478738838,\n",
       " 100.74984946419683,\n",
       " 100.73184378317795,\n",
       " 100.9070990670666,\n",
       " 100.79962888595428,\n",
       " 100.59669428862325]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f759c864550>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f759ca01d68>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(W2.Ts)\n",
    "plt.plot(range(1,18), [99.58]*17)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
